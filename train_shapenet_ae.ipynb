{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload of module\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from networks.mlp_models import MLP3D\n",
    "from data.neural_field_datasets_shapenet import AllWeights3D, ModelTransform3D, ShapeNetDataset, FlattenTransform3D, ZScore3D, get_neuron_mean_n_std, get_total_mean_n_std\n",
    "\n",
    "\n",
    "shapeNetData = ShapeNetDataset(\"./datasets/plane_mlp_weights\", transform=AllWeights3D())\n",
    "mean, std = get_total_mean_n_std(shapeNetData)\n",
    "normalizer = ZScore3D(mean, std)\n",
    "shapeNetData_normalized = ShapeNetDataset(\"./datasets/plane_mlp_weights\", transform=[AllWeights3D(), normalizer])\n",
    "\n",
    "all_weights = torch.stack([sample[0] for sample in shapeNetData])\n",
    "all_weights_normalized = torch.stack([sample[0] for sample in shapeNetData_normalized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mluis-muschal\u001b[0m (\u001b[33madl-for-cv\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/luis/uni/adl4cv/adl4cv/adl4cv/wandb/run-20240712_093046-3ti4gjtf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adl-for-cv/autoencoder/runs/3ti4gjtf' target=\"_blank\">different-moon-410</a></strong> to <a href='https://wandb.ai/adl-for-cv/autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adl-for-cv/autoencoder' target=\"_blank\">https://wandb.ai/adl-for-cv/autoencoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adl-for-cv/autoencoder/runs/3ti4gjtf' target=\"_blank\">https://wandb.ai/adl-for-cv/autoencoder/runs/3ti4gjtf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/545 [00:00<?, ?it/s]0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
      "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
      "0.00s - to python to disable frozen modules.\n",
      "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
      "Avg. Loss 0.461147, Loss 0.427890: 100%|██████████| 545/545 [05:08<00:00,  1.77it/s]\n",
      "Avg. Loss 0.395498, Loss 0.376550: 100%|██████████| 545/545 [05:44<00:00,  1.58it/s]\n",
      "Avg. Loss 0.344375, Loss 0.341331: 100%|██████████| 545/545 [06:14<00:00,  1.46it/s]\n",
      "Avg. Loss 0.312484, Loss 0.249385: 100%|██████████| 545/545 [07:19<00:00,  1.24it/s]  \n",
      "Avg. Loss 0.289615, Loss 0.277658: 100%|██████████| 545/545 [08:06<00:00,  1.12it/s]\n",
      "Avg. Loss 0.279371, Loss 0.284654:  68%|██████▊   | 368/545 [04:36<01:16,  2.32it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import math\n",
    "\n",
    "\n",
    "warmup_iters = 100\n",
    "lr_decay_iters = 150000\n",
    "learning_rate = 0.003\n",
    "\n",
    "def get_lr(it):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate * it / warmup_iters\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > lr_decay_iters:\n",
    "        return 0.0\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_iters) / (\n",
    "        lr_decay_iters - warmup_iters\n",
    "    )\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))  # coeff ranges 0..1\n",
    "    return coeff * (learning_rate)\n",
    "\n",
    "wandb.init(project=\"autoencoder\")\n",
    "\n",
    "\n",
    "data = all_weights_normalized.view(-1, 128)\n",
    "\n",
    "pos_enc = torch.Tensor([i for _ in range(3883) for i in range(287)]).unsqueeze(-1)\n",
    "nef_enc = torch.Tensor([i for i in range(3883) for _ in range(287)]).unsqueeze(-1)\n",
    "concatenated_data = torch.cat((data, pos_enc, nef_enc), dim=1)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.n_emb_input = 2048\n",
    "        self.n_emb_latent = 2048\n",
    "        \n",
    "        self.nef_input = nn.Embedding(3883, self.n_emb_input + 128)\n",
    "        self.emb_input = nn.Embedding(287, self.n_emb_input)\n",
    "        self.emb_latent = nn.Embedding(287, self.n_emb_latent)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(128 + self.n_emb_input, 112 + int(self.n_emb_input/2)),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(112 + int(self.n_emb_input/2), 96 + int(self.n_emb_input/4)),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(96 + int(self.n_emb_input/4), 96 + int(self.n_emb_input/8)),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(96 + int(self.n_emb_input/8), 96),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(96 + self.n_emb_latent, 64 + self.n_emb_latent),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64 + self.n_emb_latent, 64 + self.n_emb_latent),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64 + self.n_emb_latent, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos = x[:, -2].int()\n",
    "        nef = x[:, -1].int()\n",
    "        embedding_input = self.emb_input(pos)\n",
    "        nef_input = self.nef_input(nef)\n",
    "        x = nef_input + torch.cat((x[:, :-2], embedding_input), dim=1)\n",
    "        latent = self.encoder(x)\n",
    "        embedding_latent = self.emb_latent(pos)\n",
    "\n",
    "        reconstructed = self.decoder(torch.cat((latent, embedding_latent), dim=1))\n",
    "        return latent, reconstructed\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training the autoencoder\n",
    "num_epochs = lr_decay_iters\n",
    "batch_size = 2048\n",
    "data_loader = torch.utils.data.DataLoader(concatenated_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "exp_avg_loss = None\n",
    "\n",
    "iters = 0\n",
    "\n",
    "while True:\n",
    "    bar = tqdm(data_loader)\n",
    "    for batch in bar:\n",
    "        lr = get_lr(iters)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "        optimizer.zero_grad()\n",
    "        latent, reconstructed = model(batch)\n",
    "        loss = criterion(reconstructed, batch[:, :128])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if exp_avg_loss == None:\n",
    "            exp_avg_loss = loss\n",
    "        exp_avg_loss = 0.95*exp_avg_loss + 0.05*loss\n",
    "        bar.set_description(\"Avg. Loss %f, Loss %f\" % (exp_avg_loss, loss))\n",
    "        iters += 1\n",
    "    \n",
    "        wandb.log({\"lr\": lr, \"iters\": iters, \"loss\": exp_avg_loss.item()})\n",
    "    if iters > lr_decay_iters:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1114421, 129])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1.1579e+00, -1.2348e-01,  1.2735e-01, -1.9410e-01,  0.0000e+00,\n",
       "         1.4119e-01, -2.1411e-01, -1.0901e-01,  7.1479e-02,  7.8582e-01,\n",
       "         9.6256e-01, -1.0795e-01,  9.3229e-02, -1.8610e-02,  8.4163e-02,\n",
       "        -1.1825e-01,  2.4034e-02,  1.5581e-01,  0.0000e+00, -1.8264e-01,\n",
       "         2.2689e-01,  2.4634e-01, -6.5313e-02,  2.2073e-01, -4.3676e-01,\n",
       "         3.6150e-01,  5.8303e-01, -7.4506e-09,  6.9505e-02, -8.6208e-02,\n",
       "         4.4996e-02, -1.3389e-02, -2.3219e-01, -1.0744e-01,  2.8798e-02,\n",
       "         1.2213e+00, -3.6251e-02, -1.4901e-08, -2.8241e-01, -1.7725e-01,\n",
       "        -1.2497e-01,  2.3557e-01,  7.7375e-02,  3.4081e-01,  2.3977e-01,\n",
       "        -1.8440e-02, -1.2832e-01, -1.0434e-01, -2.2410e-01,  2.2442e-02,\n",
       "         5.5499e-02,  1.2483e-01,  7.7722e-02,  2.9068e-02, -3.6923e-02,\n",
       "         1.4052e-03,  5.6786e-01, -1.3231e-01,  6.0694e-02,  6.6704e-02,\n",
       "         2.3971e-01, -3.0080e-01,  6.2760e-01,  5.7211e-01, -4.7014e-02,\n",
       "         4.7261e-03,  1.9259e-01, -1.0223e+00,  0.0000e+00, -3.9228e-01,\n",
       "         1.9814e-01, -3.8427e-02,  6.5771e-01,  3.0492e-03,  6.0730e-01,\n",
       "         1.0155e-01,  7.5986e-01,  1.8285e-01,  0.0000e+00,  6.9265e-02,\n",
       "         1.4901e-08,  2.3992e-01, -1.5550e-01, -3.7253e-09,  1.7161e-01,\n",
       "         3.7661e-01, -4.1976e-02, -1.8150e-01,  4.0164e-01, -1.2519e-01,\n",
       "        -4.1277e-01, -1.1155e-01,  5.7789e-01, -1.7051e-03, -9.8904e-02,\n",
       "         2.0630e-01, -3.4441e-01,  3.6668e-01,  9.2384e-01, -4.9685e-03,\n",
       "        -4.7048e-01, -3.3791e-02,  8.9775e-02, -1.3968e-02, -5.9458e-02,\n",
       "         8.0893e-01,  1.7574e-01,  2.6819e-01, -4.5903e-03, -1.0354e-01,\n",
       "         1.4901e-08, -8.6195e-01,  5.5177e-01, -8.6384e-01, -1.9796e-01,\n",
       "         6.4297e-01,  0.0000e+00, -1.7129e-01, -3.7110e-01, -3.5548e-01,\n",
       "         7.1907e-01, -2.5630e-01,  5.4957e-01,  5.4533e-02, -2.5199e-01,\n",
       "         1.6906e-03, -1.5502e-01,  2.3085e-01,  0.0000e+00])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0105, -0.0242, -0.5174,  0.0126,  0.0018,  0.0026, -0.0056,  0.1566,\n",
       "         -0.0732, -0.0027, -0.0163,  0.0014,  0.0024, -0.0027, -0.0122, -0.0124,\n",
       "         -0.0525, -0.1384, -0.0062,  0.1295,  0.0293,  0.0072, -0.0201, -0.1308,\n",
       "          0.0160,  0.0346,  0.0219,  0.0151, -0.0260,  0.0174,  0.0251,  0.0021,\n",
       "         -0.0230,  0.1000,  0.0115, -0.5205, -0.0046,  0.0082, -0.0076, -0.0259,\n",
       "          0.0161, -0.0170, -0.0746, -0.0072, -0.0131,  0.0195,  0.0669,  0.0038,\n",
       "         -0.0059, -0.0287,  0.0188,  0.0007, -0.0128,  0.0606, -0.1089, -0.0363,\n",
       "          0.0075, -0.0084,  0.0048,  0.2535, -0.0047,  0.3058, -0.0111,  0.0151,\n",
       "          0.0021, -0.0139, -0.0429, -0.0248,  0.0041, -0.0117, -0.0936,  0.0323,\n",
       "         -0.0492, -0.0247,  0.0375, -0.0074,  0.0176,  0.0823, -0.0094,  0.0222,\n",
       "          0.0109,  0.0145, -0.0183, -0.0116, -0.0057,  0.0011,  0.0222,  0.0036,\n",
       "          0.0516,  0.0510, -0.0074,  0.0091, -0.5948, -0.0168, -0.0750,  0.0274,\n",
       "          0.0444,  0.0500,  0.0247, -0.0208, -0.0188,  0.0961,  0.0074,  0.0042,\n",
       "          0.0591, -0.0100,  0.0102, -0.1655,  0.0099,  0.0882, -0.0093, -0.1538,\n",
       "         -0.0101,  0.0188,  0.0012,  0.0129,  0.0011,  0.1819,  0.0449,  0.0164,\n",
       "         -0.0240, -0.0255,  0.0423, -0.0016, -0.0033,  0.0348,  0.1206,  0.0066]],\n",
       "       grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model(concatenated_data[0].unsqueeze(0))[1] - concatenated_data[0][:128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luis/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from networks.mlp_models import MLP3D\n",
    "from data.neural_field_datasets_shapenet import AllWeights3D, ModelTransform3D, ShapeNetDataset, FlattenTransform3D, ZScore3D, get_neuron_mean_n_std, get_total_mean_n_std\n",
    "\n",
    "\n",
    "shapeNetData = ShapeNetDataset(\"./datasets/plane_mlp_weights\", transform=AllWeights3D())\n",
    "means, stds = get_total_mean_n_std(shapeNetData)\n",
    "shapeNetData_simple_normalized = ShapeNetDataset(\"./datasets/plane_mlp_weights\", transform=[AllWeights3D(), ZScore3D(means, stds)])\n",
    "\n",
    "all_weights_simple_normalized = torch.stack([sample[0] for sample in shapeNetData_simple_normalized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mluis-muschal\u001b[0m (\u001b[33madl-for-cv\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/luis/uni/adl4cv/adl4cv/adl4cv/wandb/run-20240707_131212-fvidoew8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adl-for-cv/autoencoder/runs/fvidoew8' target=\"_blank\">zesty-resonance-240</a></strong> to <a href='https://wandb.ai/adl-for-cv/autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adl-for-cv/autoencoder' target=\"_blank\">https://wandb.ai/adl-for-cv/autoencoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adl-for-cv/autoencoder/runs/fvidoew8' target=\"_blank\">https://wandb.ai/adl-for-cv/autoencoder/runs/fvidoew8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Avg. Loss 0.342845, Loss 0.358489: 100%|██████████| 545/545 [01:14<00:00,  7.35it/s]\n",
      "Avg. Loss 0.233364, Loss 0.242267: 100%|██████████| 545/545 [01:17<00:00,  7.00it/s]\n",
      "Avg. Loss 0.189202, Loss 0.221404: 100%|██████████| 545/545 [01:14<00:00,  7.30it/s]\n",
      "Avg. Loss 0.153499, Loss 0.155273: 100%|██████████| 545/545 [01:04<00:00,  8.43it/s]\n",
      "Avg. Loss 0.131173, Loss 0.153633: 100%|██████████| 545/545 [01:05<00:00,  8.35it/s]\n",
      "Avg. Loss 0.118248, Loss 0.116163: 100%|██████████| 545/545 [01:19<00:00,  6.84it/s]\n",
      "Avg. Loss 0.104193, Loss 0.105730: 100%|██████████| 545/545 [01:09<00:00,  7.85it/s]\n",
      "Avg. Loss 0.099532, Loss 0.094433: 100%|██████████| 545/545 [01:04<00:00,  8.42it/s]\n",
      "Avg. Loss 0.086249, Loss 0.095640: 100%|██████████| 545/545 [01:10<00:00,  7.70it/s]\n",
      "Avg. Loss 0.078611, Loss 0.080406: 100%|██████████| 545/545 [01:10<00:00,  7.72it/s]\n",
      "Avg. Loss 0.071784, Loss 0.075807: 100%|██████████| 545/545 [01:08<00:00,  8.01it/s]\n",
      "Avg. Loss 0.074445, Loss 0.064656: 100%|██████████| 545/545 [01:10<00:00,  7.74it/s]\n",
      "Avg. Loss 0.069308, Loss 0.082605: 100%|██████████| 545/545 [01:02<00:00,  8.68it/s]\n",
      "Avg. Loss 0.075227, Loss 0.057936: 100%|██████████| 545/545 [01:25<00:00,  6.38it/s]\n",
      "Avg. Loss 0.058097, Loss 0.053032: 100%|██████████| 545/545 [01:10<00:00,  7.70it/s]\n",
      "Avg. Loss 0.055428, Loss 0.051613: 100%|██████████| 545/545 [01:14<00:00,  7.36it/s]\n",
      "Avg. Loss 0.059813, Loss 0.067472: 100%|██████████| 545/545 [01:07<00:00,  8.02it/s]\n",
      "Avg. Loss 0.059077, Loss 0.051846: 100%|██████████| 545/545 [01:01<00:00,  8.90it/s]\n",
      "Avg. Loss 0.051123, Loss 0.053729:  18%|█▊        | 100/545 [00:16<01:15,  5.92it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 97\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     96\u001b[0m     bar \u001b[38;5;241m=\u001b[39m tqdm(data_loader)\n\u001b[0;32m---> 97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbar\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mget_lr\u001b[49m\u001b[43m(\u001b[49m\u001b[43miters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mparam_group\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_groups\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import math\n",
    "\n",
    "\n",
    "warmup_iters = 100\n",
    "lr_decay_iters = 150000\n",
    "learning_rate = 0.003\n",
    "\n",
    "def get_lr(it):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate * it / warmup_iters\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > lr_decay_iters:\n",
    "        return 0.0\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_iters) / (\n",
    "        lr_decay_iters - warmup_iters\n",
    "    )\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))  # coeff ranges 0..1\n",
    "    return coeff * (learning_rate)\n",
    "\n",
    "wandb.init(project=\"autoencoder\")\n",
    "\n",
    "\n",
    "# Generate class labels\n",
    "labels = torch.arange(287).repeat_interleave(4045)\n",
    "\n",
    "data = all_weights_simple_normalized.view(-1, 128)\n",
    "\n",
    "pos_enc = torch.Tensor([i for _ in range(3883) for i in range(287)]).unsqueeze(-1)\n",
    "concatenated_data = torch.cat((data, pos_enc), dim=1)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.n_emb_input = 512\n",
    "        self.n_emb_latent = 512\n",
    "        \n",
    "        self.emb_input = nn.Embedding(287, self.n_emb_input)\n",
    "        self.emb_latent = nn.Embedding(287, self.n_emb_latent)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(128 + self.n_emb_input, 112 + int(self.n_emb_input/2)),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(112 + int(self.n_emb_input/2), 96 + int(self.n_emb_input/4)),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(96 + int(self.n_emb_input/4), 96 + int(self.n_emb_input/8)),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(96 + int(self.n_emb_input/8), 96 + int(self.n_emb_input/16)),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(96 + int(self.n_emb_input/16), 96),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(96 + self.n_emb_latent, 64 + self.n_emb_latent),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64 + self.n_emb_latent, 64 + self.n_emb_latent),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(64 + self.n_emb_latent, 128),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(128, 128)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos = x[:, -1].int()\n",
    "        embedding_input = self.emb_input(pos)\n",
    "        x = torch.cat((x[:, :-1], embedding_input), dim=1)\n",
    "        latent = self.encoder(x)\n",
    "        embedding_latent = self.emb_latent(pos)\n",
    "\n",
    "        reconstructed = self.decoder(torch.cat((latent, embedding_latent), dim=1))\n",
    "        return latent, reconstructed\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training the autoencoder\n",
    "num_epochs = lr_decay_iters\n",
    "batch_size = 2048\n",
    "data_loader = torch.utils.data.DataLoader(concatenated_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "exp_avg_loss = None\n",
    "\n",
    "iters = 0\n",
    "\n",
    "while True:\n",
    "    bar = tqdm(data_loader)\n",
    "    for batch in bar:\n",
    "        lr = get_lr(iters)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "        optimizer.zero_grad()\n",
    "        latent, reconstructed = model(batch)\n",
    "        loss = criterion(reconstructed, batch[:, :128])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if exp_avg_loss == None:\n",
    "            exp_avg_loss = loss\n",
    "        exp_avg_loss = 0.95*exp_avg_loss + 0.05*loss\n",
    "        bar.set_description(\"Avg. Loss %f, Loss %f\" % (exp_avg_loss, loss))\n",
    "        iters += 1\n",
    "    \n",
    "        wandb.log({\"lr\": lr, \"iters\": iters, \"loss\": exp_avg_loss.item()})\n",
    "    if iters > lr_decay_iters:\n",
    "            break\n",
    "\n",
    "# Project the data into the latent space\n",
    "with torch.no_grad():\n",
    "    latent_space, _ = model(data)\n",
    "\n",
    "# Visualization\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Generate a color map for the 27 classes\n",
    "cmap = plt.get_cmap(\"tab20\", 27)\n",
    "colors = cmap(labels)\n",
    "\n",
    "# # Plot each class with its respective color\n",
    "for class_idx in range(27):\n",
    "    class_data = latent_space[labels == class_idx]\n",
    "    ax.scatter(class_data[:, 0], class_data[:, 1], class_data[:, 2], label=f'Class {class_idx}', alpha=0.6, c=colors[labels == class_idx])\n",
    "\n",
    "\n",
    "ax.set_xlabel('Latent Dimension 1')\n",
    "ax.set_ylabel('Latent Dimension 2')\n",
    "ax.set_zlabel('Latent Dimension 3')\n",
    "plt.title('Latent Space Projection with Autoencoder')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2950e+00, -1.6470e-01, -2.7521e-01,  2.1858e-02, -1.5570e+00,\n",
       "         -5.1293e-02, -1.2569e-01, -4.1379e-02, -1.6014e+00, -6.5952e-01,\n",
       "         -3.4389e-01, -1.7295e-01, -2.5812e-01, -1.0768e-01, -1.6675e-01,\n",
       "         -3.8412e-01,  3.4075e-03,  3.2163e-01, -1.1021e-01,  2.8555e-01,\n",
       "          1.5521e-01, -1.0024e-01,  4.7126e-02, -5.6690e-01, -4.3606e-01,\n",
       "         -7.9278e-01,  3.1277e-02, -1.6087e-01, -2.6900e-01, -8.4168e-01,\n",
       "         -2.1610e-01, -1.1836e-01,  7.2839e-02, -1.7513e-02, -5.2016e-01,\n",
       "         -1.2546e+00,  1.6268e-03, -7.9230e-02, -3.2796e-01, -2.7438e-01,\n",
       "          9.3172e-02, -3.0386e-01,  1.1159e-01, -5.0528e-01, -6.7823e-01,\n",
       "         -2.7406e-02,  9.4909e-02, -1.0364e-01, -2.8155e-01, -8.8741e-01,\n",
       "         -3.1426e-01, -1.5171e-01, -4.6998e-01, -3.4399e-01,  6.7584e-01,\n",
       "         -3.5733e-02, -3.2437e-01, -1.0999e-01, -3.6226e-01, -1.8213e-01,\n",
       "         -3.2022e-01,  1.6424e-01, -4.9512e-01, -1.7287e+00, -1.7672e-02,\n",
       "         -2.2956e-01,  4.1811e-01,  1.6665e-01, -3.8564e-01,  1.6047e-01,\n",
       "         -6.5393e-01, -6.9292e-01, -4.3917e-01, -3.9364e-01, -1.7887e-01,\n",
       "         -3.7497e-01, -7.9749e-01, -8.6868e-02, -6.7156e-02, -4.9928e-02,\n",
       "         -9.4496e-01, -2.9610e-02,  7.3432e-01, -1.4077e-01, -5.2194e-01,\n",
       "         -3.1235e-01, -3.3315e-01, -2.2845e-01, -2.4632e-01, -4.1781e-01,\n",
       "         -5.6166e-01, -7.5557e-01, -1.1431e+00, -7.3829e-02, -2.5041e-01,\n",
       "         -4.1284e-01, -3.4450e-02,  2.7321e-01, -1.4391e+00, -2.9320e-01,\n",
       "          3.6275e-01, -4.4149e-02, -3.2341e-01, -4.3051e-01,  4.2598e-01,\n",
       "         -6.3508e-01, -4.7964e-01, -3.7134e-01, -2.8132e-02, -6.8872e-02,\n",
       "         -1.2119e-01,  1.6802e+00, -1.9152e-01,  2.5139e-01,  1.3967e-01,\n",
       "         -3.8182e-01,  3.5767e-02, -2.8115e-01, -6.1684e-01,  7.0178e-02,\n",
       "         -5.2558e-01, -1.3744e-01, -1.9899e+00, -6.1722e-01, -5.0937e-01,\n",
       "          3.1739e-02,  1.8248e-01, -2.1365e-01]], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = ZScore3D(means, stds)\n",
    "\n",
    "normalizer.reverse(model(concatenated_data[0].unsqueeze(0))[1], None)[0] - concatenated_data[0][:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.5495,  0.8123,  0.3704, -0.1775,  1.6708, -0.0851, -0.9333,  0.2162,\n",
       "         1.6531,  2.1256,  0.0671,  0.3314,  0.6256,  0.0960,  0.0909, -1.0794,\n",
       "         0.1248, -0.6179,  0.0723, -0.8027, -0.9267, -0.1643,  0.0611,  0.2004,\n",
       "         1.1189,  1.4231,  2.2143,  0.2767,  0.5708,  0.9710,  0.1077, -0.0419,\n",
       "         0.1057, -0.1394,  0.4941,  1.5916, -0.3157,  0.0285, -1.8591,  0.3200,\n",
       "         0.3421,  0.2940,  0.1683,  0.1650,  0.5711,  0.1115, -0.4845, -0.2298,\n",
       "         0.6599,  1.1922,  0.7761,  0.4648,  0.6727,  0.4525, -1.5696,  0.1103,\n",
       "         0.3395,  0.3859,  0.0215,  0.1389,  0.4945, -0.2744,  1.4628,  2.5776,\n",
       "        -0.0059,  0.3401, -0.8799, -1.3363,  0.3709,  0.9580,  0.7778,  1.0956,\n",
       "         1.5019,  0.4930,  0.0260,  0.9515, -0.0705,  0.0360,  0.2311,  0.0883,\n",
       "         1.0115,  0.8481, -1.2776,  0.1004,  1.1366, -0.0948,  0.1798,  0.3943,\n",
       "         0.7724,  0.0790,  1.6246,  1.3793,  0.9421,  0.1084,  0.0102,  0.6966,\n",
       "        -0.5904, -1.5365,  3.2594,  0.1339,  0.3238, -0.0730,  0.5441,  0.3457,\n",
       "        -0.7287,  0.8446, -0.1068,  0.2550, -0.1373,  0.1641,  0.0468, -2.7251,\n",
       "        -0.1619, -0.3870,  0.4459,  0.2277, -0.2092,  0.2144,  0.8924, -1.3962,\n",
       "         1.1273, -0.6690,  4.5527, -0.3854, -1.2600,  0.1219, -0.1743,  0.4156])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenated_data[0][:128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from networks.mlp_models import MLP3D\n",
    "from data.neural_field_datasets_shapenet import AllWeights3D, ModelTransform3D, ShapeNetDataset, FlattenTransform3D, ZScore3D, get_neuron_mean_n_std, get_total_mean_n_std\n",
    "\n",
    "\n",
    "shapeNetData_flatten = ShapeNetDataset(\"./datasets/plane_mlp_weights\", transform=[FlattenTransform3D()])\n",
    "all_weights_flatten = torch.stack([sample[0] for sample in shapeNetData_flatten])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3883, 2161, 17])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_weights_flatten.view(3883, -1, 17).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Problem at: /Users/luis/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py 849 getcaller\n"
     ]
    },
    {
     "ename": "CommError",
     "evalue": "Run initialization has timed out after 90.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCommError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m     coeff \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m math\u001b[38;5;241m.\u001b[39mcos(math\u001b[38;5;241m.\u001b[39mpi \u001b[38;5;241m*\u001b[39m decay_ratio))  \u001b[38;5;66;03m# coeff ranges 0..1\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m coeff \u001b[38;5;241m*\u001b[39m (learning_rate)\n\u001b[0;32m---> 30\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mautoencoder\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Generate class labels\u001b[39;00m\n\u001b[1;32m     34\u001b[0m labels \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m287\u001b[39m)\u001b[38;5;241m.\u001b[39mrepeat_interleave(\u001b[38;5;241m4045\u001b[39m)\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:1200\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m logger \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1199\u001b[0m         logger\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;28mstr\u001b[39m(e))\n\u001b[0;32m-> 1200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m logger\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:1181\u001b[0m, in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001b[0m\n\u001b[1;32m   1179\u001b[0m except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     run \u001b[38;5;241m=\u001b[39m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1182\u001b[0m     except_exit \u001b[38;5;241m=\u001b[39m wi\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39m_except_exit\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/wandb/sdk/wandb_init.py:780\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    778\u001b[0m         backend\u001b[38;5;241m.\u001b[39mcleanup()\n\u001b[1;32m    779\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mteardown()\n\u001b[0;32m--> 780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\n\u001b[1;32m    782\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m run_result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# for mypy\u001b[39;00m\n\u001b[1;32m    784\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m run_result\u001b[38;5;241m.\u001b[39mHasField(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mCommError\u001b[0m: Run initialization has timed out after 90.0 sec. \nPlease refer to the documentation for additional information: https://docs.wandb.ai/guides/track/tracking-faq#initstarterror-error-communicating-with-wandb-process-"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "import math\n",
    "\n",
    "\n",
    "warmup_iters = 100\n",
    "lr_decay_iters = 20000\n",
    "learning_rate = 0.008\n",
    "\n",
    "def get_lr(it):\n",
    "    # 1) linear warmup for warmup_iters steps\n",
    "    if it < warmup_iters:\n",
    "        return learning_rate * it / warmup_iters\n",
    "    # 2) if it > lr_decay_iters, return min learning rate\n",
    "    if it > lr_decay_iters:\n",
    "        return 0.0\n",
    "    # 3) in between, use cosine decay down to min learning rate\n",
    "    decay_ratio = (it - warmup_iters) / (\n",
    "        lr_decay_iters - warmup_iters\n",
    "    )\n",
    "    assert 0 <= decay_ratio <= 1\n",
    "    coeff = 0.5 * (1.0 + math.cos(math.pi * decay_ratio))  # coeff ranges 0..1\n",
    "    return coeff * (learning_rate)\n",
    "\n",
    "wandb.init(project=\"autoencoder\")\n",
    "\n",
    "\n",
    "# Generate class labels\n",
    "labels = torch.arange(287).repeat_interleave(4045)\n",
    "\n",
    "data = all_weights_flatten.view(-1, 17)\n",
    "\n",
    "emb_size = 2161\n",
    "\n",
    "pos_enc = torch.Tensor([i for _ in range(3883) for i in range(emb_size)]).unsqueeze(-1)\n",
    "concatenated_data = torch.cat((data, pos_enc), dim=1)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.n_emb_input = 128\n",
    "        self.n_emb_latent = 128\n",
    "        \n",
    "        self.emb_input = nn.Embedding(emb_size, self.n_emb_input)\n",
    "        self.emb_latent = nn.Embedding(emb_size, self.n_emb_latent)\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(17 + self.n_emb_input, 17 + self.n_emb_input//4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(17 + self.n_emb_input//4, 17 + self.n_emb_input//8),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(17 + self.n_emb_input//8, 17 + self.n_emb_input//16),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(17 + self.n_emb_input//16, 8),\n",
    "            nn.GELU(),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(8 + self.n_emb_latent, 12 + self.n_emb_latent),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(12 + self.n_emb_latent, 17),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        pos = x[:, -1].int()\n",
    "        embedding_input = self.emb_input(pos)\n",
    "        x = torch.cat((x[:, :-1], embedding_input), dim=1)\n",
    "        latent = self.encoder(x)\n",
    "        embedding_latent = self.emb_latent(pos)\n",
    "\n",
    "        reconstructed = self.decoder(torch.cat((latent, embedding_latent), dim=1))\n",
    "        return latent, reconstructed\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training the autoencoder\n",
    "num_epochs = lr_decay_iters\n",
    "batch_size = 2048\n",
    "data_loader = torch.utils.data.DataLoader(concatenated_data, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "exp_avg_loss = None\n",
    "\n",
    "iters = 0\n",
    "\n",
    "while True:\n",
    "    bar = tqdm(data_loader)\n",
    "    for batch in bar:\n",
    "        lr = get_lr(iters)\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group[\"lr\"] = lr\n",
    "        optimizer.zero_grad()\n",
    "        latent, reconstructed = model(batch)\n",
    "        loss = criterion(reconstructed, batch[:, :17])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if exp_avg_loss == None:\n",
    "            exp_avg_loss = loss\n",
    "        exp_avg_loss = 0.95*exp_avg_loss + 0.05*loss\n",
    "        bar.set_description(\"Avg. Loss %f, Loss %f\" % (exp_avg_loss, loss))\n",
    "        iters += 1\n",
    "    \n",
    "        wandb.log({\"lr\": lr, \"iters\": iters, \"loss\": exp_avg_loss.item()})\n",
    "    if iters > lr_decay_iters:\n",
    "            break\n",
    "\n",
    "# Project the data into the latent space\n",
    "with torch.no_grad():\n",
    "    latent_space, _ = model(data)\n",
    "\n",
    "# Visualization\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Generate a color map for the 27 classes\n",
    "cmap = plt.get_cmap(\"tab20\", 27)\n",
    "colors = cmap(labels)\n",
    "\n",
    "# # Plot each class with its respective color\n",
    "for class_idx in range(27):\n",
    "    class_data = latent_space[labels == class_idx]\n",
    "    ax.scatter(class_data[:, 0], class_data[:, 1], class_data[:, 2], label=f'Class {class_idx}', alpha=0.6, c=colors[labels == class_idx])\n",
    "\n",
    "\n",
    "ax.set_xlabel('Latent Dimension 1')\n",
    "ax.set_ylabel('Latent Dimension 2')\n",
    "ax.set_zlabel('Latent Dimension 3')\n",
    "plt.title('Latent Space Projection with Autoencoder')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
