{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.DWSNets_dataset import DWSNetsDataset\n",
    "import os\n",
    "\n",
    "dir_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "data_root = os.path.join(dir_path, \"adl4cv\", \"datasets\", \"DWSNets\", \"mnist-inrs\")\n",
    "\n",
    "train_dataset = DWSNetsDataset(data_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'seq.0.weight': tensor([[-4.0755e-03,  3.0275e-02],\n",
      "        [ 3.7985e-02,  3.5304e-02],\n",
      "        [-6.5506e-02,  5.7733e-02],\n",
      "        [ 1.7344e-02, -1.8718e-02],\n",
      "        [ 3.0639e-02, -1.8703e-02],\n",
      "        [ 5.9275e-02, -5.5776e-03],\n",
      "        [-1.1590e-01,  1.9634e-02],\n",
      "        [ 2.6851e-02, -2.4524e-02],\n",
      "        [ 6.5062e-03,  1.1068e-01],\n",
      "        [-9.7189e-02,  1.0473e-01],\n",
      "        [ 6.1123e-02,  1.6021e-02],\n",
      "        [-4.6886e-02, -3.9856e-02],\n",
      "        [-7.6424e-02, -6.5537e-03],\n",
      "        [ 3.6053e-02,  6.2836e-04],\n",
      "        [ 5.1460e-02, -3.5410e-02],\n",
      "        [ 1.5411e-02, -3.3180e-03],\n",
      "        [ 2.2220e-01,  9.5588e-02],\n",
      "        [-2.1557e-02,  2.9739e-02],\n",
      "        [-1.1905e-02,  3.7337e-02],\n",
      "        [-6.2158e-03, -9.7376e-02],\n",
      "        [ 1.2494e-01,  5.1267e-02],\n",
      "        [-4.9377e-02, -9.5556e-02],\n",
      "        [-1.1631e-01, -1.1108e-01],\n",
      "        [-1.6368e-02,  2.2905e-02],\n",
      "        [ 1.8129e-02, -9.8052e-03],\n",
      "        [-3.9306e-03,  2.7790e-02],\n",
      "        [-1.2015e-02, -3.1052e-02],\n",
      "        [ 1.0156e-01,  4.2260e-02],\n",
      "        [-4.4942e-05, -1.6590e-02],\n",
      "        [ 3.3038e-02,  5.0072e-02],\n",
      "        [-3.3714e-02,  1.9098e-02],\n",
      "        [ 1.0767e-01, -7.4759e-02]]), 'seq.0.bias': tensor([ 0.0202,  0.0011, -0.0174,  0.0026, -0.0029, -0.0240,  0.0412, -0.0119,\n",
      "         0.0277,  0.0181, -0.0037,  0.0323, -0.0203, -0.0057, -0.0233,  0.0048,\n",
      "         0.0057, -0.0062,  0.0012,  0.0390, -0.0237, -0.0223, -0.0284,  0.0077,\n",
      "         0.0024, -0.0060,  0.0072,  0.0151, -0.0013, -0.0252,  0.0010,  0.0349]), 'seq.1.weight': tensor([[ 0.0076, -0.0029,  0.0167,  ...,  0.0203,  0.0202, -0.0392],\n",
      "        [ 0.0076, -0.0083, -0.0249,  ..., -0.0177,  0.0130,  0.0053],\n",
      "        [-0.0017,  0.0123, -0.0071,  ...,  0.0021,  0.0089, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0037, -0.0129, -0.0056,  ..., -0.0045, -0.0081,  0.0026],\n",
      "        [ 0.0027,  0.0083,  0.0081,  ...,  0.0166,  0.0148,  0.0116],\n",
      "        [ 0.0010,  0.0076, -0.0036,  ..., -0.0120, -0.0082, -0.0130]]), 'seq.1.bias': tensor([ 2.5572e-03,  1.7622e-02, -1.5101e-03, -2.6502e-03,  1.2701e-02,\n",
      "        -1.3778e-02,  1.2277e-02, -8.3413e-03, -8.2331e-05, -2.6151e-02,\n",
      "        -1.0561e-02,  3.0911e-03,  9.9139e-03, -1.8712e-02, -8.0739e-03,\n",
      "        -4.9640e-03, -1.2774e-02, -1.5474e-04,  4.0902e-03, -9.4142e-03,\n",
      "         1.1016e-03,  1.8561e-02,  2.3165e-02, -1.7743e-02, -4.5437e-03,\n",
      "        -6.6245e-03,  8.5496e-03,  1.5334e-03,  6.8465e-03,  6.8899e-03,\n",
      "         5.0997e-03, -1.0035e-02]), 'seq.2.weight': tensor([[-0.1638,  0.1058,  0.0391,  0.0761,  0.0822,  0.0457, -0.1000,  0.1082,\n",
      "         -0.0818, -0.0971, -0.0778, -0.0021, -0.0912, -0.0910,  0.0975,  0.0253,\n",
      "          0.0760, -0.0623, -0.1723,  0.1213,  0.1141, -0.0736,  0.1695, -0.0692,\n",
      "          0.1621, -0.0721, -0.1221,  0.1021, -0.0767, -0.1468, -0.1311,  0.1318]]), 'seq.2.bias': tensor([-0.1846])})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([-0.0041,  0.0303,  0.0380,  ..., -0.1311,  0.1318, -0.1846]), 1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'seq.0.weight': tensor([[-4.0755e-03,  3.0275e-02],\n",
      "        [ 3.7985e-02,  3.5304e-02],\n",
      "        [-6.5506e-02,  5.7733e-02],\n",
      "        [ 1.7344e-02, -1.8718e-02],\n",
      "        [ 3.0639e-02, -1.8703e-02],\n",
      "        [ 5.9275e-02, -5.5776e-03],\n",
      "        [-1.1590e-01,  1.9634e-02],\n",
      "        [ 2.6851e-02, -2.4524e-02],\n",
      "        [ 6.5062e-03,  1.1068e-01],\n",
      "        [-9.7189e-02,  1.0473e-01],\n",
      "        [ 6.1123e-02,  1.6021e-02],\n",
      "        [-4.6886e-02, -3.9856e-02],\n",
      "        [-7.6424e-02, -6.5537e-03],\n",
      "        [ 3.6053e-02,  6.2836e-04],\n",
      "        [ 5.1460e-02, -3.5410e-02],\n",
      "        [ 1.5411e-02, -3.3180e-03],\n",
      "        [ 2.2220e-01,  9.5588e-02],\n",
      "        [-2.1557e-02,  2.9739e-02],\n",
      "        [-1.1905e-02,  3.7337e-02],\n",
      "        [-6.2158e-03, -9.7376e-02],\n",
      "        [ 1.2494e-01,  5.1267e-02],\n",
      "        [-4.9377e-02, -9.5556e-02],\n",
      "        [-1.1631e-01, -1.1108e-01],\n",
      "        [-1.6368e-02,  2.2905e-02],\n",
      "        [ 1.8129e-02, -9.8052e-03],\n",
      "        [-3.9306e-03,  2.7790e-02],\n",
      "        [-1.2015e-02, -3.1052e-02],\n",
      "        [ 1.0156e-01,  4.2260e-02],\n",
      "        [-4.4942e-05, -1.6590e-02],\n",
      "        [ 3.3038e-02,  5.0072e-02],\n",
      "        [-3.3714e-02,  1.9098e-02],\n",
      "        [ 1.0767e-01, -7.4759e-02]]), 'seq.0.bias': tensor([ 0.0202,  0.0011, -0.0174,  0.0026, -0.0029, -0.0240,  0.0412, -0.0119,\n",
      "         0.0277,  0.0181, -0.0037,  0.0323, -0.0203, -0.0057, -0.0233,  0.0048,\n",
      "         0.0057, -0.0062,  0.0012,  0.0390, -0.0237, -0.0223, -0.0284,  0.0077,\n",
      "         0.0024, -0.0060,  0.0072,  0.0151, -0.0013, -0.0252,  0.0010,  0.0349]), 'seq.1.weight': tensor([[ 0.0076, -0.0029,  0.0167,  ...,  0.0203,  0.0202, -0.0392],\n",
      "        [ 0.0076, -0.0083, -0.0249,  ..., -0.0177,  0.0130,  0.0053],\n",
      "        [-0.0017,  0.0123, -0.0071,  ...,  0.0021,  0.0089, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0037, -0.0129, -0.0056,  ..., -0.0045, -0.0081,  0.0026],\n",
      "        [ 0.0027,  0.0083,  0.0081,  ...,  0.0166,  0.0148,  0.0116],\n",
      "        [ 0.0010,  0.0076, -0.0036,  ..., -0.0120, -0.0082, -0.0130]]), 'seq.1.bias': tensor([ 2.5572e-03,  1.7622e-02, -1.5101e-03, -2.6502e-03,  1.2701e-02,\n",
      "        -1.3778e-02,  1.2277e-02, -8.3413e-03, -8.2331e-05, -2.6151e-02,\n",
      "        -1.0561e-02,  3.0911e-03,  9.9139e-03, -1.8712e-02, -8.0739e-03,\n",
      "        -4.9640e-03, -1.2774e-02, -1.5474e-04,  4.0902e-03, -9.4142e-03,\n",
      "         1.1016e-03,  1.8561e-02,  2.3165e-02, -1.7743e-02, -4.5437e-03,\n",
      "        -6.6245e-03,  8.5496e-03,  1.5334e-03,  6.8465e-03,  6.8899e-03,\n",
      "         5.0997e-03, -1.0035e-02]), 'seq.2.weight': tensor([[-0.1638,  0.1058,  0.0391,  0.0761,  0.0822,  0.0457, -0.1000,  0.1082,\n",
      "         -0.0818, -0.0971, -0.0778, -0.0021, -0.0912, -0.0910,  0.0975,  0.0253,\n",
      "          0.0760, -0.0623, -0.1723,  0.1213,  0.1141, -0.0736,  0.1695, -0.0692,\n",
      "          0.1621, -0.0721, -0.1221,  0.1021, -0.0767, -0.1468, -0.1311,  0.1318]]), 'seq.2.bias': tensor([-0.1846])})\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Expected state_dict to be dict-like, got <class 'torch.Tensor'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m image_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m28\u001b[39m, \u001b[38;5;241m28\u001b[39m)\n\u001b[1;32m     25\u001b[0m inr \u001b[38;5;241m=\u001b[39m INR(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minr_kwargs)\n\u001b[0;32m---> 26\u001b[0m \u001b[43minr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m inr\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m make_coordinates(image_size, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:2140\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Copy parameters and buffers from :attr:`state_dict` into this module and its descendants.\u001b[39;00m\n\u001b[1;32m   2106\u001b[0m \n\u001b[1;32m   2107\u001b[0m \u001b[38;5;124;03mIf :attr:`strict` is ``True``, then\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2137\u001b[0m \u001b[38;5;124;03m    ``RuntimeError``.\u001b[39;00m\n\u001b[1;32m   2138\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(state_dict, Mapping):\n\u001b[0;32m-> 2140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected state_dict to be dict-like, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(state_dict)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2142\u001b[0m missing_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   2143\u001b[0m unexpected_keys: List[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mTypeError\u001b[0m: Expected state_dict to be dict-like, got <class 'torch.Tensor'>."
     ]
    }
   ],
   "source": [
    "from networks.INR import INR\n",
    "from typing import List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def make_coordinates(\n",
    "    shape: Union[Tuple[int], List[int]],\n",
    "    bs: int,\n",
    "    coord_range: Union[Tuple[int], List[int]] = (-1, 1),\n",
    ") -> torch.Tensor:\n",
    "    x_coordinates = np.linspace(coord_range[0], coord_range[1], shape[0])\n",
    "    y_coordinates = np.linspace(coord_range[0], coord_range[1], shape[1])\n",
    "    x_coordinates, y_coordinates = np.meshgrid(x_coordinates, y_coordinates)\n",
    "    x_coordinates = x_coordinates.flatten()\n",
    "    y_coordinates = y_coordinates.flatten()\n",
    "    coordinates = np.stack([x_coordinates, y_coordinates]).T\n",
    "    coordinates = np.repeat(coordinates[np.newaxis, ...], bs, axis=0)\n",
    "    return torch.from_numpy(coordinates).type(torch.float)\n",
    "\n",
    "\n",
    "inr_kwargs={\"n_layers\": 3, \"in_dim\": 2, \"up_scale\": 16}\n",
    "image_size=(28, 28)\n",
    "\n",
    "inr = INR(**inr_kwargs)\n",
    "print(train_dataset[0][0])\n",
    "inr.load_state_dict(train_dataset[0][0])\n",
    "inr.eval()\n",
    "input = make_coordinates(image_size, 1)\n",
    "with torch.no_grad():\n",
    "    image = inr(input)\n",
    "    image = image.view(*image_size, -1)\n",
    "    image = image.permute(2, 0, 1)\n",
    "\n",
    "print(image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict({'seq.0.weight': tensor([[-4.0755e-03,  3.0275e-02],\n",
      "        [ 3.7985e-02,  3.5304e-02],\n",
      "        [-6.5506e-02,  5.7733e-02],\n",
      "        [ 1.7344e-02, -1.8718e-02],\n",
      "        [ 3.0639e-02, -1.8703e-02],\n",
      "        [ 5.9275e-02, -5.5776e-03],\n",
      "        [-1.1590e-01,  1.9634e-02],\n",
      "        [ 2.6851e-02, -2.4524e-02],\n",
      "        [ 6.5062e-03,  1.1068e-01],\n",
      "        [-9.7189e-02,  1.0473e-01],\n",
      "        [ 6.1123e-02,  1.6021e-02],\n",
      "        [-4.6886e-02, -3.9856e-02],\n",
      "        [-7.6424e-02, -6.5537e-03],\n",
      "        [ 3.6053e-02,  6.2836e-04],\n",
      "        [ 5.1460e-02, -3.5410e-02],\n",
      "        [ 1.5411e-02, -3.3180e-03],\n",
      "        [ 2.2220e-01,  9.5588e-02],\n",
      "        [-2.1557e-02,  2.9739e-02],\n",
      "        [-1.1905e-02,  3.7337e-02],\n",
      "        [-6.2158e-03, -9.7376e-02],\n",
      "        [ 1.2494e-01,  5.1267e-02],\n",
      "        [-4.9377e-02, -9.5556e-02],\n",
      "        [-1.1631e-01, -1.1108e-01],\n",
      "        [-1.6368e-02,  2.2905e-02],\n",
      "        [ 1.8129e-02, -9.8052e-03],\n",
      "        [-3.9306e-03,  2.7790e-02],\n",
      "        [-1.2015e-02, -3.1052e-02],\n",
      "        [ 1.0156e-01,  4.2260e-02],\n",
      "        [-4.4942e-05, -1.6590e-02],\n",
      "        [ 3.3038e-02,  5.0072e-02],\n",
      "        [-3.3714e-02,  1.9098e-02],\n",
      "        [ 1.0767e-01, -7.4759e-02]]), 'seq.0.bias': tensor([ 0.0202,  0.0011, -0.0174,  0.0026, -0.0029, -0.0240,  0.0412, -0.0119,\n",
      "         0.0277,  0.0181, -0.0037,  0.0323, -0.0203, -0.0057, -0.0233,  0.0048,\n",
      "         0.0057, -0.0062,  0.0012,  0.0390, -0.0237, -0.0223, -0.0284,  0.0077,\n",
      "         0.0024, -0.0060,  0.0072,  0.0151, -0.0013, -0.0252,  0.0010,  0.0349]), 'seq.1.weight': tensor([[ 0.0076, -0.0029,  0.0167,  ...,  0.0203,  0.0202, -0.0392],\n",
      "        [ 0.0076, -0.0083, -0.0249,  ..., -0.0177,  0.0130,  0.0053],\n",
      "        [-0.0017,  0.0123, -0.0071,  ...,  0.0021,  0.0089, -0.0061],\n",
      "        ...,\n",
      "        [ 0.0037, -0.0129, -0.0056,  ..., -0.0045, -0.0081,  0.0026],\n",
      "        [ 0.0027,  0.0083,  0.0081,  ...,  0.0166,  0.0148,  0.0116],\n",
      "        [ 0.0010,  0.0076, -0.0036,  ..., -0.0120, -0.0082, -0.0130]]), 'seq.1.bias': tensor([ 2.5572e-03,  1.7622e-02, -1.5101e-03, -2.6502e-03,  1.2701e-02,\n",
      "        -1.3778e-02,  1.2277e-02, -8.3413e-03, -8.2331e-05, -2.6151e-02,\n",
      "        -1.0561e-02,  3.0911e-03,  9.9139e-03, -1.8712e-02, -8.0739e-03,\n",
      "        -4.9640e-03, -1.2774e-02, -1.5474e-04,  4.0902e-03, -9.4142e-03,\n",
      "         1.1016e-03,  1.8561e-02,  2.3165e-02, -1.7743e-02, -4.5437e-03,\n",
      "        -6.6245e-03,  8.5496e-03,  1.5334e-03,  6.8465e-03,  6.8899e-03,\n",
      "         5.0997e-03, -1.0035e-02]), 'seq.2.weight': tensor([[-0.1638,  0.1058,  0.0391,  0.0761,  0.0822,  0.0457, -0.1000,  0.1082,\n",
      "         -0.0818, -0.0971, -0.0778, -0.0021, -0.0912, -0.0910,  0.0975,  0.0253,\n",
      "          0.0760, -0.0623, -0.1723,  0.1213,  0.1141, -0.0736,  0.1695, -0.0692,\n",
      "          0.1621, -0.0721, -0.1221,  0.1021, -0.0767, -0.1468, -0.1311,  0.1318]]), 'seq.2.bias': tensor([-0.1846])})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0041,  0.0303,  0.0380,  ..., -0.1311,  0.1318, -0.1846])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(split: str):\n",
    "    # get batch from dataloader\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
