{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Enable autoreload of module\n",
            "%load_ext autoreload\n",
            "%autoreload 2"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/home/luca/.cache/pypoetry/virtualenvs/adl4cv-OvNqwVNf-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                  "  from .autonotebook import tqdm as notebook_tqdm\n",
                  "/home/luca/.cache/pypoetry/virtualenvs/adl4cv-OvNqwVNf-py3.10/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
                  "  return self.fget.__get__(instance, owner)()\n",
                  "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
                  "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mluca-fanselau\u001b[0m (\u001b[33madl-for-cv\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "True"
                  ]
               },
               "execution_count": 2,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import torch\n",
            "from vector_quantize_pytorch import VectorQuantize\n",
            "import os\n",
            "from data.neural_field_datasets import MnistNeFDataset, TokenTransform\n",
            "from training import training_nano_gpt\n",
            "\n",
            "from networks.nano_gpt import GPTConfig\n",
            "\n",
            "torch.cuda.is_available()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<All keys matched successfully>"
                  ]
               },
               "execution_count": 3,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "kwargs = {\n",
            "\"type\": \"pretrained\",\n",
            "\"fixed_label\": None,\n",
            "}\n",
            "\n",
            "dir_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
            "data_root = os.path.join(dir_path, \"adl4cv\")\n",
            "\n",
            "# load used vector quantizer\n",
            "vq_dicts = torch.load(os.path.join(data_root, \"models\", \"vqs\", \"vq_mnist_with_all_5_conditioned_n_501.pt\"))\n",
            "vq = VectorQuantize(**vq_dicts[\"vq_config\"])\n",
            "vq.load_state_dict(vq_dicts[\"state_dict\"])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "60000"
                  ]
               },
               "execution_count": 4,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "dataset = MnistNeFDataset(os.path.join(data_root, \"datasets\", \"mnist-nerfs\"), transform=TokenTransform(vq), **kwargs)\n",
            "len(dataset)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Config Training\n",
            "config = training_nano_gpt.Config()\n",
            "config.learning_rate=3e-3\n",
            "config.max_iters = 30000\n",
            "config.weight_decay=0.00\n",
            "config.decay_lr=True\n",
            "config.lr_decay_iters=config.max_iters\n",
            "config.warmup_iters=0.05*config.max_iters\n",
            "config.batch_size = 64\n",
            "config.gradient_accumulation_steps = 1\n",
            "config.init_from = \"scratch\"\n",
            "config.out_dir =\"models/token_transformer\"\n",
            "config.detailed_folder = \"training_sample_5\"\n",
            "config.eval_interval = 250\n",
            "config.metric_interval = 250\n",
            "\n",
            "model_config = GPTConfig(n_embd=180, block_size=len(dataset[0][0]), n_head=12, n_layer=12, vocab_size=vq_dicts[\"vq_config\"][\"codebook_size\"] + 11, dropout=0.0)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "2"
                  ]
               },
               "execution_count": 6,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "182%12"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "#early_stopping = training_nano_gpt.EarlyStopper(20)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'model_config = GPTConfig(\\n    n_embd=120, \\n    block_size=len(dataset[0][0]), \\n    n_head=12, n_layer=6, \\n    vocab_size=vq_dicts[\"vq_config\"][\"codebook_size\"] + 1,\\n    dropout=0.0\\n    )'"
                  ]
               },
               "execution_count": 8,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\"\"\"model_config = GPTConfig(\n",
            "    n_embd=120, \n",
            "    block_size=len(dataset[0][0]), \n",
            "    n_head=12, n_layer=6, \n",
            "    vocab_size=vq_dicts[\"vq_config\"][\"codebook_size\"] + 1,\n",
            "    dropout=0.0\n",
            "    )\"\"\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "cb_size = vq_dicts[\"vq_config\"][\"codebook_size\"]\n",
            "token_dict = {\n",
            "    \"SOS\": cb_size - 11,\n",
            "    \"0\": cb_size - 10,\n",
            "    \"1\": cb_size - 9,\n",
            "    \"2\": cb_size - 8,\n",
            "    \"3\": cb_size - 7,\n",
            "    \"4\": cb_size - 6,\n",
            "    \"5\": cb_size - 5,\n",
            "    \"6\": cb_size - 4,\n",
            "    \"7\": cb_size - 3,\n",
            "    \"8\": cb_size - 2,\n",
            "    \"9\": cb_size - 1\n",
            "}\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Where to put?\n",
            "# Maybe adjust dataset to be able to work with splitting data and then rewrite TokenTransform \n",
            "# to do the job combined with pytorch dataloader (get_batch == __call__ of Dataloader)\n",
            "\n",
            "def create_split_indices(n, train_ratio=0.9):\n",
            "    # Generate a random permutation of indices from 0 to n-1\n",
            "    shuffled_indices = torch.randperm(n)\n",
            "    # Determine the cut-off for training data\n",
            "    train_size = int(train_ratio * n)\n",
            "    # Split indices into training and validation sets\n",
            "    train_indices = shuffled_indices[:train_size]\n",
            "    val_indices = shuffled_indices[train_size:]\n",
            "    return train_indices, val_indices\n",
            "\n",
            "train_indices, val_indices = create_split_indices(len(dataset))\n",
            "\n",
            "def get_batch_lambda(config, dataset, model_config, split):\n",
            "    batch_size = config.batch_size\n",
            "    \n",
            "\n",
            "    # Select indices based on the split\n",
            "    if split == 'train':\n",
            "        # Randomly select batch_size indices from the train_indices\n",
            "        indices = train_indices[torch.randint(0, len(train_indices), (batch_size,))]\n",
            "    elif split == 'val':\n",
            "        # Randomly select batch_size indices from the val_indices\n",
            "        indices = val_indices[torch.randint(0, len(val_indices), (batch_size,))]\n",
            "    \n",
            "    \n",
            "    # Initialize lists to hold the sequences and labels\n",
            "    samples = []\n",
            "    labels = []\n",
            "\n",
            "    # Collect samples and labels\n",
            "    for idx in indices:\n",
            "        sample, label = dataset[idx]\n",
            "        start_tokens = torch.Tensor([token_dict[\"SOS\"], token_dict[str(label)]]).long()  # Start of sequence token\n",
            "        sample = torch.cat((start_tokens, sample), dim=0)\n",
            "        #start_tokens = torch.Tensor([0]).long()  # Start of sequence token\n",
            "        #sample = torch.cat((start_tokens, sample + 1), dim=0)\n",
            "        samples.append(sample)\n",
            "        labels.append(label)\n",
            "\n",
            "    # Prepare the sequences for model input\n",
            "    max_len = samples[0].size(0)\n",
            "    x = torch.zeros((batch_size, max_len - 1), dtype=torch.long)\n",
            "    y = torch.zeros((batch_size, max_len - 1), dtype=torch.long)\n",
            "    \n",
            "    for i, sample in enumerate(samples):\n",
            "        end_index = sample.size(0) - 1\n",
            "        x[i, :end_index] = sample[:-1]  # Exclude the last token for x\n",
            "        y[i, :end_index] = sample[1:]   # Exclude the first token for y\n",
            "\n",
            "    # Ensure x and y are the correct shape (batch_size, block_size) if needed:\n",
            "    # Here, we truncate to `block_size` if samples are longer than `block_size`.\n",
            "    x = x[:, :model_config.block_size]\n",
            "    y = y[:, :model_config.block_size]\n",
            "\n",
            "    # x and y have to be\n",
            "    x = x.to(config.device)\n",
            "    y = y.to(config.device)\n",
            "\n",
            "    return x, y\n",
            "\n",
            "create_get_batch = lambda config, dataset, model_config: lambda split: get_batch_lambda(config, dataset, model_config, split)\n",
            "get_batch = create_get_batch(config, dataset, model_config)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "30294000"
                  ]
               },
               "execution_count": 11,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(train_indices)*dataset[0][0].shape[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Initializing a new model from scratch\n",
                  "number of parameters: 4.74M\n",
                  "num decayed parameter tensors: 50, with 4,812,660 parameters\n",
                  "num non-decayed parameter tensors: 98, with 28,440 parameters\n",
                  "using fused AdamW: True\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "wandb version 0.17.2 is available!  To upgrade, please run:\n",
                     " $ pip install wandb --upgrade"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Tracking run with wandb version 0.16.6"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Run data is saved locally in <code>/home/luca/uni/master/adl4cv/wandb/run-20240620_091155-0h38fvyu</code>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Syncing run <strong><a href='https://wandb.ai/adl-for-cv/naive_token_transformer/runs/0h38fvyu' target=\"_blank\">run-2024-06-20-09-11-55</a></strong> to <a href='https://wandb.ai/adl-for-cv/naive_token_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     " View project at <a href='https://wandb.ai/adl-for-cv/naive_token_transformer' target=\"_blank\">https://wandb.ai/adl-for-cv/naive_token_transformer</a>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     " View run at <a href='https://wandb.ai/adl-for-cv/naive_token_transformer/runs/0h38fvyu' target=\"_blank\">https://wandb.ai/adl-for-cv/naive_token_transformer/runs/0h38fvyu</a>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "step 0: mnist classifier loss: 3.727780818939209, mnist accuracy: 0.140625\n",
                  "step 0: train loss 5.6081, val loss 5.6067\n",
                  "step 250: mnist classifier loss: 4.654127597808838, mnist accuracy: 0.109375\n",
                  "step 250: train loss 3.5970, val loss 3.6100\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 500: mnist classifier loss: 4.508016109466553, mnist accuracy: 0.078125\n",
                  "step 500: train loss 3.5287, val loss 3.5373\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 750: mnist classifier loss: 3.647284746170044, mnist accuracy: 0.203125\n",
                  "step 750: train loss 3.4239, val loss 3.4286\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 1000: mnist classifier loss: 3.3942887783050537, mnist accuracy: 0.21875\n",
                  "step 1000: train loss 3.3050, val loss 3.3171\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 1250: mnist classifier loss: 3.3658699989318848, mnist accuracy: 0.25\n",
                  "step 1250: train loss 3.1430, val loss 3.1436\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 1500: mnist classifier loss: 2.64371395111084, mnist accuracy: 0.390625\n",
                  "step 1500: train loss 2.9904, val loss 2.9798\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 1750: mnist classifier loss: 2.617076873779297, mnist accuracy: 0.390625\n",
                  "step 1750: train loss 2.8445, val loss 2.8549\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 2000: mnist classifier loss: 3.276730537414551, mnist accuracy: 0.203125\n",
                  "step 2000: train loss 2.7647, val loss 2.7603\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 2250: mnist classifier loss: 2.446359395980835, mnist accuracy: 0.421875\n",
                  "step 2250: train loss 2.7044, val loss 2.7173\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 2500: mnist classifier loss: 1.9749685525894165, mnist accuracy: 0.53125\n",
                  "step 2500: train loss 2.6532, val loss 2.6722\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 2750: mnist classifier loss: 2.0022549629211426, mnist accuracy: 0.4375\n",
                  "step 2750: train loss 2.6147, val loss 2.6345\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 3000: mnist classifier loss: 2.411813497543335, mnist accuracy: 0.390625\n",
                  "step 3000: train loss 2.5915, val loss 2.6104\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 3250: mnist classifier loss: 2.1506991386413574, mnist accuracy: 0.421875\n",
                  "step 3250: train loss 2.5876, val loss 2.5917\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 3500: mnist classifier loss: 1.7137409448623657, mnist accuracy: 0.5\n",
                  "step 3500: train loss 2.5546, val loss 2.5815\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 3750: mnist classifier loss: 1.6404303312301636, mnist accuracy: 0.53125\n",
                  "step 3750: train loss 2.5260, val loss 2.5527\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 4000: mnist classifier loss: 2.041231155395508, mnist accuracy: 0.5\n",
                  "step 4000: train loss 2.5146, val loss 2.5415\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 4250: mnist classifier loss: 1.4109158515930176, mnist accuracy: 0.609375\n",
                  "step 4250: train loss 2.5079, val loss 2.5246\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 4500: mnist classifier loss: 1.870388150215149, mnist accuracy: 0.46875\n",
                  "step 4500: train loss 2.5039, val loss 2.5226\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 4750: mnist classifier loss: 1.945981502532959, mnist accuracy: 0.53125\n",
                  "step 4750: train loss 2.5048, val loss 2.5107\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 5000: mnist classifier loss: 1.8540799617767334, mnist accuracy: 0.5\n",
                  "step 5000: train loss 2.4721, val loss 2.4923\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 5250: mnist classifier loss: 1.977817177772522, mnist accuracy: 0.40625\n",
                  "step 5250: train loss 2.4766, val loss 2.4821\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 5500: mnist classifier loss: 1.8745108842849731, mnist accuracy: 0.546875\n",
                  "step 5500: train loss 2.4548, val loss 2.4802\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 5750: mnist classifier loss: 1.7395482063293457, mnist accuracy: 0.578125\n",
                  "step 5750: train loss 2.4558, val loss 2.4723\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 6000: mnist classifier loss: 2.1158649921417236, mnist accuracy: 0.4375\n",
                  "step 6000: train loss 2.4363, val loss 2.4635\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 6250: mnist classifier loss: 1.259770393371582, mnist accuracy: 0.640625\n",
                  "step 6250: train loss 2.4377, val loss 2.4622\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 6500: mnist classifier loss: 1.6559422016143799, mnist accuracy: 0.625\n",
                  "step 6500: train loss 2.4384, val loss 2.4594\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 6750: mnist classifier loss: 2.277500629425049, mnist accuracy: 0.484375\n",
                  "step 6750: train loss 2.4358, val loss 2.4630\n",
                  "step 7000: mnist classifier loss: 1.9130157232284546, mnist accuracy: 0.546875\n",
                  "step 7000: train loss 2.4153, val loss 2.4516\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 7250: mnist classifier loss: 2.4727656841278076, mnist accuracy: 0.4375\n",
                  "step 7250: train loss 2.4569, val loss 2.4432\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 7500: mnist classifier loss: 1.903295874595642, mnist accuracy: 0.515625\n",
                  "step 7500: train loss 2.4119, val loss 2.4407\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 7750: mnist classifier loss: 1.6952693462371826, mnist accuracy: 0.546875\n",
                  "step 7750: train loss 2.4045, val loss 2.4483\n",
                  "step 8000: mnist classifier loss: 1.8702597618103027, mnist accuracy: 0.46875\n",
                  "step 8000: train loss 2.4108, val loss 2.4401\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 8250: mnist classifier loss: 1.980433464050293, mnist accuracy: 0.515625\n",
                  "step 8250: train loss 2.4008, val loss 2.4232\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 8500: mnist classifier loss: 1.8597561120986938, mnist accuracy: 0.546875\n",
                  "step 8500: train loss 2.4027, val loss 2.4240\n",
                  "step 8750: mnist classifier loss: 1.5862996578216553, mnist accuracy: 0.578125\n",
                  "step 8750: train loss 2.3834, val loss 2.4091\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 9000: mnist classifier loss: 1.9210262298583984, mnist accuracy: 0.5\n",
                  "step 9000: train loss 2.3864, val loss 2.4273\n",
                  "step 9250: mnist classifier loss: 1.8857921361923218, mnist accuracy: 0.5625\n",
                  "step 9250: train loss 2.3744, val loss 2.4076\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 9500: mnist classifier loss: 1.698899269104004, mnist accuracy: 0.5\n",
                  "step 9500: train loss 2.3661, val loss 2.4088\n",
                  "step 9750: mnist classifier loss: 1.7518032789230347, mnist accuracy: 0.53125\n",
                  "step 9750: train loss 2.3875, val loss 2.4142\n",
                  "step 10000: mnist classifier loss: 1.8092769384384155, mnist accuracy: 0.59375\n",
                  "step 10000: train loss 2.3947, val loss 2.4120\n",
                  "step 10250: mnist classifier loss: 1.4880863428115845, mnist accuracy: 0.65625\n",
                  "step 10250: train loss 2.3690, val loss 2.4032\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 10500: mnist classifier loss: 2.00014066696167, mnist accuracy: 0.46875\n",
                  "step 10500: train loss 2.3678, val loss 2.3901\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 10750: mnist classifier loss: 1.3520939350128174, mnist accuracy: 0.59375\n",
                  "step 10750: train loss 2.3332, val loss 2.4162\n",
                  "step 11000: mnist classifier loss: 1.944415807723999, mnist accuracy: 0.515625\n",
                  "step 11000: train loss 2.3619, val loss 2.4078\n",
                  "step 11250: mnist classifier loss: 1.5429296493530273, mnist accuracy: 0.625\n",
                  "step 11250: train loss 2.3632, val loss 2.3951\n",
                  "step 11500: mnist classifier loss: 1.602096676826477, mnist accuracy: 0.625\n",
                  "step 11500: train loss 2.3535, val loss 2.3969\n",
                  "step 11750: mnist classifier loss: 0.7787380814552307, mnist accuracy: 0.796875\n",
                  "step 11750: train loss 2.3487, val loss 2.3972\n",
                  "step 12000: mnist classifier loss: 1.971565842628479, mnist accuracy: 0.53125\n",
                  "step 12000: train loss 2.3532, val loss 2.3864\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 12250: mnist classifier loss: 1.4456982612609863, mnist accuracy: 0.65625\n",
                  "step 12250: train loss 2.3386, val loss 2.3918\n",
                  "step 12500: mnist classifier loss: 1.7663253545761108, mnist accuracy: 0.515625\n",
                  "step 12500: train loss 2.3434, val loss 2.3812\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 12750: mnist classifier loss: 1.7712631225585938, mnist accuracy: 0.515625\n",
                  "step 12750: train loss 2.3222, val loss 2.3775\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 13000: mnist classifier loss: 2.031186103820801, mnist accuracy: 0.46875\n",
                  "step 13000: train loss 2.3353, val loss 2.3789\n",
                  "step 13250: mnist classifier loss: 1.760107398033142, mnist accuracy: 0.5\n",
                  "step 13250: train loss 2.3370, val loss 2.3685\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 13500: mnist classifier loss: 2.032334327697754, mnist accuracy: 0.515625\n",
                  "step 13500: train loss 2.3406, val loss 2.3685\n",
                  "step 13750: mnist classifier loss: 1.6395747661590576, mnist accuracy: 0.5625\n",
                  "step 13750: train loss 2.3243, val loss 2.3632\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 14000: mnist classifier loss: 1.4346020221710205, mnist accuracy: 0.609375\n",
                  "step 14000: train loss 2.3174, val loss 2.3737\n",
                  "step 14250: mnist classifier loss: 1.827507734298706, mnist accuracy: 0.53125\n",
                  "step 14250: train loss 2.3126, val loss 2.3664\n",
                  "step 14500: mnist classifier loss: 1.3608150482177734, mnist accuracy: 0.65625\n",
                  "step 14500: train loss 2.3146, val loss 2.3698\n",
                  "step 14750: mnist classifier loss: 1.3062705993652344, mnist accuracy: 0.671875\n",
                  "step 14750: train loss 2.3063, val loss 2.3709\n",
                  "step 15000: mnist classifier loss: 1.8192720413208008, mnist accuracy: 0.546875\n",
                  "step 15000: train loss 2.2994, val loss 2.3616\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 15250: mnist classifier loss: 1.483839750289917, mnist accuracy: 0.5625\n",
                  "step 15250: train loss 2.3002, val loss 2.3706\n",
                  "step 15500: mnist classifier loss: 1.4116401672363281, mnist accuracy: 0.65625\n",
                  "step 15500: train loss 2.3035, val loss 2.3649\n",
                  "step 15750: mnist classifier loss: 1.244101881980896, mnist accuracy: 0.625\n",
                  "step 15750: train loss 2.2979, val loss 2.3620\n",
                  "step 16000: mnist classifier loss: 1.5796306133270264, mnist accuracy: 0.59375\n",
                  "step 16000: train loss 2.2972, val loss 2.3516\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 16250: mnist classifier loss: 1.960146427154541, mnist accuracy: 0.5\n",
                  "step 16250: train loss 2.2823, val loss 2.3624\n",
                  "step 16500: mnist classifier loss: 1.1145217418670654, mnist accuracy: 0.703125\n",
                  "step 16500: train loss 2.2951, val loss 2.3574\n",
                  "step 16750: mnist classifier loss: 1.1867272853851318, mnist accuracy: 0.640625\n",
                  "step 16750: train loss 2.2867, val loss 2.3479\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 17000: mnist classifier loss: 1.309119462966919, mnist accuracy: 0.671875\n",
                  "step 17000: train loss 2.2874, val loss 2.3569\n",
                  "step 17250: mnist classifier loss: 1.1062601804733276, mnist accuracy: 0.703125\n",
                  "step 17250: train loss 2.2658, val loss 2.3437\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 17500: mnist classifier loss: 1.4788904190063477, mnist accuracy: 0.671875\n",
                  "step 17500: train loss 2.2745, val loss 2.3311\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 17750: mnist classifier loss: 1.34481680393219, mnist accuracy: 0.625\n",
                  "step 17750: train loss 2.2682, val loss 2.3212\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 18000: mnist classifier loss: 1.4711999893188477, mnist accuracy: 0.625\n",
                  "step 18000: train loss 2.2634, val loss 2.3298\n",
                  "step 18250: mnist classifier loss: 1.1700575351715088, mnist accuracy: 0.703125\n",
                  "step 18250: train loss 2.2671, val loss 2.3290\n",
                  "step 18500: mnist classifier loss: 1.9965120553970337, mnist accuracy: 0.46875\n",
                  "step 18500: train loss 2.2645, val loss 2.3271\n",
                  "step 18750: mnist classifier loss: 1.4303686618804932, mnist accuracy: 0.609375\n",
                  "step 18750: train loss 2.2674, val loss 2.3325\n",
                  "step 19000: mnist classifier loss: 1.6006555557250977, mnist accuracy: 0.59375\n",
                  "step 19000: train loss 2.2617, val loss 2.3234\n",
                  "step 19250: mnist classifier loss: 1.1559829711914062, mnist accuracy: 0.609375\n",
                  "step 19250: train loss 2.2651, val loss 2.3234\n",
                  "step 19500: mnist classifier loss: 0.917044997215271, mnist accuracy: 0.65625\n",
                  "step 19500: train loss 2.2381, val loss 2.3242\n",
                  "step 19750: mnist classifier loss: 1.6122360229492188, mnist accuracy: 0.609375\n",
                  "step 19750: train loss 2.2408, val loss 2.3134\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 20000: mnist classifier loss: 1.102932333946228, mnist accuracy: 0.671875\n",
                  "step 20000: train loss 2.2316, val loss 2.3048\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 20250: mnist classifier loss: 0.8314031362533569, mnist accuracy: 0.78125\n",
                  "step 20250: train loss 2.2450, val loss 2.3090\n",
                  "step 20500: mnist classifier loss: 1.6667307615280151, mnist accuracy: 0.578125\n",
                  "step 20500: train loss 2.2344, val loss 2.3091\n",
                  "step 20750: mnist classifier loss: 1.2020105123519897, mnist accuracy: 0.671875\n",
                  "step 20750: train loss 2.2286, val loss 2.3188\n",
                  "step 21000: mnist classifier loss: 1.224164605140686, mnist accuracy: 0.703125\n",
                  "step 21000: train loss 2.2269, val loss 2.2957\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 21250: mnist classifier loss: 1.520804762840271, mnist accuracy: 0.609375\n",
                  "step 21250: train loss 2.2182, val loss 2.3088\n",
                  "step 21500: mnist classifier loss: 1.8665910959243774, mnist accuracy: 0.578125\n",
                  "step 21500: train loss 2.2175, val loss 2.3147\n",
                  "step 21750: mnist classifier loss: 1.2739157676696777, mnist accuracy: 0.65625\n",
                  "step 21750: train loss 2.2121, val loss 2.3293\n",
                  "step 22000: mnist classifier loss: 1.3811252117156982, mnist accuracy: 0.625\n",
                  "step 22000: train loss 2.1989, val loss 2.3115\n",
                  "step 22250: mnist classifier loss: 1.1378304958343506, mnist accuracy: 0.6875\n",
                  "step 22250: train loss 2.2190, val loss 2.3070\n",
                  "step 22500: mnist classifier loss: 1.0410685539245605, mnist accuracy: 0.71875\n",
                  "step 22500: train loss 2.1951, val loss 2.3033\n",
                  "step 22750: mnist classifier loss: 1.168995976448059, mnist accuracy: 0.6875\n",
                  "step 22750: train loss 2.2014, val loss 2.2961\n",
                  "step 23000: mnist classifier loss: 1.0515896081924438, mnist accuracy: 0.6875\n",
                  "step 23000: train loss 2.1920, val loss 2.3129\n",
                  "step 23250: mnist classifier loss: 1.1424978971481323, mnist accuracy: 0.65625\n",
                  "step 23250: train loss 2.2024, val loss 2.2884\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 23500: mnist classifier loss: 1.1907548904418945, mnist accuracy: 0.71875\n",
                  "step 23500: train loss 2.1839, val loss 2.3038\n",
                  "step 23750: mnist classifier loss: 1.1495610475540161, mnist accuracy: 0.71875\n",
                  "step 23750: train loss 2.1923, val loss 2.2846\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 24000: mnist classifier loss: 1.4550793170928955, mnist accuracy: 0.59375\n",
                  "step 24000: train loss 2.1929, val loss 2.3089\n",
                  "step 24250: mnist classifier loss: 1.2474256753921509, mnist accuracy: 0.6875\n",
                  "step 24250: train loss 2.1855, val loss 2.3119\n",
                  "step 24500: mnist classifier loss: 1.4213141202926636, mnist accuracy: 0.625\n",
                  "step 24500: train loss 2.1905, val loss 2.2729\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 24750: mnist classifier loss: 0.9524323344230652, mnist accuracy: 0.703125\n",
                  "step 24750: train loss 2.1685, val loss 2.2873\n",
                  "step 25000: mnist classifier loss: 1.4466718435287476, mnist accuracy: 0.59375\n",
                  "step 25000: train loss 2.1647, val loss 2.3107\n",
                  "step 25250: mnist classifier loss: 1.4716546535491943, mnist accuracy: 0.609375\n",
                  "step 25250: train loss 2.1709, val loss 2.2880\n",
                  "step 25500: mnist classifier loss: 1.159193992614746, mnist accuracy: 0.671875\n",
                  "step 25500: train loss 2.1748, val loss 2.3119\n",
                  "step 25750: mnist classifier loss: 1.2428474426269531, mnist accuracy: 0.65625\n",
                  "step 25750: train loss 2.1531, val loss 2.2976\n",
                  "step 26000: mnist classifier loss: 0.8089775443077087, mnist accuracy: 0.703125\n",
                  "step 26000: train loss 2.1699, val loss 2.3063\n",
                  "step 26250: mnist classifier loss: 0.9382674694061279, mnist accuracy: 0.71875\n",
                  "step 26250: train loss 2.1742, val loss 2.2896\n",
                  "step 26500: mnist classifier loss: 1.3969776630401611, mnist accuracy: 0.640625\n",
                  "step 26500: train loss 2.1621, val loss 2.2930\n",
                  "step 26750: mnist classifier loss: 0.9172593951225281, mnist accuracy: 0.75\n",
                  "step 26750: train loss 2.1660, val loss 2.2893\n",
                  "step 27000: mnist classifier loss: 1.021510362625122, mnist accuracy: 0.6875\n",
                  "step 27000: train loss 2.1565, val loss 2.2829\n",
                  "step 27250: mnist classifier loss: 0.9108036160469055, mnist accuracy: 0.734375\n",
                  "step 27250: train loss 2.1436, val loss 2.3067\n",
                  "step 27500: mnist classifier loss: 1.3721113204956055, mnist accuracy: 0.671875\n",
                  "step 27500: train loss 2.1682, val loss 2.2921\n",
                  "step 27750: mnist classifier loss: 1.6382975578308105, mnist accuracy: 0.546875\n",
                  "step 27750: train loss 2.1623, val loss 2.2845\n",
                  "step 28000: mnist classifier loss: 0.8259434700012207, mnist accuracy: 0.8125\n",
                  "step 28000: train loss 2.1567, val loss 2.3036\n",
                  "step 28250: mnist classifier loss: 1.2221101522445679, mnist accuracy: 0.6875\n",
                  "step 28250: train loss 2.1587, val loss 2.2806\n",
                  "step 28500: mnist classifier loss: 1.2176969051361084, mnist accuracy: 0.703125\n",
                  "step 28500: train loss 2.1432, val loss 2.2795\n",
                  "step 28750: mnist classifier loss: 1.024832010269165, mnist accuracy: 0.71875\n",
                  "step 28750: train loss 2.1462, val loss 2.2809\n",
                  "step 29000: mnist classifier loss: 0.9491742253303528, mnist accuracy: 0.734375\n",
                  "step 29000: train loss 2.1316, val loss 2.3063\n",
                  "step 29250: mnist classifier loss: 1.7126225233078003, mnist accuracy: 0.59375\n",
                  "step 29250: train loss 2.1524, val loss 2.2908\n",
                  "step 29500: mnist classifier loss: 1.042967438697815, mnist accuracy: 0.671875\n",
                  "step 29500: train loss 2.1467, val loss 2.2827\n",
                  "step 29750: mnist classifier loss: 0.9161139726638794, mnist accuracy: 0.6875\n",
                  "step 29750: train loss 2.1450, val loss 2.2887\n",
                  "step 30000: mnist classifier loss: 0.8264291286468506, mnist accuracy: 0.796875\n",
                  "step 30000: train loss 2.1330, val loss 2.2988\n"
               ]
            }
         ],
         "source": [
            "# Prepeare model parameters and train\n",
            "import wandb\n",
            "trained_model = training_nano_gpt.train(get_batch, config, model_config, vq, vq_dicts[\"vq_config\"], token_dict=token_dict)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 18,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "dict_keys(['model', 'optimizer', 'model_args', 'iter_num', 'best_val_loss', 'config', 'vq_state_dict', 'vq_config', 'token_dict'])\n",
                  "number of parameters: 5.62M\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "tensor([[False, False, False,  True, False, False,  True, False,  True, False,\n",
                     "          True, False,  True, False,  True, False,  True, False, False, False,\n",
                     "         False, False, False,  True, False,  True, False,  True, False, False,\n",
                     "         False, False, False,  True, False,  True, False,  True, False, False,\n",
                     "         False, False, False, False, False, False,  True, False, False, False,\n",
                     "         False, False, False, False, False, False, False, False, False, False,\n",
                     "         False, False, False, False, False, False, False, False, False, False,\n",
                     "         False, False,  True, False, False, False, False, False, False, False,\n",
                     "         False, False, False, False,  True, False,  True, False, False,  True,\n",
                     "         False, False, False, False, False, False, False, False, False,  True,\n",
                     "          True,  True, False, False, False, False,  True, False,  True, False,\n",
                     "         False, False, False, False, False, False,  True,  True,  True, False,\n",
                     "          True, False, False,  True,  True, False, False, False, False, False,\n",
                     "         False, False, False,  True, False, False,  True, False, False, False,\n",
                     "         False, False, False, False, False, False, False, False,  True,  True,\n",
                     "          True,  True, False, False,  True,  True,  True, False, False, False,\n",
                     "         False, False, False, False,  True, False, False, False, False, False,\n",
                     "         False, False, False, False,  True, False,  True,  True, False,  True,\n",
                     "         False, False, False,  True, False, False, False, False, False, False,\n",
                     "         False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
                     "         False, False,  True,  True,  True, False,  True, False,  True, False,\n",
                     "         False, False, False,  True, False, False, False, False,  True,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
                     "         False, False, False, False, False, False, False,  True,  True, False,\n",
                     "          True, False,  True, False, False, False, False,  True,  True, False,\n",
                     "          True, False,  True,  True,  True,  True, False,  True,  True,  True,\n",
                     "          True,  True,  True, False, False, False, False, False, False, False,\n",
                     "         False,  True, False, False, False,  True,  True, False, False,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
                     "          True,  True,  True,  True,  True, False, False, False, False, False,\n",
                     "         False, False,  True, False, False, False, False,  True,  True, False,\n",
                     "         False, False, False,  True, False, False, False, False, False, False,\n",
                     "         False, False, False,  True,  True, False, False,  True,  True, False,\n",
                     "         False, False, False, False, False, False, False, False, False,  True,\n",
                     "         False, False, False, False, False,  True,  True, False,  True, False,\n",
                     "         False, False, False, False, False,  True, False, False, False, False,\n",
                     "         False,  True, False, False, False,  True, False, False, False,  True,\n",
                     "         False,  True, False,  True,  True, False,  True,  True, False,  True,\n",
                     "          True,  True, False,  True,  True, False,  True,  True,  True,  True,\n",
                     "         False,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
                     "         False,  True, False, False, False,  True,  True,  True, False,  True,\n",
                     "         False,  True,  True, False, False, False, False,  True, False, False,\n",
                     "         False, False, False, False, False,  True, False, False, False, False,\n",
                     "          True, False, False, False, False, False, False, False, False, False,\n",
                     "         False,  True, False, False, False, False, False, False, False,  True,\n",
                     "         False, False, False,  True, False,  True, False,  True,  True, False,\n",
                     "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
                     "         False, False, False, False, False, False, False, False, False,  True,\n",
                     "         False, False,  True, False, False,  True, False, False, False,  True,\n",
                     "          True, False, False, False, False,  True, False, False, False, False,\n",
                     "          True, False, False, False, False, False,  True,  True,  True, False,\n",
                     "          True, False,  True, False, False, False,  True,  True,  True, False,\n",
                     "          True,  True, False,  True,  True,  True, False,  True,  True, False,\n",
                     "         False]], device='cuda:0')"
                  ]
               },
               "execution_count": 18,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import matplotlib.pyplot as plt\n",
            "import torch\n",
            "from networks.nano_gpt import GPT\n",
            "from utils import get_default_device\n",
            "\n",
            "model_dict = torch.load(\"./models/token_transformer/N_ALL_5M_LARGE_GOOD.pth\")\n",
            "# Configuration\n",
            "print(model_dict.keys())\n",
            "idx = 3\n",
            "\n",
            "device = get_default_device()\n",
            "model = GPT(model_dict[\"model_args\"])#model_dict\n",
            "model.to(device=device)\n",
            "model.load_state_dict(model_dict[\"model\"])\n",
            "model.eval()\n",
            "\n",
            "vq = VectorQuantize(**model_dict[\"vq_config\"])\n",
            "vq.load_state_dict(model_dict[\"vq_state_dict\"])\n",
            "vq.eval()\n",
            "\n",
            "dataset = MnistNeFDataset(os.path.join(data_root, \"datasets\", \"mnist-nerfs\"), transform=TokenTransform(vq), **kwargs)\n",
            "\n",
            "\n",
            "sample = dataset[0][0]\n",
            "X, Y = get_batch('val')\n",
            "X, Y = (X[0].unsqueeze(0), Y[0].unsqueeze(0))\n",
            "pred, _ = model(X, Y)\n",
            "# Sanity Check\n",
            "# Should be all true except first/second element\n",
            "pred.argmax(dim=-1)==Y\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 21,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "tensor(239, device='cuda:0')\n",
                  "tensor(235, device='cuda:0')\n",
                  "tensor(240, device='cuda:0')\n",
                  "tensor(244, device='cuda:0')\n"
               ]
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 2000x1000 with 4 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "from animation.util import backtransform_weights, reconstruct_image\n",
            "from networks.mlp_models import MLP3D\n",
            "\n",
            "ij_len = 2\n",
            "# Plotting the tensors as heatmaps in grayscale\n",
            "fig, axes = plt.subplots(ij_len, ij_len, figsize=(20, 10))\n",
            "\n",
            "\n",
            "kwargs = {\n",
            "\"type\": \"pretrained\",\n",
            "\"fixed_label\": None,\n",
            "}\n",
            "\n",
            "for i in range(ij_len):\n",
            "    for j in range(ij_len):\n",
            "\n",
            "        model.eval()\n",
            "        novel_tokens = model.generate(torch.Tensor([[token_dict[\"SOS\"]]]).long().to(device=\"cuda\"), dataset[0][0].shape[0] + 1, temperature=0.6, top_k=None)[:, 1:]\n",
            "\n",
            "        print(novel_tokens[0][0])\n",
            "        novel_tokens = novel_tokens[:, 1:].unsqueeze(-1).to(\"cpu\")\n",
            "                                                                                                                         \n",
            "\n",
            "        max_similarity = 0\n",
            "        \"\"\"\n",
            "        for data in dataset:\n",
            "            similarity = (data[0].to(device)==noxmarty/resnet-tiny-mnist\n",
            "                max_similarity = similarity\n",
            "        \"\"\"\n",
            "        #print(f\"Maximum Similarity of picture (i, j) {(i, j)}: {max_similarity}\")\n",
            "\n",
            "        novel_weights= vq.get_codes_from_indices((novel_tokens))\n",
            "\n",
            "        dataset_no_transform = MnistNeFDataset(os.path.join(data_root, \"datasets\", \"mnist-nerfs\"), **kwargs)\n",
            "        original_dict = dataset_no_transform[0][0]\n",
            "\n",
            "        reconstructed_dict = backtransform_weights(novel_weights, original_dict[\"state_dict\"])\n",
            "\n",
            "        mlp3d = MLP3D(**original_dict[\"model_config\"])\n",
            "        mlp3d.load_state_dict(reconstructed_dict)\n",
            "        reconstructed_tensor = reconstruct_image(mlp3d)\n",
            "\n",
            "        axes[i][j].imshow(reconstructed_tensor, cmap='gray', aspect='auto')\n",
            "\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 22,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "0.703125\n",
                  "1.2872538566589355\n"
               ]
            }
         ],
         "source": [
            "from training.mnist_classifier_score import compute_mnist_score\n",
            "acc, loss= compute_mnist_score(model, vq, \"cuda\", token_dict)\n",
            "\n",
            "print(acc)\n",
            "print(loss)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "9"
                  ]
               },
               "execution_count": 15,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "from random import randrange\n",
            "\n",
            "randrange(10)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "number of parameters: 5.62M\n",
                  "{'1': {'1': {'acc': 0.65625, 'loss': 1.4447228908538818}}}\n"
               ]
            }
         ],
         "source": [
            "import optimize_metrics\n",
            "\n",
            "optimize_metrics.main()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'1': {'1': {'acc': 0.65625, 'loss': 1.4447228908538818}}}"
                  ]
               },
               "execution_count": 6,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.14"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
