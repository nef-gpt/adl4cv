{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Enable autoreload of module\n",
            "%load_ext autoreload\n",
            "%autoreload 2"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/home/luca/.cache/pypoetry/virtualenvs/adl4cv-OvNqwVNf-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                  "  from .autonotebook import tqdm as notebook_tqdm\n",
                  "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
                  "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mluca-fanselau\u001b[0m (\u001b[33madl-for-cv\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "True"
                  ]
               },
               "execution_count": 2,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import torch\n",
            "from vector_quantize_pytorch import VectorQuantize\n",
            "import os\n",
            "from data.neural_field_datasets import MnistNeFDataset, TokenTransform\n",
            "from training import training_nano_gpt\n",
            "from networks.nano_gpt import GPTConfig\n",
            "\n",
            "torch.cuda.is_available()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [],
         "source": [
            "kwargs = {\n",
            "\"type\": \"pretrained\",\n",
            "\"fixed_label\": 5,\n",
            "}\n",
            "\n",
            "dir_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
            "data_root = os.path.join(dir_path, \"adl4cv\")\n",
            "\n",
            "# load used vector quantizer\n",
            "vq_dicts = torch.load(os.path.join(data_root, \"models\", \"vqs\", \"vq_mnist_vs_255.pt\"))\n",
            "vq = VectorQuantize(**vq_dicts[\"vq_config\"])\n",
            "vq.load_state_dict(vq_dicts[\"state_dict\"])\n",
            "\n",
            "dataset = MnistNeFDataset(os.path.join(data_root, \"datasets\", \"mnist-nerfs\"), transform=TokenTransform(vq), **kwargs)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Config Training\n",
            "config = training_nano_gpt.Config()\n",
            "config.learning_rate=5e-3\n",
            "config.max_iters = 20000\n",
            "config.weight_decay=0.1\n",
            "config.decay_lr=True\n",
            "config.lr_decay_iters=config.max_iters\n",
            "config.warmup_iters=0.05*config.max_iters\n",
            "config.batch_size = 32\n",
            "config.gradient_accumulation_steps = 1\n",
            "config.init_from = \"scratch\"\n",
            "config.out_dir =\"models/token_transformer\"\n",
            "config.detailed_folder = \"training_sample_5\"\n",
            "config.eval_interval = 250\n",
            "config.always_save_checkpoint = True\n",
            "\n",
            "\n",
            "model_config = GPTConfig(n_embd=204, block_size=len(dataset[0][0]), n_head=12, n_layer=8, vocab_size=vq_dicts[\"vq_config\"][\"codebook_size\"] + 1, dropout=0.25)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "0"
                  ]
               },
               "execution_count": 5,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "204%12"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'model_config = GPTConfig(\\n    n_embd=120, \\n    block_size=len(dataset[0][0]), \\n    n_head=12, n_layer=6, \\n    vocab_size=vq_dicts[\"vq_config\"][\"codebook_size\"] + 1,\\n    dropout=0.0\\n    )'"
                  ]
               },
               "execution_count": 6,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\"\"\"model_config = GPTConfig(\n",
            "    n_embd=120, \n",
            "    block_size=len(dataset[0][0]), \n",
            "    n_head=12, n_layer=6, \n",
            "    vocab_size=vq_dicts[\"vq_config\"][\"codebook_size\"] + 1,\n",
            "    dropout=0.0\n",
            "    )\"\"\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Where to put?\n",
            "# Maybe adjust dataset to be able to work with splitting data and then rewrite TokenTransform \n",
            "# to do the job combined with pytorch dataloader (get_batch == __call__ of Dataloader)\n",
            "\n",
            "def create_split_indices(n, train_ratio=0.9):\n",
            "    # Generate a random permutation of indices from 0 to n-1\n",
            "    shuffled_indices = torch.randperm(n)\n",
            "    # Determine the cut-off for training data\n",
            "    train_size = int(train_ratio * n)\n",
            "    # Split indices into training and validation sets\n",
            "    train_indices = shuffled_indices[:train_size]\n",
            "    val_indices = shuffled_indices[train_size:]\n",
            "    return train_indices, val_indices\n",
            "\n",
            "train_indices, val_indices = create_split_indices(len(dataset))\n",
            "\n",
            "def get_batch_lambda(n, config, dataset, model_config, split):\n",
            "    batch_size = config.batch_size\n",
            "    \n",
            "    # Generate random indices for batch selection\n",
            "    indices = torch.randint(0, n, (batch_size,))\n",
            "\n",
            "    # Select indices based on the split\n",
            "    if split == 'train':\n",
            "        # Randomly select batch_size indices from the train_indices\n",
            "        indices = train_indices[torch.randint(0, len(train_indices), (batch_size,))]\n",
            "    elif split == 'val':\n",
            "        # Randomly select batch_size indices from the val_indices\n",
            "        indices = val_indices[torch.randint(0, len(val_indices), (batch_size,))]\n",
            "    \n",
            "    \n",
            "    # Initialize lists to hold the sequences and labels\n",
            "    samples = []\n",
            "    labels = []\n",
            "\n",
            "    # Collect samples and labels\n",
            "    for idx in indices:\n",
            "        sample, label = dataset[idx]\n",
            "        sos_token = torch.Tensor([0]).long()  # Start of sequence token\n",
            "        sample = torch.cat((sos_token, sample), dim=0)\n",
            "        samples.append(sample)\n",
            "        labels.append(label)\n",
            "\n",
            "    # Prepare the sequences for model input\n",
            "    max_len = samples[0].size(0)\n",
            "    x = torch.zeros((batch_size, max_len - 1), dtype=torch.long)\n",
            "    y = torch.zeros((batch_size, max_len - 1), dtype=torch.long)\n",
            "    \n",
            "    for i, sample in enumerate(samples):\n",
            "        end_index = sample.size(0) - 1\n",
            "        x[i, :end_index] = sample[:-1]  # Exclude the last token for x\n",
            "        y[i, :end_index] = sample[1:]   # Exclude the first token for y\n",
            "\n",
            "    # Ensure x and y are the correct shape (batch_size, block_size) if needed:\n",
            "    # Here, we truncate to `block_size` if samples are longer than `block_size`.\n",
            "    x = x[:, :model_config.block_size]\n",
            "    y = y[:, :model_config.block_size]\n",
            "\n",
            "    # x and y have to be\n",
            "    x = x.to(config.device)\n",
            "    y = y.to(config.device)\n",
            "\n",
            "    return x, y\n",
            "\n",
            "create_get_batch = lambda n, config, dataset, model_config: lambda split: get_batch_lambda(n, config, dataset, model_config, split)\n",
            "get_batch = create_get_batch(1553, config, dataset, model_config)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "2736558"
                  ]
               },
               "execution_count": 8,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(train_indices)*dataset[0][0].shape[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Initializing a new model from scratch\n",
                  "number of parameters: 4.07M\n",
                  "num decayed parameter tensors: 34, with 4,161,804 parameters\n",
                  "num non-decayed parameter tensors: 66, with 21,624 parameters\n",
                  "using fused AdamW: True\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "wandb version 0.17.1 is available!  To upgrade, please run:\n",
                     " $ pip install wandb --upgrade"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Tracking run with wandb version 0.16.6"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Run data is saved locally in <code>/home/luca/uni/master/adl4cv/wandb/run-20240610_172355-dejk41sm</code>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Syncing run <strong><a href='https://wandb.ai/adl-for-cv/naive_token_transformer/runs/dejk41sm' target=\"_blank\">run-2024-06-10-17-23-55</a></strong> to <a href='https://wandb.ai/adl-for-cv/naive_token_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     " View project at <a href='https://wandb.ai/adl-for-cv/naive_token_transformer' target=\"_blank\">https://wandb.ai/adl-for-cv/naive_token_transformer</a>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     " View run at <a href='https://wandb.ai/adl-for-cv/naive_token_transformer/runs/dejk41sm' target=\"_blank\">https://wandb.ai/adl-for-cv/naive_token_transformer/runs/dejk41sm</a>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "step 0: train loss 5.6329, val loss 5.6346\n",
                  "step 250: train loss 3.8284, val loss 3.8343\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 500: train loss 3.5037, val loss 3.5004\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 750: train loss 3.4610, val loss 3.4578\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 1000: train loss 3.4452, val loss 3.4241\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 1250: train loss 3.3835, val loss 3.4113\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 1500: train loss 3.3390, val loss 3.3325\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 1750: train loss 3.2978, val loss 3.2998\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 2000: train loss 3.2538, val loss 3.2515\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 2250: train loss 3.1743, val loss 3.1988\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 2500: train loss 3.1522, val loss 3.1503\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 2750: train loss 3.0759, val loss 3.0993\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 3000: train loss 3.0507, val loss 3.0572\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 3250: train loss 2.9999, val loss 3.0156\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 3500: train loss 2.9555, val loss 2.9605\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 3750: train loss 2.9272, val loss 2.9245\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 4000: train loss 2.8824, val loss 2.9118\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 4250: train loss 2.8400, val loss 2.8633\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 4500: train loss 2.8409, val loss 2.8552\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 4750: train loss 2.7867, val loss 2.8214\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 5000: train loss 2.7903, val loss 2.7799\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 5250: train loss 2.7692, val loss 2.7852\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 5500: train loss 2.7555, val loss 2.7797\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 5750: train loss 2.7330, val loss 2.7554\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 6000: train loss 2.7232, val loss 2.7631\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 6250: train loss 2.7163, val loss 2.7549\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 6500: train loss 2.7149, val loss 2.7331\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 6750: train loss 2.6977, val loss 2.7159\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 7000: train loss 2.6884, val loss 2.7109\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 7250: train loss 2.6882, val loss 2.7314\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 7500: train loss 2.6868, val loss 2.6935\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 7750: train loss 2.6894, val loss 2.6987\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 8000: train loss 2.6750, val loss 2.6976\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 8250: train loss 2.6590, val loss 2.6721\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 8500: train loss 2.6717, val loss 2.6875\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 8750: train loss 2.6444, val loss 2.6745\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 9000: train loss 2.6424, val loss 2.6655\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 9250: train loss 2.6246, val loss 2.6908\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 9500: train loss 2.6393, val loss 2.6621\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 9750: train loss 2.6377, val loss 2.6592\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 10000: train loss 2.6407, val loss 2.6692\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 10250: train loss 2.6365, val loss 2.6617\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 10500: train loss 2.6264, val loss 2.6758\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 10750: train loss 2.6328, val loss 2.6541\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 11000: train loss 2.6207, val loss 2.6560\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 11250: train loss 2.6193, val loss 2.6584\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 11500: train loss 2.6194, val loss 2.6715\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 11750: train loss 2.6032, val loss 2.6485\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 12000: train loss 2.5998, val loss 2.6374\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 12250: train loss 2.6270, val loss 2.6438\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 12500: train loss 2.5943, val loss 2.6384\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 12750: train loss 2.6186, val loss 2.6538\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 13000: train loss 2.6027, val loss 2.6361\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 13250: train loss 2.5951, val loss 2.6202\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 13500: train loss 2.6029, val loss 2.6411\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 13750: train loss 2.6108, val loss 2.6144\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 14000: train loss 2.5871, val loss 2.6370\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 14250: train loss 2.5790, val loss 2.6356\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 14500: train loss 2.5894, val loss 2.6294\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 14750: train loss 2.5896, val loss 2.6271\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 15000: train loss 2.5848, val loss 2.6318\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 15250: train loss 2.5844, val loss 2.6166\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 15500: train loss 2.5894, val loss 2.6322\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 15750: train loss 2.5815, val loss 2.6324\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 16000: train loss 2.5725, val loss 2.6183\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 16250: train loss 2.5715, val loss 2.6149\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 16500: train loss 2.5526, val loss 2.6053\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 16750: train loss 2.5629, val loss 2.6266\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 17000: train loss 2.5521, val loss 2.6044\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 17250: train loss 2.5666, val loss 2.6130\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 17500: train loss 2.5635, val loss 2.6155\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 17750: train loss 2.5746, val loss 2.6000\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 18000: train loss 2.5615, val loss 2.6008\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 18250: train loss 2.5688, val loss 2.6077\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 18500: train loss 2.5721, val loss 2.5995\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 18750: train loss 2.5489, val loss 2.6083\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 19000: train loss 2.5679, val loss 2.6026\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 19250: train loss 2.5616, val loss 2.5889\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 19500: train loss 2.5639, val loss 2.5817\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 19750: train loss 2.5502, val loss 2.5811\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 20000: train loss 2.5386, val loss 2.5935\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 20250: train loss 2.5297, val loss 2.6095\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 20500: train loss 2.5479, val loss 2.5820\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 20750: train loss 2.5555, val loss 2.5893\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 21000: train loss 2.5509, val loss 2.5950\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 21250: train loss 2.5379, val loss 2.5929\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 21500: train loss 2.5231, val loss 2.5793\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 21750: train loss 2.5320, val loss 2.5911\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 22000: train loss 2.5483, val loss 2.5917\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 22250: train loss 2.5417, val loss 2.5942\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 22500: train loss 2.5207, val loss 2.6011\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 22750: train loss 2.5211, val loss 2.5856\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 23000: train loss 2.5418, val loss 2.5799\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 23250: train loss 2.5387, val loss 2.5956\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 23500: train loss 2.5530, val loss 2.5887\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 23750: train loss 2.5368, val loss 2.5797\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 24000: train loss 2.5235, val loss 2.5879\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 24250: train loss 2.5138, val loss 2.5802\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 24500: train loss 2.5265, val loss 2.5873\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 24750: train loss 2.5269, val loss 2.5776\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 25000: train loss 2.5377, val loss 2.5872\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 25250: train loss 2.5090, val loss 2.5960\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 25500: train loss 2.5432, val loss 2.5791\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 25750: train loss 2.5307, val loss 2.5580\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 26000: train loss 2.5214, val loss 2.5689\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 26250: train loss 2.4984, val loss 2.5733\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 26500: train loss 2.5183, val loss 2.5568\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 26750: train loss 2.5203, val loss 2.5671\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 27000: train loss 2.5190, val loss 2.5704\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 27250: train loss 2.5157, val loss 2.5600\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 27500: train loss 2.4989, val loss 2.5764\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 27750: train loss 2.5202, val loss 2.5711\n",
                  "saving checkpoint to models/token_transformer\n"
               ]
            },
            {
               "ename": "KeyboardInterrupt",
               "evalue": "",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn[9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Prepeare model parameters and train\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_nano_gpt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvq_dicts\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvq_config\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
                  "File \u001b[0;32m~/uni/master/adl4cv/training/training_nano_gpt.py:235\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(get_batch, config, model_config, vq, vq_config)\u001b[0m\n\u001b[1;32m    231\u001b[0m     loss \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    232\u001b[0m         loss \u001b[38;5;241m/\u001b[39m config\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n\u001b[1;32m    233\u001b[0m     )  \u001b[38;5;66;03m# scale the loss to account for gradient accumulation\u001b[39;00m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;66;03m# immediately async prefetch next batch while model is doing the forward pass on the GPU\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m X, Y \u001b[38;5;241m=\u001b[39m \u001b[43mget_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;66;03m# backward pass, with gradient scaling if training in fp16\u001b[39;00m\n\u001b[1;32m    237\u001b[0m scaler\u001b[38;5;241m.\u001b[39mscale(loss)\u001b[38;5;241m.\u001b[39mbackward()\n",
                  "Cell \u001b[0;32mIn[7], line 65\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(split)\u001b[0m\n\u001b[1;32m     61\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(config\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x, y\n\u001b[0;32m---> 65\u001b[0m create_get_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m n, config, dataset, model_config: \u001b[38;5;28;01mlambda\u001b[39;00m split: \u001b[43mget_batch_lambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m get_batch \u001b[38;5;241m=\u001b[39m create_get_batch(\u001b[38;5;241m1553\u001b[39m, config, dataset, model_config)\n",
                  "Cell \u001b[0;32mIn[7], line 38\u001b[0m, in \u001b[0;36mget_batch_lambda\u001b[0;34m(n, config, dataset, model_config, split)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# Collect samples and labels\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices:\n\u001b[0;32m---> 38\u001b[0m     sample, label \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     39\u001b[0m     sos_token \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor([\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mlong()  \u001b[38;5;66;03m# Start of sequence token\u001b[39;00m\n\u001b[1;32m     40\u001b[0m     sample \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((sos_token, sample), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
                  "File \u001b[0;32m~/uni/master/adl4cv/data/neural_field_datasets.py:125\u001b[0m, in \u001b[0;36mMnistNeFDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[0;32m--> 125\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     label \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype][\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtype]\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapping[idx]]\n\u001b[1;32m    134\u001b[0m     ][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfixed_label \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                  "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-OvNqwVNf-py3.10/lib/python3.10/site-packages/torch/serialization.py:1014\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1013\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1014\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1016\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1017\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1018\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1021\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1022\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
                  "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/adl4cv-OvNqwVNf-py3.10/lib/python3.10/site-packages/torch/serialization.py:1422\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1420\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1421\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1422\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1424\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1425\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1426\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1427\u001b[0m )\n",
                  "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
               ]
            }
         ],
         "source": [
            "# Prepeare model parameters and train\n",
            "trained_model = training_nano_gpt.train(get_batch, config, model_config, vq, vq_dicts[\"vq_config\"])\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "ename": "NameError",
               "evalue": "name 'model_dict' is not defined",
               "output_type": "error",
               "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                  "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel_dict\u001b[49m\u001b[38;5;241m.\u001b[39mkeys()\n",
                  "\u001b[0;31mNameError\u001b[0m: name 'model_dict' is not defined"
               ]
            }
         ],
         "source": [
            "model_dict.keys()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "number of parameters: 4.07M\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "tensor([[False, False, False,  True,  True, False, False,  True, False,  True,\n",
                     "         False,  True, False, False, False, False, False, False, False,  True,\n",
                     "         False, False, False, False, False, False,  True, False, False,  True,\n",
                     "         False, False, False, False, False,  True, False,  True, False, False,\n",
                     "         False, False, False, False,  True,  True, False, False, False,  True,\n",
                     "         False, False, False, False, False, False, False, False, False, False,\n",
                     "         False, False, False, False, False, False, False,  True,  True, False,\n",
                     "         False, False,  True, False, False, False, False, False, False, False,\n",
                     "         False, False, False, False, False,  True,  True, False, False, False,\n",
                     "         False,  True, False, False, False, False, False, False, False,  True,\n",
                     "          True, False, False, False, False, False, False, False, False, False,\n",
                     "         False, False, False, False, False,  True,  True, False, False,  True,\n",
                     "         False, False, False,  True, False, False,  True,  True, False, False,\n",
                     "          True,  True, False,  True, False, False,  True,  True, False, False,\n",
                     "         False, False,  True, False, False, False,  True, False,  True, False,\n",
                     "         False,  True, False,  True,  True, False, False, False, False, False,\n",
                     "         False,  True, False, False, False, False,  True, False,  True, False,\n",
                     "         False, False, False, False, False, False, False, False, False,  True,\n",
                     "         False, False, False,  True, False, False, False,  True, False, False,\n",
                     "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
                     "         False,  True, False, False, False, False, False, False, False,  True,\n",
                     "         False, False, False, False,  True,  True,  True, False,  True,  True,\n",
                     "         False, False, False, False, False, False, False,  True, False, False,\n",
                     "         False, False, False, False, False, False,  True, False, False, False,\n",
                     "         False,  True, False, False, False,  True,  True,  True,  True,  True,\n",
                     "         False, False,  True, False, False, False,  True,  True,  True, False,\n",
                     "          True, False, False, False, False, False, False, False, False, False,\n",
                     "         False, False,  True, False,  True, False, False, False,  True,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
                     "          True,  True,  True,  True, False, False, False, False, False, False,\n",
                     "         False, False, False, False, False, False,  True, False, False, False,\n",
                     "         False, False, False, False,  True, False, False, False, False, False,\n",
                     "         False, False,  True,  True, False, False, False,  True, False, False,\n",
                     "         False, False, False, False, False,  True, False, False,  True, False,\n",
                     "         False, False, False, False, False,  True, False, False, False, False,\n",
                     "          True,  True, False, False,  True, False,  True, False, False, False,\n",
                     "          True, False,  True, False, False, False, False,  True, False, False,\n",
                     "          True, False, False, False, False, False, False, False, False, False,\n",
                     "          True, False, False, False, False, False,  True, False, False, False,\n",
                     "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
                     "          True,  True,  True,  True, False,  True, False,  True, False, False,\n",
                     "         False,  True,  True, False,  True, False, False, False,  True,  True,\n",
                     "          True, False, False, False, False, False, False, False, False, False,\n",
                     "         False, False, False, False,  True, False,  True, False,  True,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
                     "          True,  True,  True,  True, False, False,  True, False, False, False,\n",
                     "         False, False,  True, False, False,  True,  True, False, False,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
                     "          True, False, False,  True, False, False, False, False,  True, False,\n",
                     "         False, False,  True, False, False, False,  True,  True, False,  True,\n",
                     "          True,  True, False, False,  True, False, False, False,  True,  True,\n",
                     "         False, False, False, False,  True,  True,  True,  True, False,  True,\n",
                     "         False,  True,  True,  True, False,  True, False, False, False, False,\n",
                     "         False, False,  True,  True, False,  True, False,  True, False, False,\n",
                     "          True]], device='cuda:0')"
                  ]
               },
               "execution_count": 10,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import matplotlib.pyplot as plt\n",
            "import torch\n",
            "from networks.nano_gpt import GPT\n",
            "from utils import get_default_device\n",
            "\n",
            "model_dict = torch.load(\"./models/token_transformer/ckpt.pt\")\n",
            "# Configuration\n",
            "idx = 3\n",
            "\n",
            "device = get_default_device()\n",
            "model = GPT(model_dict[\"model_args\"])\n",
            "model.to(device=device)\n",
            "model.load_state_dict(model_dict[\"model\"])\n",
            "model.eval()\n",
            "\n",
            "vq = VectorQuantize(**model_dict[\"vq_config\"])\n",
            "vq.load_state_dict(model_dict[\"vq_state_dict\"])\n",
            "vq.eval()\n",
            "\n",
            "dataset = MnistNeFDataset(os.path.join(data_root, \"datasets\", \"mnist-nerfs\"), transform=TokenTransform(vq), **kwargs)\n",
            "\n",
            "\n",
            "sample = dataset[0][0]\n",
            "X, Y = get_batch(\"\")\n",
            "X, Y = (X[0].unsqueeze(0), Y[0].unsqueeze(0))\n",
            "pred, _ = model(X, Y)\n",
            "# Sanity Check\n",
            "# Should be all true except first/second element\n",
            "pred.argmax(dim=-1)==Y\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "tensor([[[133],\n",
                     "         [152],\n",
                     "         [209],\n",
                     "         [122],\n",
                     "         [235],\n",
                     "         [255],\n",
                     "         [ 69],\n",
                     "         [130],\n",
                     "         [ 71],\n",
                     "         [152],\n",
                     "         [ 16],\n",
                     "         [148],\n",
                     "         [ 23],\n",
                     "         [139],\n",
                     "         [233],\n",
                     "         [ 49],\n",
                     "         [102],\n",
                     "         [241],\n",
                     "         [193],\n",
                     "         [203],\n",
                     "         [172],\n",
                     "         [114],\n",
                     "         [107],\n",
                     "         [178],\n",
                     "         [ 33],\n",
                     "         [167],\n",
                     "         [167],\n",
                     "         [  9],\n",
                     "         [ 72],\n",
                     "         [226],\n",
                     "         [ 62],\n",
                     "         [ 16],\n",
                     "         [178],\n",
                     "         [152],\n",
                     "         [209],\n",
                     "         [152],\n",
                     "         [118],\n",
                     "         [ 95],\n",
                     "         [ 32],\n",
                     "         [ 26],\n",
                     "         [ 82],\n",
                     "         [109],\n",
                     "         [ 14],\n",
                     "         [116],\n",
                     "         [215],\n",
                     "         [215],\n",
                     "         [209],\n",
                     "         [ 23],\n",
                     "         [ 24],\n",
                     "         [209],\n",
                     "         [ 14],\n",
                     "         [ 84],\n",
                     "         [245],\n",
                     "         [116],\n",
                     "         [200],\n",
                     "         [180],\n",
                     "         [153],\n",
                     "         [ 95],\n",
                     "         [131],\n",
                     "         [ 18],\n",
                     "         [ 49],\n",
                     "         [178],\n",
                     "         [105],\n",
                     "         [ 32],\n",
                     "         [181],\n",
                     "         [235],\n",
                     "         [188],\n",
                     "         [127],\n",
                     "         [ 71],\n",
                     "         [ 42],\n",
                     "         [181],\n",
                     "         [127],\n",
                     "         [127],\n",
                     "         [244],\n",
                     "         [127],\n",
                     "         [130],\n",
                     "         [ 83],\n",
                     "         [187],\n",
                     "         [ 78],\n",
                     "         [ 16],\n",
                     "         [ 62],\n",
                     "         [247],\n",
                     "         [130],\n",
                     "         [ 90],\n",
                     "         [ 80],\n",
                     "         [224],\n",
                     "         [112],\n",
                     "         [244],\n",
                     "         [  9],\n",
                     "         [249],\n",
                     "         [244],\n",
                     "         [220],\n",
                     "         [102],\n",
                     "         [247],\n",
                     "         [153],\n",
                     "         [110],\n",
                     "         [ 62],\n",
                     "         [ 39],\n",
                     "         [163],\n",
                     "         [208],\n",
                     "         [ 64],\n",
                     "         [ 21],\n",
                     "         [ 54],\n",
                     "         [199],\n",
                     "         [241],\n",
                     "         [ 39],\n",
                     "         [156],\n",
                     "         [133],\n",
                     "         [152],\n",
                     "         [107],\n",
                     "         [178],\n",
                     "         [ 49],\n",
                     "         [ 14],\n",
                     "         [170],\n",
                     "         [ 39],\n",
                     "         [ 16],\n",
                     "         [127],\n",
                     "         [216],\n",
                     "         [ 35],\n",
                     "         [187],\n",
                     "         [103],\n",
                     "         [ 89],\n",
                     "         [233],\n",
                     "         [139],\n",
                     "         [ 14],\n",
                     "         [244],\n",
                     "         [ 32],\n",
                     "         [ 94],\n",
                     "         [152],\n",
                     "         [ 82],\n",
                     "         [180],\n",
                     "         [ 14],\n",
                     "         [144],\n",
                     "         [ 21],\n",
                     "         [208],\n",
                     "         [ 16],\n",
                     "         [ 39],\n",
                     "         [218],\n",
                     "         [164],\n",
                     "         [ 32],\n",
                     "         [ 66],\n",
                     "         [116],\n",
                     "         [244],\n",
                     "         [110],\n",
                     "         [ 54],\n",
                     "         [244],\n",
                     "         [100],\n",
                     "         [127],\n",
                     "         [ 51],\n",
                     "         [ 31],\n",
                     "         [ 36],\n",
                     "         [ 95],\n",
                     "         [ 45],\n",
                     "         [ 94],\n",
                     "         [216],\n",
                     "         [156],\n",
                     "         [ 32],\n",
                     "         [ 21],\n",
                     "         [ 91],\n",
                     "         [ 35],\n",
                     "         [ 60],\n",
                     "         [ 82],\n",
                     "         [180],\n",
                     "         [ 62],\n",
                     "         [ 92],\n",
                     "         [ 92],\n",
                     "         [186],\n",
                     "         [153],\n",
                     "         [209],\n",
                     "         [127],\n",
                     "         [153],\n",
                     "         [ 83],\n",
                     "         [133],\n",
                     "         [139],\n",
                     "         [201],\n",
                     "         [233],\n",
                     "         [209],\n",
                     "         [ 32],\n",
                     "         [228],\n",
                     "         [245],\n",
                     "         [248],\n",
                     "         [152],\n",
                     "         [221],\n",
                     "         [157],\n",
                     "         [200],\n",
                     "         [ 24],\n",
                     "         [ 24],\n",
                     "         [198],\n",
                     "         [ 85],\n",
                     "         [ 72],\n",
                     "         [ 95],\n",
                     "         [102],\n",
                     "         [ 77],\n",
                     "         [121],\n",
                     "         [104],\n",
                     "         [ 47],\n",
                     "         [ 26],\n",
                     "         [ 56],\n",
                     "         [231],\n",
                     "         [ 56],\n",
                     "         [234],\n",
                     "         [  2],\n",
                     "         [ 11],\n",
                     "         [172],\n",
                     "         [205],\n",
                     "         [248],\n",
                     "         [217],\n",
                     "         [159],\n",
                     "         [ 66],\n",
                     "         [122],\n",
                     "         [244],\n",
                     "         [125],\n",
                     "         [211],\n",
                     "         [ 92],\n",
                     "         [224],\n",
                     "         [130],\n",
                     "         [218],\n",
                     "         [122],\n",
                     "         [ 52],\n",
                     "         [ 72],\n",
                     "         [ 14],\n",
                     "         [ 14],\n",
                     "         [233],\n",
                     "         [ 82],\n",
                     "         [218],\n",
                     "         [241],\n",
                     "         [208],\n",
                     "         [145],\n",
                     "         [136],\n",
                     "         [ 24],\n",
                     "         [ 39],\n",
                     "         [ 64],\n",
                     "         [245],\n",
                     "         [ 35],\n",
                     "         [ 21],\n",
                     "         [166],\n",
                     "         [ 14],\n",
                     "         [ 95],\n",
                     "         [ 82],\n",
                     "         [  9],\n",
                     "         [133],\n",
                     "         [167],\n",
                     "         [150],\n",
                     "         [127],\n",
                     "         [132],\n",
                     "         [132],\n",
                     "         [ 49],\n",
                     "         [218],\n",
                     "         [ 32],\n",
                     "         [ 26],\n",
                     "         [244],\n",
                     "         [216],\n",
                     "         [133],\n",
                     "         [102],\n",
                     "         [241],\n",
                     "         [ 44],\n",
                     "         [150],\n",
                     "         [ 71],\n",
                     "         [152],\n",
                     "         [ 36],\n",
                     "         [208],\n",
                     "         [ 64],\n",
                     "         [ 51],\n",
                     "         [138],\n",
                     "         [ 90],\n",
                     "         [201],\n",
                     "         [155],\n",
                     "         [ 39],\n",
                     "         [ 35],\n",
                     "         [ 80],\n",
                     "         [ 63],\n",
                     "         [ 78],\n",
                     "         [ 89],\n",
                     "         [ 23],\n",
                     "         [ 32],\n",
                     "         [ 39],\n",
                     "         [ 14],\n",
                     "         [116],\n",
                     "         [249],\n",
                     "         [ 45],\n",
                     "         [ 82],\n",
                     "         [153],\n",
                     "         [131],\n",
                     "         [ 82],\n",
                     "         [141],\n",
                     "         [ 90],\n",
                     "         [ 71],\n",
                     "         [201],\n",
                     "         [199],\n",
                     "         [162],\n",
                     "         [102],\n",
                     "         [ 57],\n",
                     "         [  1],\n",
                     "         [178],\n",
                     "         [  8],\n",
                     "         [250],\n",
                     "         [210],\n",
                     "         [  1],\n",
                     "         [ 32],\n",
                     "         [228],\n",
                     "         [179],\n",
                     "         [173],\n",
                     "         [178],\n",
                     "         [ 60],\n",
                     "         [ 16],\n",
                     "         [255],\n",
                     "         [209],\n",
                     "         [139],\n",
                     "         [133],\n",
                     "         [ 41],\n",
                     "         [ 40],\n",
                     "         [181],\n",
                     "         [ 49],\n",
                     "         [133],\n",
                     "         [133],\n",
                     "         [181],\n",
                     "         [ 76],\n",
                     "         [ 78],\n",
                     "         [ 83],\n",
                     "         [ 98],\n",
                     "         [ 53],\n",
                     "         [ 23],\n",
                     "         [177],\n",
                     "         [203],\n",
                     "         [ 18],\n",
                     "         [ 82],\n",
                     "         [193],\n",
                     "         [ 83],\n",
                     "         [200],\n",
                     "         [ 82],\n",
                     "         [133],\n",
                     "         [153],\n",
                     "         [ 81],\n",
                     "         [148],\n",
                     "         [ 54],\n",
                     "         [ 49],\n",
                     "         [241],\n",
                     "         [174],\n",
                     "         [ 44],\n",
                     "         [133],\n",
                     "         [102],\n",
                     "         [167],\n",
                     "         [ 71],\n",
                     "         [139],\n",
                     "         [203],\n",
                     "         [ 73],\n",
                     "         [ 16],\n",
                     "         [ 44],\n",
                     "         [ 60],\n",
                     "         [ 24],\n",
                     "         [178],\n",
                     "         [ 85],\n",
                     "         [ 49],\n",
                     "         [220],\n",
                     "         [167],\n",
                     "         [114],\n",
                     "         [248],\n",
                     "         [130],\n",
                     "         [ 66],\n",
                     "         [180],\n",
                     "         [102],\n",
                     "         [ 56],\n",
                     "         [199],\n",
                     "         [ 45],\n",
                     "         [245],\n",
                     "         [ 32],\n",
                     "         [180],\n",
                     "         [255],\n",
                     "         [224],\n",
                     "         [ 33],\n",
                     "         [161],\n",
                     "         [ 16],\n",
                     "         [158],\n",
                     "         [133],\n",
                     "         [139],\n",
                     "         [ 89],\n",
                     "         [ 14],\n",
                     "         [ 83],\n",
                     "         [183],\n",
                     "         [102],\n",
                     "         [253],\n",
                     "         [151],\n",
                     "         [245],\n",
                     "         [209],\n",
                     "         [ 91],\n",
                     "         [ 42],\n",
                     "         [164],\n",
                     "         [ 80],\n",
                     "         [103],\n",
                     "         [253],\n",
                     "         [ 97],\n",
                     "         [112],\n",
                     "         [116],\n",
                     "         [ 54],\n",
                     "         [ 48],\n",
                     "         [ 82],\n",
                     "         [162],\n",
                     "         [118],\n",
                     "         [166],\n",
                     "         [149],\n",
                     "         [ 58],\n",
                     "         [ 93],\n",
                     "         [ 90],\n",
                     "         [ 35],\n",
                     "         [179],\n",
                     "         [145],\n",
                     "         [ 81],\n",
                     "         [  9],\n",
                     "         [225],\n",
                     "         [ 42],\n",
                     "         [  3],\n",
                     "         [186],\n",
                     "         [178],\n",
                     "         [172],\n",
                     "         [217],\n",
                     "         [ 56],\n",
                     "         [153],\n",
                     "         [254],\n",
                     "         [249],\n",
                     "         [181],\n",
                     "         [129],\n",
                     "         [131],\n",
                     "         [ 24],\n",
                     "         [208],\n",
                     "         [218],\n",
                     "         [ 92],\n",
                     "         [ 80],\n",
                     "         [146],\n",
                     "         [188],\n",
                     "         [127],\n",
                     "         [136],\n",
                     "         [ 89],\n",
                     "         [241],\n",
                     "         [246],\n",
                     "         [216],\n",
                     "         [ 39],\n",
                     "         [244],\n",
                     "         [178],\n",
                     "         [133],\n",
                     "         [178],\n",
                     "         [203],\n",
                     "         [ 82],\n",
                     "         [ 16],\n",
                     "         [ 73],\n",
                     "         [ 50],\n",
                     "         [ 89],\n",
                     "         [  9],\n",
                     "         [ 37],\n",
                     "         [ 39],\n",
                     "         [ 57],\n",
                     "         [ 63],\n",
                     "         [ 51],\n",
                     "         [ 19],\n",
                     "         [231],\n",
                     "         [118],\n",
                     "         [221],\n",
                     "         [203],\n",
                     "         [208],\n",
                     "         [ 22],\n",
                     "         [ 60],\n",
                     "         [207],\n",
                     "         [ 82],\n",
                     "         [ 11],\n",
                     "         [ 38],\n",
                     "         [ 89],\n",
                     "         [247],\n",
                     "         [ 98],\n",
                     "         [241],\n",
                     "         [ 14],\n",
                     "         [148],\n",
                     "         [ 14],\n",
                     "         [178],\n",
                     "         [ 62],\n",
                     "         [170],\n",
                     "         [247],\n",
                     "         [ 80],\n",
                     "         [206],\n",
                     "         [ 14],\n",
                     "         [ 32],\n",
                     "         [247],\n",
                     "         [177],\n",
                     "         [ 88],\n",
                     "         [184],\n",
                     "         [ 12],\n",
                     "         [230],\n",
                     "         [ 45],\n",
                     "         [126],\n",
                     "         [132],\n",
                     "         [ 12],\n",
                     "         [ 10],\n",
                     "         [182],\n",
                     "         [  1],\n",
                     "         [  8],\n",
                     "         [191],\n",
                     "         [230],\n",
                     "         [ 17],\n",
                     "         [ 37],\n",
                     "         [170],\n",
                     "         [198],\n",
                     "         [170],\n",
                     "         [204],\n",
                     "         [110],\n",
                     "         [228],\n",
                     "         [220],\n",
                     "         [ 83],\n",
                     "         [ 14],\n",
                     "         [177],\n",
                     "         [ 39],\n",
                     "         [169],\n",
                     "         [ 16],\n",
                     "         [ 89],\n",
                     "         [198],\n",
                     "         [ 74],\n",
                     "         [170],\n",
                     "         [ 98],\n",
                     "         [233],\n",
                     "         [110],\n",
                     "         [ 85],\n",
                     "         [ 21],\n",
                     "         [198],\n",
                     "         [201],\n",
                     "         [244],\n",
                     "         [ 62],\n",
                     "         [215],\n",
                     "         [  9],\n",
                     "         [  9],\n",
                     "         [102],\n",
                     "         [181],\n",
                     "         [ 39],\n",
                     "         [173],\n",
                     "         [103],\n",
                     "         [192],\n",
                     "         [152],\n",
                     "         [ 32],\n",
                     "         [ 11],\n",
                     "         [  9],\n",
                     "         [ 93],\n",
                     "         [197],\n",
                     "         [221],\n",
                     "         [122],\n",
                     "         [129],\n",
                     "         [ 19],\n",
                     "         [125],\n",
                     "         [249],\n",
                     "         [112],\n",
                     "         [177],\n",
                     "         [ 16],\n",
                     "         [139],\n",
                     "         [ 30],\n",
                     "         [ 69],\n",
                     "         [204],\n",
                     "         [ 24],\n",
                     "         [170],\n",
                     "         [216],\n",
                     "         [209],\n",
                     "         [145],\n",
                     "         [107],\n",
                     "         [ 81],\n",
                     "         [142],\n",
                     "         [111],\n",
                     "         [200]]], device='cuda:0')"
                  ]
               },
               "execution_count": 11,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "pred.argmax(dim=-1).unsqueeze(-1)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Maximum Similarity of picture (i, j) (0, 0): 101\n",
                  "Maximum Similarity of picture (i, j) (0, 1): 103\n",
                  "Maximum Similarity of picture (i, j) (1, 0): 112\n",
                  "Maximum Similarity of picture (i, j) (1, 1): 148\n"
               ]
            },
            {
               "data": {
                  "image/png": "iVBORw0KGgoAAAANSUhEUgAABj0AAAMtCAYAAADE6bOsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABYc0lEQVR4nO3df3TV9Z0n/tclQEBNLkaEkPJD1KodRdxVQdbW0cIKuOsUdc/xR9vFjmu3DnpGaccOM1Vq2z107J4ea4dp/2llPFsca1dx67bOsag4noJu8VjXmZYRShccfqh0yIUAAZLP94/5NmMUawJ535u87+Nxzj3H3Nzk+cJPPnBfeebmUyqKoggAAAAAAIAhblitBwAAAAAAABgISg8AAAAAACALSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALw2s9wDt1d3fHtm3boqmpKUqlUq3HAQCA5IqiiD179kRbW1sMG+bnknh/9iYAAOpJf3amQVd6bNu2LSZNmlTrMQAAoOq2bt0aEydOrPUYDAH2JgAA6lFfdqZB92NkTU1NtR4BAABqwnNh+srXCgAA9agvz4MHXenhpdkAANQrz4XpK18rAADUo748D05WeixfvjxOOeWUGDVqVMycOTNefPHFVFEAAABDjp0JAAAGXpLS4+GHH47FixfH0qVL46WXXorp06fH3Llz44033kgRBwAAMKTYmQAAII1SURTFQH/SmTNnxoUXXhh/+Zd/GRER3d3dMWnSpLjtttviT//0T3/nx1YqlSiXywM9EgAADHrt7e3R3Nxc6zGogmPZmSLsTQAA1Ke+7EwD/kqPgwcPxvr162POnDn/GjJsWMyZMyfWrl37rsd3dnZGpVLpdQMAAMhVf3emCHsTAAD01YCXHm+99VZ0dXXF+PHje90/fvz42LFjx7sev2zZsiiXyz23SZMmDfRIAAAAg0Z/d6YIexMAAPRVsguZ99WSJUuivb2957Z169ZajwQAADCo2JsAAKBvhg/0Jxw7dmw0NDTEzp07e92/c+fOaG1tfdfjGxsbo7GxcaDHAAAAGJT6uzNF2JsAAKCvBvyVHiNHjozzzz8/Vq9e3XNfd3d3rF69OmbNmjXQcQAAAEOKnQkAANIZ8Fd6REQsXrw4Fi5cGBdccEHMmDEj7rvvvujo6IhPfepTKeIAAACGFDsTAACkkaT0uPbaa+PNN9+Mu+++O3bs2BHnnXdePPnkk++6UB8AAEA9sjMBAEAapaIoiloP8XaVSiXK5XKtxwAAgKprb2+P5ubmWo/BEGBvAgCgHvVlZxrwa3oAAAAAAADUgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIwvBaDwAAKZRKpeQZRVEkzwAAAACg77zSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyMLwWg8A1LeGhobkGRdccEHyjK9+9avJM84777zkGfv370+eERFx3HHHJc9ob29PnvGDH/wgecbjjz+ePGPdunXJMyIiDh48WJUcAACgvpRKpSwyqpXT3d2dPKMoiuQZ8F680gMAAAAAAMiC0gMAAAAAAMjCgJceX/ziF6NUKvW6nXXWWQMdAwAAMCTZmQAAIJ0k1/Q4++yz4yc/+cm/hgx36RAAAIDfsjMBAEAaSZ5ZDx8+PFpbW1N8agAAgCHPzgQAAGkkuabHa6+9Fm1tbXHqqafGxz/+8diyZct7PrazszMqlUqvGwAAQM76szNF2JsAAKCvBrz0mDlzZqxYsSKefPLJ+Na3vhWbN2+Oj3zkI7Fnz54jPn7ZsmVRLpd7bpMmTRrokQAAAAaN/u5MEfYmAADoq1JRFEXKgN27d8eUKVPi61//etx0003ven9nZ2d0dnb2vF2pVDyBhzrS0NCQPOOCCy5InvHVr341ecZ5552XPGP//v3JMyIijjvuuOQZ7e3tyTN+8IMfJM94/PHHk2esW7cueUZExMGDB6uSA0NZe3t7NDc313oMquz9dqYIexMA/C6lUimLjGrldHd3J89I/C1n6lhfdqbkV8sbM2ZMnHHGGbFx48Yjvr+xsTEaGxtTjwEAADAovd/OFGFvAgCAvkpyTY+327t3b2zatCkmTJiQOgoAAGDIsTMBAMDAGfDS43Of+1ysWbMmfv3rX8dPf/rTuOqqq6KhoSGuv/76gY4CAAAYcuxMAACQzoD/eqvXX389rr/++ti1a1ecfPLJ8eEPfzjWrVsXJ5988kBHAQAADDl2JgAASCf5hcz7q1KpRLlcrvUYMKhV4+LfEREnnnhi8oz/9t/+W/KMyZMnJ89YvXp18oz/8T/+R/KMf/7nf06eERFV+Z3k1bho9qFDh5JndHV1Jc8ABg8XMqev7E3AUDRixIjkGW1tbckzfu/3fi95RkTEpZdemjzj3/27f5c848wzz0yeMXr06OQZ1foWajUuZL5nz57kGdX4Psny5cuTZ6xbty55Bv3Tl50p+TU9AAAAAAAAqkHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZKFUFEVR6yHerlKpRLlcrvUYMKgNG1advnLkyJFVyUnt8OHDyTO6urqSZwyyv64BSKC9vT2am5trPQZDgL0J3l9DQ0NVcm6++ebkGV/+8peTZ4wZMyZ5RjV22VKplDwjp92sGn+W7u5uGf1QjWOSy3mya9eu5BnTpk1LntHe3p48Iyd92Zm80gMAAAAAAMiC0gMAAAAAAMiC0gMAAAAAAMiC0gMAAAAAAMiC0gMAAAAAAMiC0gMAAAAAAMiC0gMAAAAAAMiC0gMAAAAAAMiC0gMAAAAAAMiC0gMAAAAAAMiC0gMAAAAAAMiC0gMAAAAAAMjC8FoPAPRfd3d3VXIOHDhQlRwAAKC+nHDCCckz1q5dmzwjIuL3fu/3kmcMG5b+Z1aLokiesWPHjuQZL7/8cvKM5557LnlGRMTPf/7z5BlvvPFG8oyOjo7kGYcPH06eUY0/R0REV1dX8oyGhobkGdX43tWePXuSZ+zbty95BgPPKz0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsDK/1AFBNpVIpeUZRFMkzAAAAUmlpaUme8aMf/Sh5xplnnpk8I6I6e2ZXV1fyjFWrViXP+MM//MPkGdXYyQ8fPpw8o1o51cjwfRKg2rzSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyMLwWg8AvzVsWPoOrru7O3kGAABAKqVSKXnGySefnDyjXC4nz6jG/6uIiKIokmfs2bMnecbf//3fJ8+oxjHp7OxMnjF69OjkGRHV+T5JV1dX8oxqnCMAb+eVHgAAAAAAQBaUHgAAAAAAQBb6XXo899xzceWVV0ZbW1uUSqVYtWpVr/cXRRF33313TJgwIUaPHh1z5syJ1157baDmBQAAGNTsTAAAUDv9Lj06Ojpi+vTpsXz58iO+/9577437778/vv3tb8cLL7wQxx9/fMydOzcOHDhwzMMCAAAMdnYmAAConX5fyHz+/Pkxf/78I76vKIq477774gtf+EJ87GMfi4iIBx98MMaPHx+rVq2K66677timBQAAGOTsTAAAUDsDek2PzZs3x44dO2LOnDk995XL5Zg5c2asXbv2iB/T2dkZlUql1w0AACBHR7MzRdibAACgrwa09NixY0dERIwfP77X/ePHj+953zstW7YsyuVyz23SpEkDORIAAMCgcTQ7U4S9CQAA+mpAS4+jsWTJkmhvb++5bd26tdYjAQAADCr2JgAA6JsBLT1aW1sjImLnzp297t+5c2fP+96psbExmpube90AAABydDQ7U4S9CQAA+mpAS4+pU6dGa2trrF69uue+SqUSL7zwQsyaNWsgowAAAIYcOxMAAKQ1vL8fsHfv3ti4cWPP25s3b46XX345WlpaYvLkyXH77bfHV77ylfjgBz8YU6dOjbvuuiva2tpiwYIFAzk3AADAoGRnAgCA2ul36fGzn/0sLrvssp63Fy9eHBERCxcujBUrVsSdd94ZHR0d8elPfzp2794dH/7wh+PJJ5+MUaNGDdzUZKlUKtV6BKh71ToPq5FTjYzhw/v9z2i/dXV1Jc84fPhw8gyAemJnYqgbMWJEFhnDhlXnMqZFUSTPOP7445Nn/OEf/mHyjKuvvjp5xi9+8YvkGaecckryjIiI7u7u5BkPP/xw8ozvfOc7yTMqlUryDGDoKBXV+Ne5HyqVSpTL5VqPQQ00NDQkz6jGNw9hKFN69I/SAxho7e3trtVAn9ib6lc1nuOcffbZyTNWrVqVPGPq1KnJMyKqU3pU45vf77zWUAq7d+9OnqH06B+lBzDU9GVnqs6PPQAAAAAAACSm9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALIwvNYDMDSUSqXkGY2NjckzOjs7k2d0dXUlz2DwqcY5UhRFFhnVzEmtoaEhecYpp5ySPGPfvn3JMyIitm3bVpUcAODYHDp0KIuMajxHj4gYNiz9z5NW43nnxIkTs8g4++yzk2fk5IILLkie8ed//ufJM/7jf/yPyTPWrVuXPAMYGF7pAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZKFUFEVR6yHerlKpRLlcrvUYvEOpVEqe0dzcnDzjhBNOSJ7x5ptvJs84ePBg8gxgcBg5cmTyjA996EPJMyIidu3alTzjn/7pn5JnDLKnTmSmvb29Ks+JGPrsTaQ0YsSI5Bmf+tSnkmd84xvfSJ4REdHY2Jg8oxo7eS7PcXL5c1RLNb62qpFx+PDh5Bl/8Ad/kDwjIuLHP/5xVXJgqOrLzuSVHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBZKRVEUtR7i7SqVSpTL5VqPwTuUSqXkGS0tLckzbrzxxuQZDz74YPKMN998M3kGUD+q8Xd8RMTJJ5+cPOPAgQPJM/bs2ZM8Y5A9PaOK2tvbo7m5udZjMATYmxjqGhoakmecddZZyTMiIj75yU8mzxgxYkTyjH379iXPeOutt5JnDBuW/ud7q/W1NX78+OQZ1fheTFtbW/KMavy/Gj16dPKMiIh//+//ffKMZ555JnkGpNKXnckrPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCyUiqIoaj3E21UqlSiXy7Ueg3colUrJM5qbm5NnfOITn0iesWPHjuQZq1atSp4REdHV1VWVHICBMnHixOQZ+/btS57xm9/8JnkGg1N7e3tVnhMx9NmbAI6sGt+/qEZGRMTIkSOTZzQ2NibPOPHEE5NnzJgxI3nG9ddfnzwjIuKCCy5InjFt2rTkGbt3706eQX3qy87klR4AAAAAAEAWlB4AAAAAAEAW+l16PPfcc3HllVdGW1tblEqld/2anRtvvDFKpVKv27x58wZqXgAAgEHNzgQAALXT79Kjo6Mjpk+fHsuXL3/Px8ybNy+2b9/ec3vooYeOaUgAAIChws4EAAC1M7y/HzB//vyYP3/+73xMY2NjtLa2HvVQAAAAQ5WdCQAAaifJNT2effbZGDduXJx55plxyy23xK5du97zsZ2dnVGpVHrdAAAActafnSnC3gQAAH014KXHvHnz4sEHH4zVq1fHX/zFX8SaNWti/vz50dXVdcTHL1u2LMrlcs9t0qRJAz0SAADAoNHfnSnC3gQAAH3V719v9X6uu+66nv+eNm1anHvuuXHaaafFs88+G7Nnz37X45csWRKLFy/uebtSqXgCDwAAZKu/O1OEvQkAAPoqya+3ertTTz01xo4dGxs3bjzi+xsbG6O5ubnXDQAAoF68384UYW8CAIC+Sl56vP7667Fr166YMGFC6igAAIAhx84EAAADp9+/3mrv3r29fgJp8+bN8fLLL0dLS0u0tLTEPffcE9dcc020trbGpk2b4s4774zTTz895s6dO6CDAwAADEZ2JgAAqJ1+lx4/+9nP4rLLLut5+7e/V3bhwoXxrW99K1555ZX467/+69i9e3e0tbXF5ZdfHl/+8pejsbFx4KYGAAAYpOxMAABQO6WiKIpaD/F2lUolyuVyrcfgHUqlUvKME088MXnGTTfdlDzjv/yX/5I842Mf+1jyjIiIX/7yl1XJARgoI0eOTJ5xxRVXJM/4yU9+kjxj7969yTPov/b2dtdqoE/sTQAMFdX4nlJDQ0PyjLFjxybPiIj4+Mc/njzj7/7u75JnvPjii8kzqE992ZmSX9MDAAAAAACgGpQeAAAAAABAFpQeAAAAAABAFpQeAAAAAABAFpQeAAAAAABAFpQeAAAAAABAFpQeAAAAAABAFpQeAAAAAABAFpQeAAAAAABAFpQeAAAAAABAFpQeAAAAAABAFobXegCGhmHD0vdjkydPTp4xd+7c5BkTJkxInvH0008nz4iIOP3005Nn7Nu3L3kGUD9Gjx6dPOOrX/1q8owlS5Ykz3jssceSZwAAQFEUyTOq8X2r1tbW5BkRETNmzEiesWvXruQZL774YvIMeC9e6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRheK0HYGgYNix9PzZu3LjkGdOmTUuecfzxxyfPOO6445JnRET86le/Sp7xjW98I4uMffv2Jc+AoW7EiBHJM26//fbkGePHj0+esXnz5uQZAAAMbtX4Xszw4em/NViN75Ocd955yTOWLl2aPCOiOt+7+vKXv5w8A2rJKz0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsKD0AAAAAAIAsDK/1AAwNI0aMSJ4xefLk5BkHDhxInrF169bkGfv27UueERGxZcuW5Bn/+T//5+QZS5cuTZ5RjXNk7969yTO+/vWvJ8+IiPjWt76VPOM3v/lN8ozu7u7kGdXQ3NxclZzPfOYzyTM+97nPJc/4n//zfybP+PnPf548AwBqadiw9D+DWRRF8oxqyeXPUiqVkmc0NDQkzzjppJOSZ0REXHHFFckzbrjhhuQZZ5xxRvKMMWPGJM+olmr8/fiLX/wieQbUkld6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWSgVRVHUeoi3q1QqUS6Xaz0G7zB8+PDkGbNnz06e8eqrrybP2LFjR/KM7u7u5BkREdX462HUqFHJM772ta8lz/iv//W/Js8YMWJE8oxq6erqSp6xZ8+e5BnVON/379+fPKO1tTV5RkTEySefnDzju9/9bvKMW265JXlGtf6eZ/Bpb2+P5ubmWo/BEGBvYqirxnPbs88+O3lGRMT48eOTZ+zcuTN5RkNDQ/KMCy+8MHnGf/gP/yF5xr/9t/82eUZExIknnpg8I5c9sxrfv9i9e3fyjIiIq6++OnnG888/nzwDUunLzuSVHgAAAAAAQBaUHgAAAAAAQBb6VXosW7YsLrzwwmhqaopx48bFggULYsOGDb0ec+DAgVi0aFGcdNJJccIJJ8Q111xTlZdhAgAADAb2JgAAqJ1+lR5r1qyJRYsWxbp16+Kpp56KQ4cOxeWXXx4dHR09j7njjjvihz/8YTzyyCOxZs2a2LZtW1V+Fx0AAMBgYG8CAIDa6dfVqZ988sleb69YsSLGjRsX69evj0suuSTa29vjO9/5TqxcuTI++tGPRkTEAw88EB/60Idi3bp1cdFFFw3c5AAAAIOQvQkAAGrnmK7p0d7eHhERLS0tERGxfv36OHToUMyZM6fnMWeddVZMnjw51q5de8TP0dnZGZVKpdcNAAAgF/YmAAConqMuPbq7u+P222+Piy++OM4555yIiNixY0eMHDkyxowZ0+ux48ePjx07dhzx8yxbtizK5XLPbdKkSUc7EgAAwKBibwIAgOo66tJj0aJF8eqrr8bf/M3fHNMAS5Ysifb29p7b1q1bj+nzAQAADBb2JgAAqK5+XdPjt2699dZ44okn4rnnnouJEyf23N/a2hoHDx6M3bt39/qppZ07d0Zra+sRP1djY2M0NjYezRgAAACDlr0JAACqr1+v9CiKIm699dZ47LHH4umnn46pU6f2ev/5558fI0aMiNWrV/fct2HDhtiyZUvMmjVrYCYGAAAYxOxNAABQO/16pceiRYti5cqV8fjjj0dTU1PP75stl8sxevToKJfLcdNNN8XixYujpaUlmpub47bbbotZs2bFRRddlOQPAAAAMJjYmwAAoHZKRVEUfX5wqXTE+x944IG48cYbIyLiwIED8dnPfjYeeuih6OzsjLlz58Zf/dVfvefLtN+pUqlEuVzu60gAg8LJJ5+cPOPRRx9NnlGtny5taGioSk4ODh8+nDzjH/7hH5JnREQsXLgwecbPf/7z5Bn9eOoE/dbe3h7Nzc21HoNjZG+C9zds2FFfYrTPrr322uQZERH33ntv8oy3/yq8VEaPHp08473+fhxqcvlzVEtXV1fyjG9/+9vJMz772c8mz4iIOHjwYFVyYKjqy87Ur1d69GXJHzVqVCxfvjyWL1/en08NAACQBXsTAADUTvofrQAAAAAAAKgCpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJCF4bUeACAHb775ZvKMj3zkI8kzGhoakmdERHzgAx9InnHeeeclz9i/f3/yjP/zf/5P8oxKpZI8IyKiu7u7KjkAwOBXjecFP/rRj5JnRES88cYbyTNWrFiRPGP48PTfIiqVSskzqvHnKIoieUZEdfaNJ554InnGpz/96eQZe/bsSZ4BDB1e6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGShVBRFUesh3q5SqUS5XK71GAAAUHXt7e3R3Nxc6zEYAuxNwFA0YsSI5BmNjY3JMw4fPpw8IyLi4MGDyTO6u7uTZwAMpL7sTF7pAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZEHpAQAAAAAAZGF4rQcAAAAAIH+HDh3KIgOAwc0rPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCwoPQAAAAAAgCz0q/RYtmxZXHjhhdHU1BTjxo2LBQsWxIYNG3o95tJLL41SqdTr9pnPfGZAhwYAABis7E0AAFA7/So91qxZE4sWLYp169bFU089FYcOHYrLL788Ojo6ej3u5ptvju3bt/fc7r333gEdGgAAYLCyNwEAQO0M78+Dn3zyyV5vr1ixIsaNGxfr16+PSy65pOf+4447LlpbWwdmQgAAgCHE3gQAALVzTNf0aG9vj4iIlpaWXvd/73vfi7Fjx8Y555wTS5YsiX379r3n5+js7IxKpdLrBgAAkAt7EwAAVE+/Xunxdt3d3XH77bfHxRdfHOecc07P/TfccENMmTIl2tra4pVXXonPf/7zsWHDhnj00UeP+HmWLVsW99xzz9GOAQAAMGjZmwAAoLpKRVEUR/OBt9xyS/z4xz+O559/PiZOnPiej3v66adj9uzZsXHjxjjttNPe9f7Ozs7o7OzsebtSqcSkSZOOZiQAABjS2tvbo7m5udZjMIDsTQAAMHD6sjMd1Ss9br311njiiSfiueee+51P3CMiZs6cGRHxnk/eGxsbo7Gx8WjGAAAAGLTsTQAAUH39Kj2KoojbbrstHnvssXj22Wdj6tSp7/sxL7/8ckRETJgw4agGBAAAGErsTQAAUDv9Kj0WLVoUK1eujMcffzyamppix44dERFRLpdj9OjRsWnTpli5cmVcccUVcdJJJ8Urr7wSd9xxR1xyySVx7rnnJvkDAAAADCb2JgAAqJ1+XdOjVCod8f4HHnggbrzxxti6dWt84hOfiFdffTU6Ojpi0qRJcdVVV8UXvvCFPv9u4kqlEuVyua8jAQBANlzTIw/2JgAASKMvO9NRX8g8FU/eAQCoV0oP+sreBABAPerLzjSsSrMAAAAAAAAkpfQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyMOhKj6Ioaj0CAADUhOfC9JWvFQAA6lFfngcPutJjz549tR4BAABqwnNh+srXCgAA9agvz4NLxSD7EaHu7u7Ytm1bNDU1RalU6tPHVCqVmDRpUmzdujWam5sTT8hg4bjXJ8e9/jjm9clxr0/1fNyLoog9e/ZEW1tbDBs26H4uiUGov3tTPZ9f9cxxr0+Oe31y3OuT415/6vmY92dnGl6lmfps2LBhMXHixKP62Obm5ro72Dju9cpxrz+OeX1y3OtTvR73crlc6xEYQo52b6rX86veOe71yXGvT457fXLc60+9HvO+7kx+jAwAAAAAAMiC0gMAAAAAAMhCFqVHY2NjLF26NBobG2s9ClXkuNcnx73+OOb1yXGvT447pOP8qk+Oe31y3OuT416fHPf645j3zaC7kDkAAAAAAMDRyOKVHgAAAAAAAEoPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0O+9Fi+fHmccsopMWrUqJg5c2a8+OKLtR6JhL74xS9GqVTqdTvrrLNqPRYD7Lnnnosrr7wy2traolQqxapVq3q9vyiKuPvuu2PChAkxevTomDNnTrz22mu1GZYB837H/cYbb3zX+T9v3rzaDMuAWLZsWVx44YXR1NQU48aNiwULFsSGDRt6PebAgQOxaNGiOOmkk+KEE06Ia665Jnbu3FmjiRkIfTnul1566bvO98985jM1mhjyYG+qL/am+mBvqk/2pvpjb6pP9qZjM6RLj4cffjgWL14cS5cujZdeeimmT58ec+fOjTfeeKPWo5HQ2WefHdu3b++5Pf/887UeiQHW0dER06dPj+XLlx/x/ffee2/cf//98e1vfzteeOGFOP7442Pu3Llx4MCBKk/KQHq/4x4RMW/evF7n/0MPPVTFCRloa9asiUWLFsW6deviqaeeikOHDsXll18eHR0dPY+544474oc//GE88sgjsWbNmti2bVtcffXVNZyaY9WX4x4RcfPNN/c63++9994aTQxDn72pPtmb8mdvqk/2pvpjb6pP9qZjVAxhM2bMKBYtWtTzdldXV9HW1lYsW7ashlOR0tKlS4vp06fXegyqKCKKxx57rOft7u7uorW1tfja177Wc9/u3buLxsbG4qGHHqrBhKTwzuNeFEWxcOHC4mMf+1hN5qE63njjjSIiijVr1hRF8S/n9ogRI4pHHnmk5zG/+MUviogo1q5dW6sxGWDvPO5FURS///u/X/zxH/9x7YaCzNib6o+9qf7Ym+qTvak+2Zvqk72pf4bsKz0OHjwY69evjzlz5vTcN2zYsJgzZ06sXbu2hpOR2muvvRZtbW1x6qmnxsc//vHYsmVLrUeiijZv3hw7duzode6Xy+WYOXOmc78OPPvsszFu3Lg488wz45Zbboldu3bVeiQGUHt7e0REtLS0RETE+vXr49ChQ73O97POOismT57sfM/IO4/7b33ve9+LsWPHxjnnnBNLliyJffv21WI8GPLsTfXL3lTf7E31zd6UN3tTfbI39c/wWg9wtN56663o6uqK8ePH97p//Pjx8ctf/rJGU5HazJkzY8WKFXHmmWfG9u3b45577omPfOQj8eqrr0ZTU1Otx6MKduzYERFxxHP/t+8jT/PmzYurr746pk6dGps2bYo/+7M/i/nz58fatWujoaGh1uNxjLq7u+P222+Piy++OM4555yI+JfzfeTIkTFmzJhej3W+5+NIxz0i4oYbbogpU6ZEW1tbvPLKK/H5z38+NmzYEI8++mgNp4Whyd5Un+xN2Jvql70pb/am+mRv6r8hW3pQn+bPn9/z3+eee27MnDkzpkyZEt///vfjpptuquFkQGrXXXddz39PmzYtzj333DjttNPi2WefjdmzZ9dwMgbCokWL4tVXX/X7xuvMex33T3/60z3/PW3atJgwYULMnj07Nm3aFKeddlq1xwQYcuxNUL/sTXmzN9Une1P/DdlfbzV27NhoaGiInTt39rp/586d0draWqOpqLYxY8bEGWecERs3bqz1KFTJb89v5z6nnnpqjB071vmfgVtvvTWeeOKJeOaZZ2LixIk997e2tsbBgwdj9+7dvR7vfM/Dex33I5k5c2ZEhPMdjoK9iQh7Uz2yN/Fb9qZ82Jvqk73p6AzZ0mPkyJFx/vnnx+rVq3vu6+7ujtWrV8esWbNqOBnVtHfv3ti0aVNMmDCh1qNQJVOnTo3W1tZe536lUokXXnjBuV9nXn/99di1a5fzfwgriiJuvfXWeOyxx+Lpp5+OqVOn9nr/+eefHyNGjOh1vm/YsCG2bNnifB/C3u+4H8nLL78cEeF8h6NgbyLC3lSP7E38lr1p6LM31Sd707EZ0r/eavHixbFw4cK44IILYsaMGXHfffdFR0dHfOpTn6r1aCTyuc99Lq688sqYMmVKbNu2LZYuXRoNDQ1x/fXX13o0BtDevXt7tdKbN2+Ol19+OVpaWmLy5Mlx++23x1e+8pX44Ac/GFOnTo277ror2traYsGCBbUbmmP2u457S0tL3HPPPXHNNddEa2trbNq0Ke688844/fTTY+7cuTWcmmOxaNGiWLlyZTz++OPR1NTU8/tmy+VyjB49Osrlctx0002xePHiaGlpiebm5rjtttti1qxZcdFFF9V4eo7W+x33TZs2xcqVK+OKK66Ik046KV555ZW444474pJLLolzzz23xtPD0GRvqj/2pvpgb6pP9qb6Y2+qT/amY1QMcd/85jeLyZMnFyNHjixmzJhRrFu3rtYjkdC1115bTJgwoRg5cmTxgQ98oLj22muLjRs31nosBtgzzzxTRMS7bgsXLiyKoii6u7uLu+66qxg/fnzR2NhYzJ49u9iwYUNth+aY/a7jvm/fvuLyyy8vTj755GLEiBHFlClTiptvvrnYsWNHrcfmGBzpeEdE8cADD/Q8Zv/+/cUf/dEfFSeeeGJx3HHHFVdddVWxffv22g3NMXu/475ly5bikksuKVpaWorGxsbi9NNPL/7kT/6kaG9vr+3gMMTZm+qLvak+2Jvqk72p/tib6pO96diUiqIo0tQpAAAAAAAA1TNkr+kBAAAAAADwdkoPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC8NrPcA7dXd3x7Zt26KpqSlKpVKtxwEAgOSKoog9e/ZEW1tbDBvm55J4f/YmAADqSX92pkFXemzbti0mTZpU6zEAAKDqtm7dGhMnTqz1GAwB9iYAAOpRX3amQfdjZE1NTbUeAQAAasJzYfrK1woAAPWoL8+DB13p4aXZAADUK8+F6StfKwAA1KO+PA9OVnosX748TjnllBg1alTMnDkzXnzxxVRRAAAAQ46dCQAABl6S0uPhhx+OxYsXx9KlS+Oll16K6dOnx9y5c+ONN95IEQcAADCk2JkAACCNUlEUxUB/0pkzZ8aFF14Yf/mXfxkREd3d3TFp0qS47bbb4k//9E9/58dWKpUol8sDPRIAAAx67e3t0dzcXOsxqIJj2Zki7E0AANSnvuxMA/5Kj4MHD8b69etjzpw5/xoybFjMmTMn1q5d+67Hd3Z2RqVS6XUDAADIVX93pgh7EwAA9NWAlx5vvfVWdHV1xfjx43vdP378+NixY8e7Hr9s2bIol8s9t0mTJg30SAAAAINGf3emCHsTAAD0VbILmffVkiVLor29vee2devWWo8EAAAwqNibAACgb4YP9CccO3ZsNDQ0xM6dO3vdv3PnzmhtbX3X4xsbG6OxsXGgxwAAABiU+rszRdibAACgrwb8lR4jR46M888/P1avXt1zX3d3d6xevTpmzZo10HEAAABDip0JAADSGfBXekRELF68OBYuXBgXXHBBzJgxI+67777o6OiIT33qUyniAAAAhhQ7EwAApJGk9Lj22mvjzTffjLvvvjt27NgR5513Xjz55JPvulAfAABAPbIzAQBAGqWiKIpaD/F2lUolyuVyrccAAICqa29vj+bm5lqPwRBgbwIAoB71ZWca8Gt6AAAAAAAA1ILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyILSAwAAAAAAyMLwWg8AkINSqZQ8oyiK5Bn0TzWOe0NDQ/KM7u7u5BnVkst5ksufAwAAIJXhw9N/a7sa+3JOO/lg4ZUeAAAAAABAFpQeAAAAAABAFga89PjiF78YpVKp1+2ss84a6BgAAIAhyc4EAADpJPnFZ2effXb85Cc/+deQKvx+NQAAgKHCzgQAAGkkeWY9fPjwaG1tTfGpAQAAhjw7EwAApJHkmh6vvfZatLW1xamnnhof//jHY8uWLe/52M7OzqhUKr1uAAAAOevPzhRhbwIAgL4a8NJj5syZsWLFinjyySfjW9/6VmzevDk+8pGPxJ49e474+GXLlkW5XO65TZo0aaBHAgAAGDT6uzNF2JsAAKCvSkVRFCkDdu/eHVOmTImvf/3rcdNNN73r/Z2dndHZ2dnzdqVS8QQeGHJKpVLyjMR/XXMUqnHcGxoakmd0d3cnz6iWXM6TXP4c9F97e3s0NzfXegyq7P12pgh7EwDAO1XjmmjV2Jdz2smroS87U/KvjDFjxsQZZ5wRGzduPOL7Gxsbo7GxMfUYAAAAg9L77UwR9iYAAOirJNf0eLu9e/fGpk2bYsKECamjAAAAhhw7EwAADJwBLz0+97nPxZo1a+LXv/51/PSnP42rrroqGhoa4vrrrx/oKAAAgCHHzgQAAOkM+K+3ev311+P666+PXbt2xcknnxwf/vCHY926dXHyyScPdBQAAMCQY2cCAIB0kl/IvL8qlUqUy+VajwFHrRoXH502bVryjIiICy+8MHnGxRdfnDzj3HPPTZ4xatSo5BnVuLBVtf5JqMbFuUePHp084+0XlE2lo6MjeUa1NDU1Jc+oxjH5/ve/nzzj7/7u77LIqFQqyTNy40Lm9JW9CQD+ValUSp5Rredol112WfKMa6+9NnnGxIkTk2esWrUqecbDDz+cPOP1119PnpGTvuxMya/pAQAAAAAAUA1KDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAuloiiKWg/xdpVKJcrlcq3HIFMjR45MnvHlL385ecbkyZOTZ0REjBs3LnnG6aefnjyjpaUlecbo0aOTZzQ0NCTPYPAZZP9MD3rV+P+1b9++5BmbN29OnvGf/tN/Sp7xj//4j8kzctPe3h7Nzc21HoMhwN4EUDsjRoyoSs7555+fPOOmm25KnjFjxozkGSeccELyjE2bNiXPiIj427/92+QZ3/3ud5NnVCqV5Bnd3d3JM+zkg09fdiav9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALKg9AAAAAAAALIwvNYDQDV1d3cnz9i9e3fyjOuuuy55RkTEqFGjkmeMGDEii4yurq7kGdX4+u3s7EyeERFx4MCBLDLeeOON5BlvvfVW8oxq/L+KiDh8+HDyjPb29uQZ3//+95NnrF+/PnnGm2++mTwDYDBpaGhInjFmzJjkGdV4vrZv377kGdV4bsvgUyqVkmd897vfTZ7xyU9+MnlGtVRj33j00UeTZ6xcuTJ5xtq1a5NnRFTn+wuQO6/0AAAAAAAAsqD0AAAAAAAAsqD0AAAAAAAAsqD0AAAAAAAAsqD0AAAAAAAAsqD0AAAAAAAAsqD0AAAAAAAAsqD0AAAAAAAAsqD0AAAAAAAAsqD0AAAAAAAAsqD0AAAAAAAAsjC81gNANTU2NibPuOCCC5JnjB49OnlGRMTf//3fJ8/4/Oc/nzzjF7/4RfKMESNGJM/Yv39/8oyDBw8mz4iI6O7uTp5RFEXyjGoolUrJM4YNq87PQDQ0NCTPqMZx7+rqSp5RjXMEoN5U4+/vSqWSPGPy5MnJMz75yU8mz/hf/+t/Jc/4v//3/ybPqJbm5ubkGddff33yjK985SvJM6rx/6pau8YLL7yQPOP+++9PnvGDH/wgecbhw4eTZwBDh1d6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWVB6AAAAAAAAWRhe6wGgmk4++eTkGT//+c+TZ1QqleQZERH79+9PnlGNY7J+/frkGV1dXckzqE9FUSTPqNbXr/MEgNwdOnQoecavf/3r5Bn33ntv8ozOzs7kGdV4HhURMWLEiOQZU6ZMSZ5xyy23JM9oampKnlEqlZJnvPXWW8kzIiKuvvrq5BlvvPFG8ozu7u7kGQBv55UeAAAAAABAFpQeAAAAAABAFvpdejz33HNx5ZVXRltbW5RKpVi1alWv9xdFEXfffXdMmDAhRo8eHXPmzInXXnttoOYFAAAY1OxMAABQO/0uPTo6OmL69OmxfPnyI77/3nvvjfvvvz++/e1vxwsvvBDHH398zJ07Nw4cOHDMwwIAAAx2diYAAKidfl/IfP78+TF//vwjvq8oirjvvvviC1/4QnzsYx+LiIgHH3wwxo8fH6tWrYrrrrvu2KYFAAAY5OxMAABQOwN6TY/NmzfHjh07Ys6cOT33lcvlmDlzZqxdu/aIH9PZ2RmVSqXXDQAAIEdHszNF2JsAAKCvBrT02LFjR0REjB8/vtf948eP73nfOy1btizK5XLPbdKkSQM5EgAAwKBxNDtThL0JAAD6akBLj6OxZMmSaG9v77lt3bq11iMBAAAMKvYmAADomwEtPVpbWyMiYufOnb3u37lzZ8/73qmxsTGam5t73QAAAHJ0NDtThL0JAAD6akBLj6lTp0Zra2usXr26575KpRIvvPBCzJo1ayCjAAAAhhw7EwAApDW8vx+wd+/e2LhxY8/bmzdvjpdffjlaWlpi8uTJcfvtt8dXvvKV+OAHPxhTp06Nu+66K9ra2mLBggUDOTcAAMCgZGcCAIDa6Xfp8bOf/Swuu+yynrcXL14cERELFy6MFStWxJ133hkdHR3x6U9/Onbv3h0f/vCH48knn4xRo0YN3NRkqVQqJc/YtWtX8oyf/vSnyTOmTJmSPCMi4oILLkie8dJLLyXPOOGEE5JntLe3J88AAIYGOxMpdXV1Jc/Yt29f8oycdHZ2Js945ZVXkmcsXbo0ecb3vve95BkjRoxInlGN4xER8Zvf/CZ5Rnd3d/IMgGrrd+lx6aWXRlEU7/n+UqkUX/rSl+JLX/rSMQ0GAAAwFNmZAACgdgb0mh4AAAAAAAC1ovQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyMLzWA8BvNTU1Jc9YtWpV8ozp06cnzxgzZkzyjIiIUqmUPOP8889PnnH//fcnz/jGN76RPOPuu+9OnnHo0KHkGdVSja/foiiSZwAAwOHDh5NnPPXUU8kztm7dmjzj1FNPTZ7x1ltvJc+IiOju7q5KDkBuvNIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIwvBaDwC/tXfv3uQZX/rSl5JnfOMb30ieMXx4dU7dESNGJM84dOhQ8ox/+qd/Sp7R0dGRPOO0005LnrF///7kGRER7e3tyTOKokieUY2v32pkdHV1Jc+IiOju7q5KDgAA/VeN5+i333578oxVq1Ylz/jABz6QPCMiYtgwP6sMcDT87QkAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGRB6QEAAAAAAGShVBRFUesh3q5SqUS5XK71GHDUjj/++OQZEydOTJ4RETF+/PjkGb/5zW+SZ7z++uvJM9rb25NnDLK/ro9JqVSS0UcjR45MnnHcccclz4iI6OjoSJ7R2dmZPCOnc5HBp729PZqbm2s9BkOAvQkYikaPHp08Y9u2bckzKpVK8oyIiGnTpiXPqNafBWCg9GVn8koPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC0oPAAAAAAAgC8NrPQDkpqOjI3nGP/7jPybPiIh47bXXkmd0d3cnz2DwKYoii4xqOHDgQPKMrq6u5BkREa2trckztm/fnjzj0KFDyTMAAHLU2dmZPOP//b//lzzjlFNOSZ4REdHc3Jw8o1KpJM8AqDav9AAAAAAAALKg9AAAAAAAALLQ79LjueeeiyuvvDLa2tqiVCrFqlWrer3/xhtvjFKp1Os2b968gZoXAABgULMzAQBA7fS79Ojo6Ijp06fH8uXL3/Mx8+bNi+3bt/fcHnrooWMaEgAAYKiwMwEAQO30+0Lm8+fPj/nz5//OxzQ2NlblYqUAAACDjZ0JAABqJ8k1PZ599tkYN25cnHnmmXHLLbfErl273vOxnZ2dUalUet0AAABy1p+dKcLeBAAAfTXgpce8efPiwQcfjNWrV8df/MVfxJo1a2L+/PnR1dV1xMcvW7YsyuVyz23SpEkDPRIAAMCg0d+dKcLeBAAAfVUqiqI46g8uleKxxx6LBQsWvOdjfvWrX8Vpp50WP/nJT2L27Nnven9nZ2d0dnb2vF2pVDyBh/dRKpWyyenu7k6eAUNZNc7DESNGJM+IiKr8Gpft27cnzzh06FDyDOpXe3t7NDc313oMBtBA7EwR9iYgD8OGJfmFI7289NJLyTNOOeWU5BkREeecc07yjNdffz15BsBA6svOlPxfm1NPPTXGjh0bGzduPOL7Gxsbo7m5udcNAACgXrzfzhRhbwIAgL5KXnq8/vrrsWvXrpgwYULqKAAAgCHHzgQAAANneH8/YO/evb1+Amnz5s3x8ssvR0tLS7S0tMQ999wT11xzTbS2tsamTZvizjvvjNNPPz3mzp07oIMDAAAMRnYmAAConX6XHj/72c/isssu63l78eLFERGxcOHC+Na3vhWvvPJK/PVf/3Xs3r072tra4vLLL48vf/nL0djYOHBTAwAADFJ2JgAAqJ1+lx6XXnpp/K5rn//t3/7tMQ0EvL/fdQ4OxRzgvVXjPOzq6kqeERHR0dFRlRyAWrMzARxZNS5kvmfPnuQZxx13XPKMiOpcMN2FzIEcpf/XBgAAAAAAoAqUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaUHgAAAAAAQBaG13oAAKC2hg+vztOB448/PnlGpVJJnlEqlZJnFEWRPAMAoNqmTJmSPGPatGnJM6rxfDAioqmpqSo5ALnxSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALSg8AAAAAACALw2s9ANB/I0aMqErOyJEjk2fs378/eUZ3d3fyDEiloaEhecZZZ52VPCMi4rzzzkue8aMf/Sh5xj//8z8nz+jq6kqeURRF8gyAwWTYsPQ/8zd58uTkGaNGjUqecdxxxyXPGDduXPKMn//858kzIiJ2796dPGP06NHJM66++urkGUuXLk2e0dzcnDzjwIEDyTMiIv7hH/6hKjkAufFKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAtKDwAAAAAAIAvDaz0A5KapqSl5xhVXXJE8IyJi9uzZyTM2b96cPOPBBx9MnrFjx47kGd3d3ckziqJInpGTxsbG5Bk33HBD8ozbbrsteUZEdf5/jRkzJnnG//7f/zt5xuuvv54848CBA8kzAAaTkSNHJs9Yu3Zt8ozx48cnzyiVSskzqqEaz58jIvbt25c8oxrP00eNGpU8Y/jw9N+Gqsb/q29+85vJMyIitmzZUpUcgNx4pQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJAFpQcAAAAAAJCF4bUeAKpp2LD0Pd9JJ52UPOP0009PnhERMXHixOQZ/+bf/JvkGddcc03yjDfffDN5xjPPPJM8Y/PmzckzIiJOPPHE5BkLFixInjFt2rTkGS0tLckzRo4cmTwjIqJUKiXP+PM///PkGWeccUbyjG9+85vJMzZs2JA8oyiK5BkAfXXw4MHkGb/85S+TZ7S2tibPyEU19r+IiBNOOKEqOTk4cOBA8owvfvGLyTP++3//78kzIjyXAjhaXukBAAAAAABkQekBAAAAAABkoV+lx7Jly+LCCy+MpqamGDduXCxYsOBdvxrhwIEDsWjRojjppJPihBNOiGuuuSZ27tw5oEMDAAAMVvYmAAConX6VHmvWrIlFixbFunXr4qmnnopDhw7F5ZdfHh0dHT2PueOOO+KHP/xhPPLII7FmzZrYtm1bXH311QM+OAAAwGBkbwIAgNrp14XMn3zyyV5vr1ixIsaNGxfr16+PSy65JNrb2+M73/lOrFy5Mj760Y9GRMQDDzwQH/rQh2LdunVx0UUXDdzkAAAAg5C9CQAAaueYrunR3t4eEREtLS0REbF+/fo4dOhQzJkzp+cxZ511VkyePDnWrl17xM/R2dkZlUql1w0AACAX9iYAAKieoy49uru74/bbb4+LL744zjnnnIiI2LFjR4wcOTLGjBnT67Hjx4+PHTt2HPHzLFu2LMrlcs9t0qRJRzsSAADAoGJvAgCA6jrq0mPRokXx6quvxt/8zd8c0wBLliyJ9vb2ntvWrVuP6fMBAAAMFvYmAACorn5d0+O3br311njiiSfiueeei4kTJ/bc39raGgcPHozdu3f3+qmlnTt3Rmtr6xE/V2NjYzQ2Nh7NGAAAAIOWvQkAAKqvX6/0KIoibr311njsscfi6aefjqlTp/Z6//nnnx8jRoyI1atX99y3YcOG2LJlS8yaNWtgJgYAABjE7E0AAFA7/Xqlx6JFi2LlypXx+OOPR1NTU8/vmy2XyzF69Ogol8tx0003xeLFi6OlpSWam5vjtttui1mzZsVFF12U5A8AAAAwmNibAACgdkpFURR9fnCpdMT7H3jggbjxxhsjIuLAgQPx2c9+Nh566KHo7OyMuXPnxl/91V+958u036lSqUS5XO7rSDDonHjiickzLr300uQZERF/8Ad/kDzjox/9aPKMlpaW5BnV+HUT7/V38FBUjT+LjPp06NCh5Bm/+c1vkmfcfPPNyTOeeOKJ5Bn9eJrJ/6+9vT2am5trPQbHyN5ESjNmzEie8aMf/Sh5RjX+rqvW86jDhw8nz9i7d2/yjBUrViTPuPfee5NnvPnmm8kzAKidvuxM/XqlR18W11GjRsXy5ctj+fLl/fnUAAAAWbA3AQBA7fTrmh4AAAAAAACDldIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIgtIDAAAAAADIwvBaDwC56ezsTJ6xf//+5BkREU888UTyjJaWluQZF110UfKMxsbG5BkNDQ3JM6qlVCrVegQyNWxY+p/nWL9+ffKM559/PnlGURTJMwAYeC+++GLyjLFjxybPGDlyZPKMajwviKjOv6mHDh1KntHd3Z08AwCqwSs9AAAAAACALCg9AAAAAACALCg9AAAAAACALCg9AAAAAACALCg9AAAAAACALCg9AAAAAACALCg9AAAAAACALCg9AAAAAACALCg9AAAAAACALCg9AAAAAACALCg9AAAAAACALJSKoihqPcTbVSqVKJfLtR4DBrVSqVSVnIaGhuQZTU1NyTPOPvvs5Blz5sxJnnHZZZclzzj11FOTZ0REVf6eHz58ePKMapyL1fhnulp/pxw6dCh5xvLly5NnfP3rX0+esWvXruQZ3d3dyTPov/b29mhubq71GAwB9iYAAOpRX3Ymr/QAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyoPQAAAAAAACyUCqKoqj1EG9XqVSiXC7XegyAfhk2LH2HPHz48OQZo0ePTp4REdHU1JQ844QTTkie0dDQkDxj//79yTMOHDiQPCOiOsfkV7/6VfKMw4cPJ8+gfrW3t0dzc3Otx2AIsDcBAFCP+rIzeaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQheG1HgAgB93d3ckzDh48mEVGRER7e3tVcuibUqlUlZyGhobkGYcPH06eAQAAAAxeXukBAAAAAABkQekBAAAAAABkoV+lx7Jly+LCCy+MpqamGDduXCxYsCA2bNjQ6zGXXnpplEqlXrfPfOYzAzo0AADAYGVvAgCA2ulX6bFmzZpYtGhRrFu3Lp566qk4dOhQXH755dHR0dHrcTfffHNs376953bvvfcO6NAAAACDlb0JAABqp18XMn/yySd7vb1ixYoYN25crF+/Pi655JKe+4877rhobW0dmAkBAACGEHsTAADUzjFd06O9vT0iIlpaWnrd/73vfS/Gjh0b55xzTixZsiT27dv3np+js7MzKpVKrxsAAEAu7E0AAFA9/Xqlx9t1d3fH7bffHhdffHGcc845PfffcMMNMWXKlGhra4tXXnklPv/5z8eGDRvi0UcfPeLnWbZsWdxzzz1HOwYAAMCgZW8CAIDqKhVFURzNB95yyy3x4x//OJ5//vmYOHHiez7u6aefjtmzZ8fGjRvjtNNOe9f7Ozs7o7Ozs+ftSqUSkyZNOpqRAICjUCqVqpLT0NCQPOPw4cPJMyCl9vb2aG5urvUYDCB7EwAADJy+7ExH9UqPW2+9NZ544ol47rnnfucT94iImTNnRkS855P3xsbGaGxsPJoxAAAABi17EwAAVF+/So+iKOK2226Lxx57LJ599tmYOnXq+37Myy+/HBEREyZMOKoBAQAAhhJ7EwAA1E6/So9FixbFypUr4/HHH4+mpqbYsWNHRESUy+UYPXp0bNq0KVauXBlXXHFFnHTSSfHKK6/EHXfcEZdcckmce+65Sf4AAAAAg4m9CQAAaqdf1/R4r9/5/cADD8SNN94YW7dujU984hPx6quvRkdHR0yaNCmuuuqq+MIXvtDn301cqVSiXC73dSQA4Bi5pgcMHq7pkQd7EwAApNGXnemoL2SeiifvAADUK6UHfWVvAgCgHvVlZxpWpVkAAAAAAACSUnoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZUHoAAAAAAABZGHSlR1EUtR4BAABqwnNh+srXCgAA9agvz4MHXemxZ8+eWo8AAAA14bkwfeVrBQCAetSX58GlYpD9iFB3d3ds27YtmpqaolQq9eljKpVKTJo0KbZu3RrNzc2JJ2SwcNzrk+Nefxzz+uS416d6Pu5FUcSePXuira0thg0bdD+XxCDU372pns+veua41yfHvT457vXJca8/9XzM+7MzDa/STH02bNiwmDhx4lF9bHNzc90dbBz3euW41x/HvD457vWpXo97uVyu9QgMIUe7N9Xr+VXvHPf65LjXJ8e9Pjnu9adej3lfdyY/RgYAAAAAAGRB6QEAAAAAAGQhi9KjsbExli5dGo2NjbUehSpy3OuT415/HPP65LjXJ8cd0nF+1SfHvT457vXJca9Pjnv9ccz7ZtBdyBwAAAAAAOBoZPFKDwAAAAAAAKUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQhSFfeixfvjxOOeWUGDVqVMycOTNefPHFWo9EQl/84hejVCr1up111lm1HosB9txzz8WVV14ZbW1tUSqVYtWqVb3eXxRF3H333TFhwoQYPXp0zJkzJ1577bXaDMuAeb/jfuONN77r/J83b15thmVALFu2LC688MJoamqKcePGxYIFC2LDhg29HnPgwIFYtGhRnHTSSXHCCSfENddcEzt37qzRxAyEvhz3Sy+99F3n+2c+85kaTQx5sDfVF3tTfbA31Sd7U/2xN9Une9OxGdKlx8MPPxyLFy+OpUuXxksvvRTTp0+PuXPnxhtvvFHr0Ujo7LPPju3bt/fcnn/++VqPxADr6OiI6dOnx/Lly4/4/nvvvTfuv//++Pa3vx0vvPBCHH/88TF37tw4cOBAlSdlIL3fcY+ImDdvXq/z/6GHHqrihAy0NWvWxKJFi2LdunXx1FNPxaFDh+Lyyy+Pjo6Onsfccccd8cMf/jAeeeSRWLNmTWzbti2uvvrqGk7NserLcY+IuPnmm3ud7/fee2+NJoahz95Un+xN+bM31Sd7U/2xN9Une9MxKoawGTNmFIsWLep5u6urq2hrayuWLVtWw6lIaenSpcX06dNrPQZVFBHFY4891vN2d3d30draWnzta1/ruW/37t1FY2Nj8dBDD9VgQlJ453EviqJYuHBh8bGPfawm81Adb7zxRhERxZo1a4qi+Jdze8SIEcUjjzzS85hf/OIXRUQUa9eurdWYDLB3HveiKIrf//3fL/74j/+4dkNBZuxN9cfeVH/sTfXJ3lSf7E31yd7UP0P2lR4HDx6M9evXx5w5c3ruGzZsWMyZMyfWrl1bw8lI7bXXXou2trY49dRT4+Mf/3hs2bKl1iNRRZs3b44dO3b0OvfL5XLMnDnTuV8Hnn322Rg3blyceeaZccstt8SuXbtqPRIDqL29PSIiWlpaIiJi/fr1cejQoV7n+1lnnRWTJ092vmfkncf9t773ve/F2LFj45xzzoklS5bEvn37ajEeDHn2pvplb6pv9qb6Zm/Km72pPtmb+md4rQc4Wm+99VZ0dXXF+PHje90/fvz4+OUvf1mjqUht5syZsWLFijjzzDNj+/btcc8998RHPvKRePXVV6OpqanW41EFO3bsiIg44rn/2/eRp3nz5sXVV18dU6dOjU2bNsWf/dmfxfz582Pt2rXR0NBQ6/E4Rt3d3XH77bfHxRdfHOecc05E/Mv5PnLkyBgzZkyvxzrf83Gk4x4RccMNN8SUKVOira0tXnnllfj85z8fGzZsiEcffbSG08LQZG+qT/Ym7E31y96UN3tTfbI39d+QLT2oT/Pnz+/573PPPTdmzpwZU6ZMie9///tx00031XAyILXrrruu57+nTZsW5557bpx22mnx7LPPxuzZs2s4GQNh0aJF8eqrr/p943XmvY77pz/96Z7/njZtWkyYMCFmz54dmzZtitNOO63aYwIMOfYmqF/2przZm+qTvan/huyvtxo7dmw0NDTEzp07e92/c+fOaG1trdFUVNuYMWPijDPOiI0bN9Z6FKrkt+e3c59TTz01xo4d6/zPwK233hpPPPFEPPPMMzFx4sSe+1tbW+PgwYOxe/fuXo93vufhvY77kcycOTMiwvkOR8HeRIS9qR7Zm/gte1M+7E31yd50dIZs6TFy5Mg4//zzY/Xq1T33dXd3x+rVq2PWrFk1nIxq2rt3b2zatCkmTJhQ61GokqlTp0Zra2uvc79SqcQLL7zg3K8zr7/+euzatcv5P4QVRRG33nprPPbYY/H000/H1KlTe73//PPPjxEjRvQ63zds2BBbtmxxvg9h73fcj+Tll1+OiHC+w1GwNxFhb6pH9iZ+y9409Nmb6pO96dgM6V9vtXjx4li4cGFccMEFMWPGjLjvvvuio6MjPvWpT9V6NBL53Oc+F1deeWVMmTIltm3bFkuXLo2Ghoa4/vrraz0aA2jv3r29WunNmzfHyy+/HC0tLTF58uS4/fbb4ytf+Up88IMfjKlTp8Zdd90VbW1tsWDBgtoNzTH7Xce9paUl7rnnnrjmmmuitbU1Nm3aFHfeeWecfvrpMXfu3BpOzbFYtGhRrFy5Mh5//PFoamrq+X2z5XI5Ro8eHeVyOW666aZYvHhxtLS0RHNzc9x2220xa9asuOiii2o8PUfr/Y77pk2bYuXKlXHFFVfESSedFK+88krccccdcckll8S5555b4+lhaLI31R97U32wN9Une1P9sTfVJ3vTMSqGuG9+85vF5MmTi5EjRxYzZswo1q1bV+uRSOjaa68tJkyYUIwcObL4wAc+UFx77bXFxo0baz0WA+yZZ54pIuJdt4ULFxZFURTd3d3FXXfdVYwfP75obGwsZs+eXWzYsKG2Q3PMftdx37dvX3H55ZcXJ598cjFixIhiypQpxc0331zs2LGj1mNzDI50vCOieOCBB3oes3///uKP/uiPihNPPLE47rjjiquuuqrYvn177YbmmL3fcd+yZUtxySWXFC0tLUVjY2Nx+umnF3/yJ39StLe313ZwGOLsTfXF3lQf7E31yd5Uf+xN9cnedGxKRVEUaeoUAAAAAACA6hmy1/QAAAAAAAB4O6UHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQBaUHAAAAAACQhf8Po7pA1VR2pBoAAAAASUVORK5CYII=",
                  "text/plain": [
                     "<Figure size 2000x1000 with 4 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "from animation.util import backtransform_weights, reconstruct_image\n",
            "from networks.mlp_models import MLP3D\n",
            "\n",
            "ij_len = 2\n",
            "# Plotting the tensors as heatmaps in grayscale\n",
            "fig, axes = plt.subplots(ij_len, ij_len, figsize=(20, 10))\n",
            "\n",
            "SOS = torch.Tensor([[0]]).long().to(device)\n",
            "\n",
            "kwargs = {\n",
            "\"type\": \"pretrained\",\n",
            "\"fixed_label\": 5,\n",
            "}\n",
            "\n",
            "for i in range(ij_len):\n",
            "    for j in range(ij_len):\n",
            "\n",
            "        model.eval()\n",
            "        novel_tokens = model.generate(SOS, dataset[0][0].shape[0], temperature=1.0, top_k=None)[:, 1:].unsqueeze(-1).to(\"cpu\")\n",
            "\n",
            "        max_similarity = 0\n",
            "\n",
            "        for data in dataset:\n",
            "            similarity = (data[0].to(device)==novel_tokens.squeeze(-1).squeeze(0).to(device)).int().sum()\n",
            "            if similarity > max_similarity:\n",
            "                max_similarity = similarity\n",
            "\n",
            "        print(f\"Maximum Similarity of picture (i, j) {(i, j)}: {max_similarity}\")\n",
            "\n",
            "        novel_weights= vq.get_codes_from_indices((novel_tokens-1))\n",
            "\n",
            "        dataset_no_transform = MnistNeFDataset(os.path.join(data_root, \"datasets\", \"mnist-nerfs\"), **kwargs)\n",
            "        original_dict = dataset_no_transform[0][0]\n",
            "\n",
            "        reconstructed_dict = backtransform_weights(novel_weights, original_dict[\"state_dict\"])\n",
            "\n",
            "        mlp3d = MLP3D(**original_dict[\"model_config\"])\n",
            "        mlp3d.load_state_dict(reconstructed_dict)\n",
            "        reconstructed_tensor = reconstruct_image(mlp3d)\n",
            "\n",
            "        axes[i][j].imshow(reconstructed_tensor, cmap='gray', aspect='auto')\n",
            "\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.14"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
