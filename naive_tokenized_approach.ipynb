{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 1,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Enable autoreload of module\n",
            "%load_ext autoreload\n",
            "%autoreload 2"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 2,
         "metadata": {},
         "outputs": [
            {
               "name": "stderr",
               "output_type": "stream",
               "text": [
                  "/home/luca/.cache/pypoetry/virtualenvs/adl4cv-OvNqwVNf-py3.10/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
                  "  from .autonotebook import tqdm as notebook_tqdm\n",
                  "/home/luca/.cache/pypoetry/virtualenvs/adl4cv-OvNqwVNf-py3.10/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
                  "  return self.fget.__get__(instance, owner)()\n",
                  "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
                  "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mluca-fanselau\u001b[0m (\u001b[33madl-for-cv\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "True"
                  ]
               },
               "execution_count": 2,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import torch\n",
            "from vector_quantize_pytorch import VectorQuantize\n",
            "import os\n",
            "from data.neural_field_datasets import MnistNeFDataset, TokenTransform\n",
            "from training import training_nano_gpt\n",
            "\n",
            "from networks.nano_gpt import GPTConfig\n",
            "\n",
            "torch.cuda.is_available()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 3,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "<All keys matched successfully>"
                  ]
               },
               "execution_count": 3,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "kwargs = {\n",
            "\"type\": \"pretrained\",\n",
            "\"fixed_label\": None,\n",
            "}\n",
            "\n",
            "dir_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
            "data_root = os.path.join(dir_path, \"adl4cv\")\n",
            "\n",
            "# load used vector quantizer\n",
            "vq_dicts = torch.load(os.path.join(data_root, \"models\", \"vqs\", \"vq_mnist_with_all_5_conditioned_n_501.pt\"))\n",
            "vq = VectorQuantize(**vq_dicts[\"vq_config\"])\n",
            "vq.load_state_dict(vq_dicts[\"state_dict\"])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 4,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "60000"
                  ]
               },
               "execution_count": 4,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "dataset = MnistNeFDataset(os.path.join(data_root, \"datasets\", \"mnist-nerfs\"), transform=TokenTransform(vq), **kwargs)\n",
            "len(dataset)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 5,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Config Training\n",
            "config = training_nano_gpt.Config()\n",
            "config.learning_rate=3e-3\n",
            "config.max_iters = 30000\n",
            "config.weight_decay=0.00\n",
            "config.decay_lr=True\n",
            "config.lr_decay_iters=config.max_iters\n",
            "config.warmup_iters=0.05*config.max_iters\n",
            "config.batch_size = 64\n",
            "config.gradient_accumulation_steps = 1\n",
            "config.init_from = \"scratch\"\n",
            "config.out_dir =\"models/token_transformer\"\n",
            "config.detailed_folder = \"training_sample_5\"\n",
            "config.eval_interval = 250\n",
            "config.metric_interval = 250\n",
            "\n",
            "model_config = GPTConfig(n_embd=180, block_size=len(dataset[0][0]), n_head=12, n_layer=12, vocab_size=vq_dicts[\"vq_config\"][\"codebook_size\"] + 11, dropout=0.0)\n",
            "\n",
            "loaded = torch.load(\"./models/token_transformer/N_ALL_5M_LARGE_GOOD.pth\")\n",
            "model_config = loaded[\"model_args\"]\n",
            "config = loaded[\"config\"]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 6,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "2"
                  ]
               },
               "execution_count": 6,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "182%12"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 7,
         "metadata": {},
         "outputs": [],
         "source": [
            "#early_stopping = training_nano_gpt.EarlyStopper(20)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 8,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "'model_config = GPTConfig(\\n    n_embd=120, \\n    block_size=len(dataset[0][0]), \\n    n_head=12, n_layer=6, \\n    vocab_size=vq_dicts[\"vq_config\"][\"codebook_size\"] + 1,\\n    dropout=0.0\\n    )'"
                  ]
               },
               "execution_count": 8,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "\"\"\"model_config = GPTConfig(\n",
            "    n_embd=120, \n",
            "    block_size=len(dataset[0][0]), \n",
            "    n_head=12, n_layer=6, \n",
            "    vocab_size=vq_dicts[\"vq_config\"][\"codebook_size\"] + 1,\n",
            "    dropout=0.0\n",
            "    )\"\"\""
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 9,
         "metadata": {},
         "outputs": [],
         "source": [
            "cb_size = vq_dicts[\"vq_config\"][\"codebook_size\"]\n",
            "token_dict = {\n",
            "    \"SOS\": cb_size + 0,\n",
            "    \"0\": cb_size + 10,\n",
            "    \"1\": cb_size + 9,\n",
            "    \"2\": cb_size + 8,\n",
            "    \"3\": cb_size + 7,\n",
            "    \"4\": cb_size + 6,\n",
            "    \"5\": cb_size + 5,\n",
            "    \"6\": cb_size + 4,\n",
            "    \"7\": cb_size + 3,\n",
            "    \"8\": cb_size + 2,\n",
            "    \"9\": cb_size + 1\n",
            "}\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 10,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "({'SOS': 245,\n",
                     "  '0': 255,\n",
                     "  '1': 254,\n",
                     "  '2': 253,\n",
                     "  '3': 252,\n",
                     "  '4': 251,\n",
                     "  '5': 250,\n",
                     "  '6': 249,\n",
                     "  '7': 248,\n",
                     "  '8': 247,\n",
                     "  '9': 246},\n",
                     " 245)"
                  ]
               },
               "execution_count": 10,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "token_dict, cb_size"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 11,
         "metadata": {},
         "outputs": [],
         "source": [
            "# Where to put?\n",
            "# Maybe adjust dataset to be able to work with splitting data and then rewrite TokenTransform \n",
            "# to do the job combined with pytorch dataloader (get_batch == __call__ of Dataloader)\n",
            "\n",
            "def create_split_indices(n, train_ratio=0.9):\n",
            "    # Generate a random permutation of indices from 0 to n-1\n",
            "    shuffled_indices = torch.randperm(n)\n",
            "    # Determine the cut-off for training data\n",
            "    train_size = int(train_ratio * n)\n",
            "    # Split indices into training and validation sets\n",
            "    train_indices = shuffled_indices[:train_size]\n",
            "    val_indices = shuffled_indices[train_size:]\n",
            "    return train_indices, val_indices\n",
            "\n",
            "train_indices, val_indices = create_split_indices(len(dataset))\n",
            "\n",
            "def get_batch_lambda(config, dataset, model_config, split):\n",
            "    batch_size = config.batch_size\n",
            "    \n",
            "\n",
            "    # Select indices based on the split\n",
            "    if split == 'train':\n",
            "        # Randomly select batch_size indices from the train_indices\n",
            "        indices = train_indices[torch.randint(0, len(train_indices), (batch_size,))]\n",
            "    elif split == 'val':\n",
            "        # Randomly select batch_size indices from the val_indices\n",
            "        indices = val_indices[torch.randint(0, len(val_indices), (batch_size,))]\n",
            "    \n",
            "    \n",
            "    # Initialize lists to hold the sequences and labels\n",
            "    samples = []\n",
            "    labels = []\n",
            "\n",
            "    # Collect samples and labels\n",
            "    for idx in indices:\n",
            "        sample, label = dataset[idx]\n",
            "        start_tokens = torch.Tensor([token_dict[\"SOS\"], token_dict[str(label)]]).long()  # Start of sequence token\n",
            "        sample = torch.cat((start_tokens, sample), dim=0)\n",
            "        #start_tokens = torch.Tensor([0]).long()  # Start of sequence token\n",
            "        #sample = torch.cat((start_tokens, sample + 1), dim=0)\n",
            "        samples.append(sample)\n",
            "        labels.append(label)\n",
            "\n",
            "    # Prepare the sequences for model input\n",
            "    max_len = samples[0].size(0)\n",
            "    x = torch.zeros((batch_size, max_len - 1), dtype=torch.long)\n",
            "    y = torch.zeros((batch_size, max_len - 1), dtype=torch.long)\n",
            "    \n",
            "    for i, sample in enumerate(samples):\n",
            "        end_index = sample.size(0) - 1\n",
            "        x[i, :end_index] = sample[:-1]  # Exclude the last token for x\n",
            "        y[i, :end_index] = sample[1:]   # Exclude the first token for y\n",
            "\n",
            "    # Ensure x and y are the correct shape (batch_size, block_size) if needed:\n",
            "    # Here, we truncate to `block_size` if samples are longer than `block_size`.\n",
            "    x = x[:, :model_config.block_size]\n",
            "    y = y[:, :model_config.block_size]\n",
            "\n",
            "    # x and y have to be\n",
            "    x = x.to(config.device)\n",
            "    y = y.to(config.device)\n",
            "\n",
            "    return x, y\n",
            "\n",
            "create_get_batch = lambda config, dataset, model_config: lambda split: get_batch_lambda(config, dataset, model_config, split)\n",
            "get_batch = create_get_batch(config, dataset, model_config)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "30294000"
                  ]
               },
               "execution_count": 12,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "len(train_indices)*dataset[0][0].shape[0]"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 26,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "Initializing a new model from scratch\n",
                  "number of parameters: 5.62M\n",
                  "num decayed parameter tensors: 34, with 5,725,680 parameters\n",
                  "num non-decayed parameter tensors: 66, with 25,440 parameters\n",
                  "using fused AdamW: True\n"
               ]
            },
            {
               "data": {
                  "text/html": [
                     "Finishing last run (ID:gzewyzun) before initializing another..."
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     " View run <strong style=\"color:#cdcd00\">run-2024-06-22-00-23-47</strong> at: <a href='https://wandb.ai/adl-for-cv/naive_token_transformer/runs/gzewyzun' target=\"_blank\">https://wandb.ai/adl-for-cv/naive_token_transformer/runs/gzewyzun</a><br/> View project at: <a href='https://wandb.ai/adl-for-cv/naive_token_transformer' target=\"_blank\">https://wandb.ai/adl-for-cv/naive_token_transformer</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Find logs at: <code>./wandb/run-20240622_002348-gzewyzun/logs</code>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Successfully finished last run (ID:gzewyzun). Initializing new run:<br/>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "wandb version 0.17.2 is available!  To upgrade, please run:\n",
                     " $ pip install wandb --upgrade"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Tracking run with wandb version 0.16.6"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Run data is saved locally in <code>/home/luca/uni/master/adl4cv/wandb/run-20240622_002448-01ubqxty</code>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     "Syncing run <strong><a href='https://wandb.ai/adl-for-cv/naive_token_transformer/runs/01ubqxty' target=\"_blank\">run-2024-06-22-00-23-47</a></strong> to <a href='https://wandb.ai/adl-for-cv/naive_token_transformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     " View project at <a href='https://wandb.ai/adl-for-cv/naive_token_transformer' target=\"_blank\">https://wandb.ai/adl-for-cv/naive_token_transformer</a>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "data": {
                  "text/html": [
                     " View run at <a href='https://wandb.ai/adl-for-cv/naive_token_transformer/runs/01ubqxty' target=\"_blank\">https://wandb.ai/adl-for-cv/naive_token_transformer/runs/01ubqxty</a>"
                  ],
                  "text/plain": [
                     "<IPython.core.display.HTML object>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            },
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "step 0: mnist classifier loss: 4.148148059844971, mnist accuracy: 0.09375\n",
                  "step 0: train loss 5.6732, val loss 5.6733\n",
                  "step 250: mnist classifier loss: 3.7687907218933105, mnist accuracy: 0.1875\n",
                  "step 250: train loss 3.6009, val loss 3.5888\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 500: mnist classifier loss: 4.303024768829346, mnist accuracy: 0.09375\n",
                  "step 500: train loss 3.5206, val loss 3.5355\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 750: mnist classifier loss: 4.295627593994141, mnist accuracy: 0.109375\n",
                  "step 750: train loss 3.4429, val loss 3.4496\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 1000: mnist classifier loss: 3.656226396560669, mnist accuracy: 0.25\n",
                  "step 1000: train loss 3.3417, val loss 3.3356\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 1250: mnist classifier loss: 3.9164624214172363, mnist accuracy: 0.15625\n",
                  "step 1250: train loss 3.1918, val loss 3.1861\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 1500: mnist classifier loss: 3.4543380737304688, mnist accuracy: 0.25\n",
                  "step 1500: train loss 3.0275, val loss 3.0085\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 1750: mnist classifier loss: 3.1729729175567627, mnist accuracy: 0.265625\n",
                  "step 1750: train loss 2.8847, val loss 2.9091\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 2000: mnist classifier loss: 3.203535556793213, mnist accuracy: 0.296875\n",
                  "step 2000: train loss 2.8185, val loss 2.8098\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 2250: mnist classifier loss: 2.7375705242156982, mnist accuracy: 0.359375\n",
                  "step 2250: train loss 2.7262, val loss 2.7237\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 2500: mnist classifier loss: 2.763983964920044, mnist accuracy: 0.40625\n",
                  "step 2500: train loss 2.6599, val loss 2.6737\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 2750: mnist classifier loss: 2.650320291519165, mnist accuracy: 0.34375\n",
                  "step 2750: train loss 2.6438, val loss 2.6528\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 3000: mnist classifier loss: 3.2069480419158936, mnist accuracy: 0.296875\n",
                  "step 3000: train loss 2.6192, val loss 2.6126\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 3250: mnist classifier loss: 2.8839385509490967, mnist accuracy: 0.34375\n",
                  "step 3250: train loss 2.5748, val loss 2.5932\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 3500: mnist classifier loss: 2.4475526809692383, mnist accuracy: 0.40625\n",
                  "step 3500: train loss 2.5465, val loss 2.5525\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 3750: mnist classifier loss: 2.722465991973877, mnist accuracy: 0.34375\n",
                  "step 3750: train loss 2.5150, val loss 2.5406\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 4000: mnist classifier loss: 2.3997201919555664, mnist accuracy: 0.40625\n",
                  "step 4000: train loss 2.5363, val loss 2.5471\n",
                  "step 4250: mnist classifier loss: 2.252192258834839, mnist accuracy: 0.515625\n",
                  "step 4250: train loss 2.5143, val loss 2.5144\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 4500: mnist classifier loss: 2.2157859802246094, mnist accuracy: 0.484375\n",
                  "step 4500: train loss 2.4876, val loss 2.4972\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 4750: mnist classifier loss: 2.0937392711639404, mnist accuracy: 0.5\n",
                  "step 4750: train loss 2.4586, val loss 2.5048\n",
                  "step 5000: mnist classifier loss: 1.912968397140503, mnist accuracy: 0.484375\n",
                  "step 5000: train loss 2.4895, val loss 2.4763\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 5250: mnist classifier loss: 1.6256603002548218, mnist accuracy: 0.5\n",
                  "step 5250: train loss 2.4572, val loss 2.4725\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 5500: mnist classifier loss: 1.9345241785049438, mnist accuracy: 0.546875\n",
                  "step 5500: train loss 2.4512, val loss 2.4745\n",
                  "step 5750: mnist classifier loss: 1.8475745916366577, mnist accuracy: 0.515625\n",
                  "step 5750: train loss 2.4581, val loss 2.4774\n",
                  "step 6000: mnist classifier loss: 1.7666765451431274, mnist accuracy: 0.578125\n",
                  "step 6000: train loss 2.4377, val loss 2.4642\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 6250: mnist classifier loss: 1.984254240989685, mnist accuracy: 0.453125\n",
                  "step 6250: train loss 2.4526, val loss 2.4652\n",
                  "step 6500: mnist classifier loss: 2.0001540184020996, mnist accuracy: 0.546875\n",
                  "step 6500: train loss 2.4134, val loss 2.4579\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 6750: mnist classifier loss: 2.0856313705444336, mnist accuracy: 0.515625\n",
                  "step 6750: train loss 2.4252, val loss 2.4233\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 7000: mnist classifier loss: 1.4054621458053589, mnist accuracy: 0.609375\n",
                  "step 7000: train loss 2.4201, val loss 2.4363\n",
                  "step 7250: mnist classifier loss: 2.064077615737915, mnist accuracy: 0.546875\n",
                  "step 7250: train loss 2.4193, val loss 2.4397\n",
                  "step 7500: mnist classifier loss: 1.748969316482544, mnist accuracy: 0.5\n",
                  "step 7500: train loss 2.3947, val loss 2.4318\n",
                  "step 7750: mnist classifier loss: 1.356325626373291, mnist accuracy: 0.640625\n",
                  "step 7750: train loss 2.3902, val loss 2.4272\n",
                  "step 8000: mnist classifier loss: 1.2881869077682495, mnist accuracy: 0.6875\n",
                  "step 8000: train loss 2.3742, val loss 2.4225\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 8250: mnist classifier loss: 2.0098443031311035, mnist accuracy: 0.5625\n",
                  "step 8250: train loss 2.3897, val loss 2.4089\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 8500: mnist classifier loss: 2.2145273685455322, mnist accuracy: 0.46875\n",
                  "step 8500: train loss 2.3740, val loss 2.4179\n",
                  "step 8750: mnist classifier loss: 1.6367019414901733, mnist accuracy: 0.53125\n",
                  "step 8750: train loss 2.3804, val loss 2.4161\n",
                  "step 9000: mnist classifier loss: 1.6499300003051758, mnist accuracy: 0.546875\n",
                  "step 9000: train loss 2.3666, val loss 2.4004\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 9250: mnist classifier loss: 1.6150082349777222, mnist accuracy: 0.59375\n",
                  "step 9250: train loss 2.3581, val loss 2.3958\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 9500: mnist classifier loss: 1.6619409322738647, mnist accuracy: 0.53125\n",
                  "step 9500: train loss 2.3594, val loss 2.3812\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 9750: mnist classifier loss: 2.139007568359375, mnist accuracy: 0.515625\n",
                  "step 9750: train loss 2.3345, val loss 2.3982\n",
                  "step 10000: mnist classifier loss: 2.102252244949341, mnist accuracy: 0.4375\n",
                  "step 10000: train loss 2.3398, val loss 2.3714\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 10250: mnist classifier loss: 1.644403100013733, mnist accuracy: 0.53125\n",
                  "step 10250: train loss 2.3463, val loss 2.3781\n",
                  "step 10500: mnist classifier loss: 1.9710164070129395, mnist accuracy: 0.453125\n",
                  "step 10500: train loss 2.3165, val loss 2.3807\n",
                  "step 10750: mnist classifier loss: 1.8091703653335571, mnist accuracy: 0.515625\n",
                  "step 10750: train loss 2.3283, val loss 2.3754\n",
                  "step 11000: mnist classifier loss: 1.6036808490753174, mnist accuracy: 0.578125\n",
                  "step 11000: train loss 2.3226, val loss 2.3702\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 11250: mnist classifier loss: 1.5894687175750732, mnist accuracy: 0.578125\n",
                  "step 11250: train loss 2.3032, val loss 2.3525\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 11500: mnist classifier loss: 1.8730629682540894, mnist accuracy: 0.5625\n",
                  "step 11500: train loss 2.2987, val loss 2.3519\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 11750: mnist classifier loss: 1.7420319318771362, mnist accuracy: 0.546875\n",
                  "step 11750: train loss 2.3062, val loss 2.3586\n",
                  "step 12000: mnist classifier loss: 1.2019867897033691, mnist accuracy: 0.671875\n",
                  "step 12000: train loss 2.2959, val loss 2.3559\n",
                  "step 12250: mnist classifier loss: 1.483982801437378, mnist accuracy: 0.578125\n",
                  "step 12250: train loss 2.2943, val loss 2.3346\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 12500: mnist classifier loss: 1.6787465810775757, mnist accuracy: 0.5\n",
                  "step 12500: train loss 2.2769, val loss 2.3392\n",
                  "step 12750: mnist classifier loss: 1.6004465818405151, mnist accuracy: 0.5625\n",
                  "step 12750: train loss 2.2732, val loss 2.3570\n",
                  "step 13000: mnist classifier loss: 1.512274980545044, mnist accuracy: 0.625\n",
                  "step 13000: train loss 2.2687, val loss 2.3454\n",
                  "step 13250: mnist classifier loss: 1.0652048587799072, mnist accuracy: 0.65625\n",
                  "step 13250: train loss 2.2716, val loss 2.3248\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 13500: mnist classifier loss: 1.4087601900100708, mnist accuracy: 0.625\n",
                  "step 13500: train loss 2.2565, val loss 2.3272\n",
                  "step 13750: mnist classifier loss: 1.3800263404846191, mnist accuracy: 0.65625\n",
                  "step 13750: train loss 2.2603, val loss 2.3208\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 14000: mnist classifier loss: 1.3900257349014282, mnist accuracy: 0.640625\n",
                  "step 14000: train loss 2.2445, val loss 2.3046\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 14250: mnist classifier loss: 1.4430567026138306, mnist accuracy: 0.5625\n",
                  "step 14250: train loss 2.2484, val loss 2.3416\n",
                  "step 14500: mnist classifier loss: 1.2739278078079224, mnist accuracy: 0.671875\n",
                  "step 14500: train loss 2.2345, val loss 2.3282\n",
                  "step 14750: mnist classifier loss: 1.2512106895446777, mnist accuracy: 0.609375\n",
                  "step 14750: train loss 2.2183, val loss 2.3323\n",
                  "step 15000: mnist classifier loss: 1.63127863407135, mnist accuracy: 0.59375\n",
                  "step 15000: train loss 2.2280, val loss 2.3188\n",
                  "step 15250: mnist classifier loss: 1.3286024332046509, mnist accuracy: 0.59375\n",
                  "step 15250: train loss 2.2217, val loss 2.3037\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 15500: mnist classifier loss: 1.050424337387085, mnist accuracy: 0.671875\n",
                  "step 15500: train loss 2.2079, val loss 2.3037\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 15750: mnist classifier loss: 1.158934235572815, mnist accuracy: 0.71875\n",
                  "step 15750: train loss 2.2073, val loss 2.3166\n",
                  "step 16000: mnist classifier loss: 1.2369084358215332, mnist accuracy: 0.640625\n",
                  "step 16000: train loss 2.1996, val loss 2.3062\n",
                  "step 16250: mnist classifier loss: 1.6773791313171387, mnist accuracy: 0.5625\n",
                  "step 16250: train loss 2.2193, val loss 2.3032\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 16500: mnist classifier loss: 1.0296046733856201, mnist accuracy: 0.6875\n",
                  "step 16500: train loss 2.1689, val loss 2.3010\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 16750: mnist classifier loss: 1.32686448097229, mnist accuracy: 0.640625\n",
                  "step 16750: train loss 2.1793, val loss 2.2804\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 17000: mnist classifier loss: 1.564943790435791, mnist accuracy: 0.59375\n",
                  "step 17000: train loss 2.1900, val loss 2.2950\n",
                  "step 17250: mnist classifier loss: 1.0369778871536255, mnist accuracy: 0.6875\n",
                  "step 17250: train loss 2.1700, val loss 2.3022\n",
                  "step 17500: mnist classifier loss: 1.1634373664855957, mnist accuracy: 0.703125\n",
                  "step 17500: train loss 2.1736, val loss 2.3077\n",
                  "step 17750: mnist classifier loss: 1.1435848474502563, mnist accuracy: 0.671875\n",
                  "step 17750: train loss 2.1852, val loss 2.2914\n",
                  "step 18000: mnist classifier loss: 1.038824439048767, mnist accuracy: 0.671875\n",
                  "step 18000: train loss 2.1480, val loss 2.3005\n",
                  "step 18250: mnist classifier loss: 1.259472370147705, mnist accuracy: 0.65625\n",
                  "step 18250: train loss 2.1596, val loss 2.3155\n",
                  "step 18500: mnist classifier loss: 1.422720193862915, mnist accuracy: 0.625\n",
                  "step 18500: train loss 2.1522, val loss 2.3157\n",
                  "step 18750: mnist classifier loss: 1.1166592836380005, mnist accuracy: 0.65625\n",
                  "step 18750: train loss 2.1493, val loss 2.2974\n",
                  "step 19000: mnist classifier loss: 1.3174738883972168, mnist accuracy: 0.625\n",
                  "step 19000: train loss 2.1606, val loss 2.2823\n",
                  "step 19250: mnist classifier loss: 1.2074623107910156, mnist accuracy: 0.671875\n",
                  "step 19250: train loss 2.1616, val loss 2.2823\n",
                  "step 19500: mnist classifier loss: 1.0495144128799438, mnist accuracy: 0.703125\n",
                  "step 19500: train loss 2.1521, val loss 2.2965\n",
                  "step 19750: mnist classifier loss: 0.9958219528198242, mnist accuracy: 0.6875\n",
                  "step 19750: train loss 2.1692, val loss 2.2753\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 20000: mnist classifier loss: 0.9311839938163757, mnist accuracy: 0.71875\n",
                  "step 20000: train loss 2.1506, val loss 2.2967\n",
                  "step 20250: mnist classifier loss: 1.3922044038772583, mnist accuracy: 0.65625\n",
                  "step 20250: train loss 2.1375, val loss 2.2982\n",
                  "step 20500: mnist classifier loss: 1.0218688249588013, mnist accuracy: 0.71875\n",
                  "step 20500: train loss 2.1586, val loss 2.3010\n",
                  "step 20750: mnist classifier loss: 1.1628007888793945, mnist accuracy: 0.640625\n",
                  "step 20750: train loss 2.1523, val loss 2.2805\n",
                  "step 21000: mnist classifier loss: 1.2448537349700928, mnist accuracy: 0.625\n",
                  "step 21000: train loss 2.1597, val loss 2.2899\n",
                  "step 21250: mnist classifier loss: 0.923713207244873, mnist accuracy: 0.75\n",
                  "step 21250: train loss 2.1528, val loss 2.2935\n",
                  "step 21500: mnist classifier loss: 1.240504264831543, mnist accuracy: 0.6875\n",
                  "step 21500: train loss 2.1613, val loss 2.3120\n",
                  "step 21750: mnist classifier loss: 1.4138514995574951, mnist accuracy: 0.5625\n",
                  "step 21750: train loss 2.1421, val loss 2.2951\n",
                  "step 22000: mnist classifier loss: 1.2583998441696167, mnist accuracy: 0.65625\n",
                  "step 22000: train loss 2.1579, val loss 2.2960\n",
                  "step 22250: mnist classifier loss: 1.3027725219726562, mnist accuracy: 0.671875\n",
                  "step 22250: train loss 2.1445, val loss 2.2930\n",
                  "step 22500: mnist classifier loss: 1.511387825012207, mnist accuracy: 0.5625\n",
                  "step 22500: train loss 2.1516, val loss 2.3138\n",
                  "step 22750: mnist classifier loss: 1.0214956998825073, mnist accuracy: 0.65625\n",
                  "step 22750: train loss 2.1258, val loss 2.2777\n",
                  "step 23000: mnist classifier loss: 1.008334755897522, mnist accuracy: 0.75\n",
                  "step 23000: train loss 2.1441, val loss 2.3018\n",
                  "step 23250: mnist classifier loss: 1.1217797994613647, mnist accuracy: 0.640625\n",
                  "step 23250: train loss 2.1522, val loss 2.2900\n",
                  "step 23500: mnist classifier loss: 1.1425755023956299, mnist accuracy: 0.703125\n",
                  "step 23500: train loss 2.1309, val loss 2.2907\n",
                  "step 23750: mnist classifier loss: 1.2384250164031982, mnist accuracy: 0.671875\n",
                  "step 23750: train loss 2.1565, val loss 2.2733\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 24000: mnist classifier loss: 0.9368175864219666, mnist accuracy: 0.734375\n",
                  "step 24000: train loss 2.1393, val loss 2.3017\n",
                  "step 24250: mnist classifier loss: 1.029770016670227, mnist accuracy: 0.75\n",
                  "step 24250: train loss 2.1668, val loss 2.3069\n",
                  "step 24500: mnist classifier loss: 0.8510778546333313, mnist accuracy: 0.78125\n",
                  "step 24500: train loss 2.1491, val loss 2.2918\n",
                  "step 24750: mnist classifier loss: 1.1887198686599731, mnist accuracy: 0.65625\n",
                  "step 24750: train loss 2.1587, val loss 2.2824\n",
                  "step 25000: mnist classifier loss: 1.1917744874954224, mnist accuracy: 0.640625\n",
                  "step 25000: train loss 2.1484, val loss 2.2858\n",
                  "step 25250: mnist classifier loss: 0.7907828688621521, mnist accuracy: 0.796875\n",
                  "step 25250: train loss 2.1293, val loss 2.3076\n",
                  "step 25500: mnist classifier loss: 0.8867863416671753, mnist accuracy: 0.65625\n",
                  "step 25500: train loss 2.1448, val loss 2.3022\n",
                  "step 25750: mnist classifier loss: 0.9060347676277161, mnist accuracy: 0.71875\n",
                  "step 25750: train loss 2.1321, val loss 2.3353\n",
                  "step 26000: mnist classifier loss: 1.1991114616394043, mnist accuracy: 0.703125\n",
                  "step 26000: train loss 2.1486, val loss 2.2839\n",
                  "step 26250: mnist classifier loss: 1.4097777605056763, mnist accuracy: 0.640625\n",
                  "step 26250: train loss 2.1514, val loss 2.3149\n",
                  "step 26500: mnist classifier loss: 0.8610833287239075, mnist accuracy: 0.765625\n",
                  "step 26500: train loss 2.1514, val loss 2.2970\n",
                  "step 26750: mnist classifier loss: 0.7250838875770569, mnist accuracy: 0.765625\n",
                  "step 26750: train loss 2.1436, val loss 2.2807\n",
                  "step 27000: mnist classifier loss: 1.2197351455688477, mnist accuracy: 0.703125\n",
                  "step 27000: train loss 2.1349, val loss 2.2737\n",
                  "step 27250: mnist classifier loss: 0.9925397634506226, mnist accuracy: 0.71875\n",
                  "step 27250: train loss 2.1372, val loss 2.3072\n",
                  "step 27500: mnist classifier loss: 0.9869872331619263, mnist accuracy: 0.71875\n",
                  "step 27500: train loss 2.1570, val loss 2.2768\n",
                  "step 27750: mnist classifier loss: 1.0196560621261597, mnist accuracy: 0.71875\n",
                  "step 27750: train loss 2.1443, val loss 2.2970\n",
                  "step 28000: mnist classifier loss: 1.219185471534729, mnist accuracy: 0.75\n",
                  "step 28000: train loss 2.1487, val loss 2.2927\n",
                  "step 28250: mnist classifier loss: 1.4860122203826904, mnist accuracy: 0.578125\n",
                  "step 28250: train loss 2.1285, val loss 2.3179\n",
                  "step 28500: mnist classifier loss: 1.1845704317092896, mnist accuracy: 0.671875\n",
                  "step 28500: train loss 2.1386, val loss 2.3184\n",
                  "step 28750: mnist classifier loss: 1.2886568307876587, mnist accuracy: 0.640625\n",
                  "step 28750: train loss 2.1479, val loss 2.2689\n",
                  "saving checkpoint to models/token_transformer\n",
                  "step 29000: mnist classifier loss: 1.3971658945083618, mnist accuracy: 0.578125\n",
                  "step 29000: train loss 2.1364, val loss 2.2922\n",
                  "step 29250: mnist classifier loss: 1.2506674528121948, mnist accuracy: 0.703125\n",
                  "step 29250: train loss 2.1322, val loss 2.3141\n",
                  "step 29500: mnist classifier loss: 0.9431710839271545, mnist accuracy: 0.765625\n",
                  "step 29500: train loss 2.1437, val loss 2.2770\n",
                  "step 29750: mnist classifier loss: 1.3859667778015137, mnist accuracy: 0.59375\n",
                  "step 29750: train loss 2.1348, val loss 2.2961\n",
                  "step 30000: mnist classifier loss: 0.8185750842094421, mnist accuracy: 0.796875\n",
                  "step 30000: train loss 2.1392, val loss 2.3085\n",
                  "step 30250: mnist classifier loss: 1.031673550605774, mnist accuracy: 0.703125\n",
                  "step 30250: train loss 2.1418, val loss 2.3140\n",
                  "step 30500: mnist classifier loss: 1.3725991249084473, mnist accuracy: 0.65625\n",
                  "step 30500: train loss 2.1147, val loss 2.2872\n",
                  "step 30750: mnist classifier loss: 1.1826173067092896, mnist accuracy: 0.625\n",
                  "step 30750: train loss 2.1492, val loss 2.2917\n",
                  "step 31000: mnist classifier loss: 1.0610381364822388, mnist accuracy: 0.703125\n",
                  "step 31000: train loss 2.1470, val loss 2.2930\n",
                  "step 31250: mnist classifier loss: 1.5270583629608154, mnist accuracy: 0.625\n",
                  "step 31250: train loss 2.1345, val loss 2.2828\n",
                  "step 31500: mnist classifier loss: 1.2480559349060059, mnist accuracy: 0.640625\n",
                  "step 31500: train loss 2.1349, val loss 2.2916\n",
                  "step 31750: mnist classifier loss: 1.328740119934082, mnist accuracy: 0.671875\n",
                  "step 31750: train loss 2.1309, val loss 2.3034\n",
                  "step 32000: mnist classifier loss: 1.1624081134796143, mnist accuracy: 0.703125\n",
                  "step 32000: train loss 2.1394, val loss 2.3054\n",
                  "step 32250: mnist classifier loss: 0.9886049032211304, mnist accuracy: 0.671875\n",
                  "step 32250: train loss 2.1450, val loss 2.2886\n",
                  "step 32500: mnist classifier loss: 1.501177191734314, mnist accuracy: 0.59375\n",
                  "step 32500: train loss 2.1529, val loss 2.2792\n",
                  "step 32750: mnist classifier loss: 1.5726425647735596, mnist accuracy: 0.625\n",
                  "step 32750: train loss 2.1466, val loss 2.3216\n",
                  "step 33000: mnist classifier loss: 1.2652826309204102, mnist accuracy: 0.734375\n",
                  "step 33000: train loss 2.1407, val loss 2.3069\n",
                  "step 33250: mnist classifier loss: 1.1195091009140015, mnist accuracy: 0.65625\n",
                  "step 33250: train loss 2.1540, val loss 2.2904\n",
                  "step 33500: mnist classifier loss: 1.0574067831039429, mnist accuracy: 0.75\n",
                  "step 33500: train loss 2.1321, val loss 2.3120\n",
                  "step 33750: mnist classifier loss: 1.0218974351882935, mnist accuracy: 0.703125\n",
                  "step 33750: train loss 2.1399, val loss 2.3322\n",
                  "step 34000: mnist classifier loss: 1.15639328956604, mnist accuracy: 0.6875\n",
                  "step 34000: train loss 2.1489, val loss 2.3198\n",
                  "step 34250: mnist classifier loss: 1.3076508045196533, mnist accuracy: 0.609375\n",
                  "step 34250: train loss 2.1466, val loss 2.2883\n",
                  "step 34500: mnist classifier loss: 0.9929695725440979, mnist accuracy: 0.734375\n",
                  "step 34500: train loss 2.1267, val loss 2.3108\n",
                  "step 34750: mnist classifier loss: 1.1557936668395996, mnist accuracy: 0.6875\n",
                  "step 34750: train loss 2.1287, val loss 2.2942\n",
                  "step 35000: mnist classifier loss: 1.0706206560134888, mnist accuracy: 0.734375\n",
                  "step 35000: train loss 2.1182, val loss 2.2998\n",
                  "step 35250: mnist classifier loss: 0.8279260396957397, mnist accuracy: 0.78125\n",
                  "step 35250: train loss 2.1434, val loss 2.3061\n",
                  "step 35500: mnist classifier loss: 1.1900362968444824, mnist accuracy: 0.671875\n",
                  "step 35500: train loss 2.1216, val loss 2.3038\n",
                  "step 35750: mnist classifier loss: 0.9014370441436768, mnist accuracy: 0.6875\n",
                  "step 35750: train loss 2.1361, val loss 2.3054\n",
                  "step 36000: mnist classifier loss: 1.0638437271118164, mnist accuracy: 0.703125\n",
                  "step 36000: train loss 2.1159, val loss 2.3105\n",
                  "step 36250: mnist classifier loss: 1.1161469221115112, mnist accuracy: 0.703125\n",
                  "step 36250: train loss 2.1327, val loss 2.3067\n",
                  "step 36500: mnist classifier loss: 1.1263854503631592, mnist accuracy: 0.6875\n",
                  "step 36500: train loss 2.1390, val loss 2.3071\n",
                  "step 36750: mnist classifier loss: 1.22869074344635, mnist accuracy: 0.671875\n",
                  "step 36750: train loss 2.1238, val loss 2.3275\n",
                  "step 37000: mnist classifier loss: 1.066611647605896, mnist accuracy: 0.703125\n",
                  "step 37000: train loss 2.1359, val loss 2.2965\n",
                  "step 37250: mnist classifier loss: 0.9019394516944885, mnist accuracy: 0.734375\n",
                  "step 37250: train loss 2.1143, val loss 2.3034\n",
                  "step 37500: mnist classifier loss: 1.2114967107772827, mnist accuracy: 0.703125\n",
                  "step 37500: train loss 2.1316, val loss 2.3065\n",
                  "step 37750: mnist classifier loss: 0.998195230960846, mnist accuracy: 0.71875\n",
                  "step 37750: train loss 2.1333, val loss 2.2942\n",
                  "step 38000: mnist classifier loss: 1.1348153352737427, mnist accuracy: 0.671875\n",
                  "step 38000: train loss 2.1319, val loss 2.2965\n",
                  "step 38250: mnist classifier loss: 1.0695886611938477, mnist accuracy: 0.734375\n",
                  "step 38250: train loss 2.1306, val loss 2.3077\n",
                  "step 38500: mnist classifier loss: 1.3097124099731445, mnist accuracy: 0.625\n",
                  "step 38500: train loss 2.1417, val loss 2.3130\n",
                  "step 38750: mnist classifier loss: 1.507566213607788, mnist accuracy: 0.609375\n",
                  "step 38750: train loss 2.1591, val loss 2.3185\n",
                  "step 39000: mnist classifier loss: 0.9986258149147034, mnist accuracy: 0.71875\n",
                  "step 39000: train loss 2.1231, val loss 2.3129\n",
                  "step 39250: mnist classifier loss: 1.140053153038025, mnist accuracy: 0.671875\n",
                  "step 39250: train loss 2.1428, val loss 2.3082\n",
                  "step 39500: mnist classifier loss: 0.8552961945533752, mnist accuracy: 0.71875\n",
                  "step 39500: train loss 2.1585, val loss 2.3123\n",
                  "step 39750: mnist classifier loss: 1.1332545280456543, mnist accuracy: 0.640625\n",
                  "step 39750: train loss 2.1247, val loss 2.3189\n",
                  "step 40000: mnist classifier loss: 1.1377906799316406, mnist accuracy: 0.671875\n",
                  "step 40000: train loss 2.1271, val loss 2.3502\n"
               ]
            }
         ],
         "source": [
            "# Prepeare model parameters and train\n",
            "import wandb\n",
            "trained_model = training_nano_gpt.train(get_batch, config, model_config, vq, vq_dicts[\"vq_config\"], token_dict=token_dict)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "dict_keys(['model', 'optimizer', 'model_args', 'iter_num', 'best_val_loss', 'config', 'vq_state_dict', 'vq_config', 'token_dict'])\n",
                  "number of parameters: 5.62M\n"
               ]
            },
            {
               "data": {
                  "text/plain": [
                     "tensor([[False, False, False, False, False, False,  True, False, False,  True,\n",
                     "         False, False, False, False, False, False, False, False,  True, False,\n",
                     "          True, False, False, False,  True,  True,  True, False, False, False,\n",
                     "         False, False, False,  True, False,  True, False,  True,  True, False,\n",
                     "          True, False, False, False, False, False,  True, False, False, False,\n",
                     "         False, False, False, False,  True, False, False, False, False,  True,\n",
                     "         False, False, False, False, False, False, False, False,  True, False,\n",
                     "          True, False, False,  True, False, False, False, False, False, False,\n",
                     "         False, False,  True, False, False, False, False, False,  True,  True,\n",
                     "         False, False, False, False, False,  True,  True, False, False, False,\n",
                     "         False,  True, False,  True, False, False, False, False, False, False,\n",
                     "         False, False, False, False, False,  True, False,  True, False, False,\n",
                     "          True, False, False, False,  True, False, False, False, False, False,\n",
                     "         False, False, False,  True,  True, False,  True, False, False, False,\n",
                     "         False, False, False, False,  True, False, False, False,  True, False,\n",
                     "         False, False, False, False,  True, False, False, False, False, False,\n",
                     "         False,  True, False, False, False, False, False, False, False, False,\n",
                     "         False, False, False, False,  True, False, False, False, False, False,\n",
                     "         False, False, False, False,  True, False, False,  True, False, False,\n",
                     "         False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
                     "         False, False, False, False,  True, False, False, False, False,  True,\n",
                     "         False, False, False,  True, False, False, False, False,  True,  True,\n",
                     "          True,  True, False, False, False,  True,  True, False, False, False,\n",
                     "         False, False, False,  True,  True, False, False, False,  True, False,\n",
                     "         False, False,  True, False, False, False, False, False,  True,  True,\n",
                     "          True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
                     "          True,  True,  True, False,  True, False, False, False, False, False,\n",
                     "         False, False, False, False, False,  True, False, False, False,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
                     "          True,  True,  True,  True,  True, False, False, False, False, False,\n",
                     "         False, False, False, False, False, False, False,  True, False, False,\n",
                     "         False,  True,  True, False, False, False, False, False, False, False,\n",
                     "          True, False, False,  True, False, False, False, False, False, False,\n",
                     "         False,  True, False, False, False, False, False, False, False,  True,\n",
                     "         False, False, False,  True, False, False, False, False, False, False,\n",
                     "         False, False, False, False, False,  True, False, False, False,  True,\n",
                     "         False,  True, False,  True, False,  True,  True, False,  True,  True,\n",
                     "         False,  True, False, False,  True,  True,  True, False,  True, False,\n",
                     "         False, False, False, False, False,  True,  True,  True, False,  True,\n",
                     "         False,  True,  True,  True, False,  True,  True, False,  True,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
                     "          True,  True,  True,  True,  True,  True, False, False,  True,  True,\n",
                     "          True,  True, False, False,  True, False, False, False, False, False,\n",
                     "          True, False, False, False, False,  True, False, False, False, False,\n",
                     "         False, False, False, False, False,  True, False, False, False, False,\n",
                     "         False,  True, False, False, False, False, False,  True, False, False,\n",
                     "         False, False,  True, False, False, False, False,  True, False, False,\n",
                     "         False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
                     "          True,  True,  True,  True,  True,  True,  True, False, False, False,\n",
                     "         False,  True, False, False, False,  True, False, False, False,  True,\n",
                     "         False,  True, False, False, False, False, False, False,  True, False,\n",
                     "          True, False, False, False, False,  True, False, False, False,  True,\n",
                     "          True, False, False,  True, False, False,  True,  True,  True, False,\n",
                     "         False, False,  True, False,  True, False,  True, False,  True, False,\n",
                     "          True,  True, False,  True,  True, False, False,  True,  True,  True,\n",
                     "          True]], device='cuda:0')"
                  ]
               },
               "execution_count": 13,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "import matplotlib.pyplot as plt\n",
            "import torch\n",
            "from networks.nano_gpt import GPT\n",
            "from utils import get_default_device\n",
            "\n",
            "model_dict = torch.load(\"./models/token_transformer/proper_tokens.pt\")\n",
            "# Configuration\n",
            "print(model_dict.keys())\n",
            "idx = 3\n",
            "\n",
            "device = get_default_device()\n",
            "model = GPT(model_dict[\"model_args\"])#model_dict\n",
            "model.to(device=device)\n",
            "model.load_state_dict(model_dict[\"model\"])\n",
            "model.eval()\n",
            "\n",
            "vq = VectorQuantize(**model_dict[\"vq_config\"])\n",
            "vq.load_state_dict(model_dict[\"vq_state_dict\"])\n",
            "vq.eval()\n",
            "\n",
            "dataset = MnistNeFDataset(os.path.join(data_root, \"datasets\", \"mnist-nerfs\"), transform=TokenTransform(vq), **kwargs)\n",
            "\n",
            "\n",
            "sample = dataset[0][0]\n",
            "X, Y = get_batch('val')\n",
            "X, Y = (X[0].unsqueeze(0), Y[0].unsqueeze(0))\n",
            "pred, _ = model(X, Y)\n",
            "# Sanity Check\n",
            "# Should be all true except first/second element\n",
            "pred.argmax(dim=-1)==Y\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 24,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "2\n",
                  "0\n",
                  "0\n",
                  "6\n",
                  "1\n",
                  "9\n",
                  "2\n",
                  "9\n",
                  "4\n"
               ]
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 1000x1000 with 9 Axes>"
                  ]
               },
               "metadata": {
                  "needs_background": "light"
               },
               "output_type": "display_data"
            }
         ],
         "source": [
            "from random import randint\n",
            "from animation.util import backtransform_weights, reconstruct_image\n",
            "from networks.mlp_models import MLP3D\n",
            "\n",
            "ij_len = 3\n",
            "# Plotting the tensors as heatmaps in grayscale\n",
            "plt.style.use(\"dark_background\")\n",
            "fig, axes = plt.subplots(ij_len, ij_len, figsize=(10, 10))\n",
            "\n",
            "fig.patch.set_alpha(0)\n",
            "\n",
            "for ax in axes.flat:\n",
            "    ax.patch.set_facecolor(\"none\")\n",
            "    ax.patch.set_alpha(0)\n",
            "\n",
            "\n",
            "kwargs = {\n",
            "\"type\": \"pretrained\",\n",
            "\"fixed_label\": None,\n",
            "}\n",
            "\n",
            "for i in range(ij_len):\n",
            "    for j in range(ij_len):\n",
            "\n",
            "        model.eval()\n",
            "        number = str(randint(0, 9))\n",
            "        novel_tokens = model.generate(torch.Tensor([[token_dict[\"SOS\"], token_dict[number]]]).long().to(device=\"cuda\"), dataset[0][0].shape[0], temperature=1, top_k=None)[:, 1:]\n",
            "\n",
            "        print(number)\n",
            "        novel_tokens = novel_tokens[:, 1:].unsqueeze(-1).to(\"cpu\")\n",
            "                                                                                                                         \n",
            "\n",
            "        max_similarity = 0\n",
            "        \"\"\"\n",
            "        for data in dataset:\n",
            "            similarity = (data[0].to(device)==noxmarty/resnet-tiny-mnist\n",
            "                max_similarity = similarity\n",
            "        \"\"\"\n",
            "        #print(f\"Maximum Similarity of picture (i, j) {(i, j)}: {max_similarity}\")\n",
            "\n",
            "        novel_weights= vq.get_codes_from_indices((novel_tokens))\n",
            "\n",
            "        dataset_no_transform = MnistNeFDataset(os.path.join(data_root, \"datasets\", \"mnist-nerfs\"), **kwargs)\n",
            "        original_dict = dataset_no_transform[0][0]\n",
            "\n",
            "        reconstructed_dict = backtransform_weights(novel_weights, original_dict[\"state_dict\"])\n",
            "\n",
            "        mlp3d = MLP3D(**original_dict[\"model_config\"])\n",
            "        mlp3d.load_state_dict(reconstructed_dict)\n",
            "        reconstructed_tensor = reconstruct_image(mlp3d)\n",
            "\n",
            "        axes[i][j].imshow(reconstructed_tensor, cmap='gray', aspect='auto')\n",
            "        axes[i][j].set_title(number)\n",
            "        axes[i][j].axis(\"off\")\n",
            "\n",
            "fig.patch.set_alpha(0)\n",
            "\n",
            "\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "0.703125\n",
                  "1.2872538566589355\n"
               ]
            }
         ],
         "source": [
            "from training.mnist_classifier_score import compute_mnist_score\n",
            "acc, loss= compute_mnist_score(model, vq, \"cuda\", token_dict)\n",
            "\n",
            "print(acc)\n",
            "print(loss)\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# script to "
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from utils.metrics import compute_all_metrics\n",
            "\n",
            "reference =\n",
            "\n",
            "compute_all_metrics()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 43,
         "metadata": {},
         "outputs": [],
         "source": [
            "# get the logits of the gpt model generation\n",
            "model.eval()\n",
            "logits_conditioning = model.generate_logits(torch.Tensor([[token_dict[\"SOS\"]]]).long().to(device=\"cuda\"))\n",
            "\n",
            "# do a whole autoregressive proccess and get the logits for the last token\n",
            "novel_tokens = model.generate(torch.Tensor([[token_dict[\"SOS\"]]]).long().to(device=\"cuda\"), dataset[0][0].shape[0] + 1, temperature=0.8, top_k=3)[:, :]\n",
            "logits_last = model.generate_logits(novel_tokens[:, :-1])"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 44,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 1000x500 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# barchart of the logits\n",
            "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
            "ax.bar(range(logits_last.shape[-1]), logits_last[0].detach().cpu().numpy())\n",
            "ax.set_title(\"Logits of the conditioning tokens\")\n",
            "plt.show()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "logits"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "# store the logits as numpy file\n",
            "import numpy as np\n",
            "np.save(\"logits_conditioning.npy\", logits_conditioning.squeeze(0).detach().cpu().numpy())\n",
            "np.save(\"logits_last.npy\", logits_last.squeeze(0).detach().cpu().numpy())"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "Text(0.5, 1.0, 'Softmax of the logits of the conditioning tokens')"
                  ]
               },
               "execution_count": 35,
               "metadata": {},
               "output_type": "execute_result"
            },
            {
               "data": {
                  "image/png": "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",
                  "text/plain": [
                     "<Figure size 1000x500 with 1 Axes>"
                  ]
               },
               "metadata": {},
               "output_type": "display_data"
            }
         ],
         "source": [
            "# softmax of the logits conditioning\n",
            "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
            "temperature = 2\n",
            "logits = logits_last / temperature\n",
            "ax.bar(range(logits_last.shape[-1]), torch.softmax(logits[0], dim=-1).detach().cpu().numpy())\n",
            "ax.set_title(\"Softmax of the logits of the conditioning tokens\")"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "name": "stdout",
               "output_type": "stream",
               "text": [
                  "number of parameters: 5.62M\n",
                  "{'1': {'1': {'acc': 0.65625, 'loss': 1.4447228908538818}}}\n"
               ]
            }
         ],
         "source": [
            "import optimize_metrics\n",
            "\n",
            "optimize_metrics.main()"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "{'1': {'1': {'acc': 0.65625, 'loss': 1.4447228908538818}}}"
                  ]
               },
               "execution_count": 6,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": []
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": []
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.10.14"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
