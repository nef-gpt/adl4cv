{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Enable autoreload of module\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.neural_field_datasets_shapenet import FlattenTransform3D, ShapeNetDataset, AllWeights3D\n",
    "from vector_quantize_pytorch import ResidualVQ, kmeans\n",
    "\n",
    "# load dataset\n",
    "dataset = ShapeNetDataset(\"./datasets/plane_mlp_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils import get_default_device\n",
    "\n",
    "\n",
    "def get_weight_vector(state_dict: OrderedDict, layer: int, neuron: int) -> torch.Tensor:\n",
    "    return state_dict[f\"layers.{layer}.weight\"][:, neuron]\n",
    "\n",
    "def get_bias(state_dict: OrderedDict, layer: int, neuron: int) -> torch.Tensor:\n",
    "    return  state_dict[f\"layers.{layer}.bias\"][neuron]\n",
    "\n",
    "def get_all_weights(dataset: ShapeNetDataset, layer: int, neuron: int) -> torch.Tensor:\n",
    "    all_weights = torch.stack([get_weight_vector(mlp3d[0], layer, neuron) for mlp3d in dataset])\n",
    "    return all_weights\n",
    "\n",
    "\n",
    "\n",
    "def get_all_biases(dataset: ShapeNetDataset, layer: int, neuron: int) -> torch.Tensor:\n",
    "    all_biases = torch.stack([get_bias(mlp3d[0], layer, neuron) for mlp3d in dataset])\n",
    "    return all_biases\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ShapeNetDataset(\"./datasets/plane_mlp_weights\", transform=AllWeights3D())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "path =\"./models/rq_search_results/learnable_rq_model_dim_128_vocab_287_batch_size_1024_threshold_ema_dead_code_0_kmean_iters_0_num_quantizers_2_use_init_True.pth\"\n",
    "dataset = ShapeNetDataset(\"./datasets/plane_mlp_weights\", transform=AllWeights3D())\n",
    "\n",
    "rq_dicts = torch.load(path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvq = ResidualVQ(**rq_dicts[\"rq_config\"])\n",
    "rvq.load_state_dict(rq_dicts[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dim': 128,\n",
       " 'codebook_size': 287,\n",
       " 'decay': 0.8,\n",
       " 'commitment_weight': 1.0,\n",
       " 'kmeans_init': False,\n",
       " 'kmeans_iters': 0,\n",
       " 'threshold_ema_dead_code': 0,\n",
       " 'num_quantizers': 2,\n",
       " 'ema_update': False,\n",
       " 'learnable_codebook': True,\n",
       " 'in_place_codebook_optimizer': torch.optim.adam.Adam,\n",
       " 'use_cosine_sim': True}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rq_dicts[\"rq_config\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in rvq.layers:\n",
    "    layer.eval()\n",
    "    layer.training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([287, 128])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorQuantize(\n",
       "  (project_in): Identity()\n",
       "  (project_out): Identity()\n",
       "  (_codebook): CosineSimCodebook()\n",
       ")"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvq.layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_0, indices_0, loss_0 = rvq.layers[0](dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_1, indices_1, loss_1 = rvq.layers[1](dataset[0][0] - quantized_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_norm = dataset[0][0].norm(p=2, dim=-1, keepdim=True)\n",
    "quantized_1_norm = (dataset[0][0] - quantized_0).norm(p=2, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7154,  1.1090,  0.0950,  ...,  0.0263, -0.3183,  0.3249],\n",
       "        [-0.6302,  6.9132,  0.1760,  ..., -0.2754, -0.4918,  0.2230],\n",
       "        [-0.1570, -0.8731, -0.0985,  ..., -0.0961, -0.0925,  0.0629],\n",
       "        ...,\n",
       "        [-0.1746, -0.1891, -0.0435,  ..., -0.0854, -0.1295, -0.0722],\n",
       "        [-0.3456, -0.4081, -0.0896,  ..., -0.1784, -0.2610, -0.1592],\n",
       "        [-0.6637, -0.7739, -0.1818,  ..., -0.2098, -0.3669, -0.4075]])"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized_0*dataset_norm + quantized_1*quantized_1_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3149,  0.6769,  0.1253,  ..., -0.0045, -0.1866,  0.1910],\n",
       "        [-1.9470,  4.1741,  0.2301,  ..., -0.0606, -0.2085,  0.0677],\n",
       "        [-0.1827, -0.2787, -0.2146,  ..., -0.2211, -0.1881, -0.7975],\n",
       "        ...,\n",
       "        [-0.0288,  0.0232, -0.2488,  ..., -0.2464, -0.3122,  0.0921],\n",
       "        [-0.5402, -0.8153, -0.0747,  ..., -0.4094, -1.4079, -0.1554],\n",
       "        [-0.8989, -0.0449, -0.3596,  ...,  0.0108, -0.0728, -0.7832]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized, indices, loss = rvq(dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3149,  0.6769,  0.1253,  ..., -0.0045, -0.1866,  0.1910],\n",
       "        [-1.9470,  4.1741,  0.2301,  ..., -0.0606, -0.2085,  0.0677],\n",
       "        [-0.1827, -0.2787, -0.2146,  ..., -0.2211, -0.1881, -0.7975],\n",
       "        ...,\n",
       "        [-0.0288,  0.0232, -0.2488,  ..., -0.2464, -0.3122,  0.0921],\n",
       "        [-0.5402, -0.8153, -0.0747,  ..., -0.4094, -1.4079, -0.1554],\n",
       "        [-0.8989, -0.0449, -0.3596,  ...,  0.0108, -0.0728, -0.7832]])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.5821],\n",
       "        [1.7209],\n",
       "        [1.4479],\n",
       "        [1.5821],\n",
       "        [1.7209],\n",
       "        [1.4479],\n",
       "        [5.2103],\n",
       "        [5.2103],\n",
       "        [5.2103],\n",
       "        [1.5821],\n",
       "        [1.7209],\n",
       "        [1.4479],\n",
       "        [5.2103],\n",
       "        [5.2103],\n",
       "        [5.2103],\n",
       "        [1.5821],\n",
       "        [1.7209],\n",
       "        [2.8002],\n",
       "        [1.9246],\n",
       "        [5.2103],\n",
       "        [1.6459],\n",
       "        [1.4879],\n",
       "        [1.7209],\n",
       "        [1.5332],\n",
       "        [2.3842],\n",
       "        [5.2103],\n",
       "        [1.8822],\n",
       "        [3.7619],\n",
       "        [1.6654],\n",
       "        [1.0774],\n",
       "        [5.2103],\n",
       "        [0.9694],\n",
       "        [1.2777],\n",
       "        [6.1507],\n",
       "        [5.2103],\n",
       "        [5.2103],\n",
       "        [2.7117],\n",
       "        [2.8375],\n",
       "        [2.1485],\n",
       "        [1.2480],\n",
       "        [5.2103],\n",
       "        [1.2205],\n",
       "        [1.6983],\n",
       "        [1.4516],\n",
       "        [1.4839],\n",
       "        [0.6340],\n",
       "        [5.2103],\n",
       "        [2.7595],\n",
       "        [1.9340],\n",
       "        [1.1815],\n",
       "        [2.4259],\n",
       "        [5.8100],\n",
       "        [3.7619],\n",
       "        [5.9255],\n",
       "        [0.7291],\n",
       "        [3.8072],\n",
       "        [1.3475],\n",
       "        [0.9864],\n",
       "        [5.9888],\n",
       "        [1.6997],\n",
       "        [2.0901],\n",
       "        [3.9182],\n",
       "        [2.7677],\n",
       "        [2.4006],\n",
       "        [1.2540],\n",
       "        [4.6019],\n",
       "        [5.2103],\n",
       "        [1.6168],\n",
       "        [1.1160],\n",
       "        [1.2207],\n",
       "        [2.1077],\n",
       "        [5.6925],\n",
       "        [5.8960],\n",
       "        [5.6925],\n",
       "        [1.1538],\n",
       "        [1.1964],\n",
       "        [1.9340],\n",
       "        [1.9193],\n",
       "        [2.9255],\n",
       "        [1.6027],\n",
       "        [1.3135],\n",
       "        [1.3860],\n",
       "        [1.0811],\n",
       "        [5.8475],\n",
       "        [5.2103],\n",
       "        [1.0887],\n",
       "        [0.9272],\n",
       "        [1.9145],\n",
       "        [3.9182],\n",
       "        [5.7576],\n",
       "        [5.8663],\n",
       "        [1.0166],\n",
       "        [0.1191],\n",
       "        [1.8330],\n",
       "        [5.7576],\n",
       "        [1.2480],\n",
       "        [1.3280],\n",
       "        [1.7313],\n",
       "        [5.2103],\n",
       "        [2.3723],\n",
       "        [0.7115],\n",
       "        [1.0245],\n",
       "        [3.9182],\n",
       "        [2.6063],\n",
       "        [1.3119],\n",
       "        [1.2480],\n",
       "        [0.7867],\n",
       "        [0.0515],\n",
       "        [3.7022],\n",
       "        [5.9403],\n",
       "        [0.7506],\n",
       "        [5.6925],\n",
       "        [5.2103],\n",
       "        [0.7115],\n",
       "        [2.8155],\n",
       "        [2.6958],\n",
       "        [5.2103],\n",
       "        [1.7284],\n",
       "        [2.5558],\n",
       "        [1.7059],\n",
       "        [0.6992],\n",
       "        [1.1643],\n",
       "        [5.2103],\n",
       "        [2.8757],\n",
       "        [5.9103],\n",
       "        [3.0457],\n",
       "        [3.7666],\n",
       "        [1.6660],\n",
       "        [0.8154],\n",
       "        [1.2830],\n",
       "        [2.7042],\n",
       "        [1.3930],\n",
       "        [1.2429],\n",
       "        [5.7576],\n",
       "        [1.2480],\n",
       "        [5.2103],\n",
       "        [1.3811],\n",
       "        [0.9229],\n",
       "        [2.7398],\n",
       "        [3.7996],\n",
       "        [5.8934],\n",
       "        [2.8155],\n",
       "        [5.9126],\n",
       "        [1.2480],\n",
       "        [1.2480],\n",
       "        [2.8272],\n",
       "        [2.7989],\n",
       "        [4.5920],\n",
       "        [2.8952],\n",
       "        [6.1322],\n",
       "        [3.8317],\n",
       "        [6.0140],\n",
       "        [1.4426],\n",
       "        [5.2103],\n",
       "        [2.9702],\n",
       "        [5.2103],\n",
       "        [2.3199],\n",
       "        [0.7120],\n",
       "        [1.9345],\n",
       "        [0.9087],\n",
       "        [1.2977],\n",
       "        [2.7351],\n",
       "        [0.8894],\n",
       "        [0.7472],\n",
       "        [5.2103],\n",
       "        [2.9255],\n",
       "        [0.8308],\n",
       "        [1.4611],\n",
       "        [5.2103],\n",
       "        [1.7008],\n",
       "        [1.2548],\n",
       "        [5.2103],\n",
       "        [1.4273],\n",
       "        [0.5432],\n",
       "        [0.9087],\n",
       "        [5.6567],\n",
       "        [1.5327],\n",
       "        [5.2103],\n",
       "        [5.2103],\n",
       "        [0.8932],\n",
       "        [1.5264],\n",
       "        [5.2103],\n",
       "        [0.2510],\n",
       "        [0.8879],\n",
       "        [0.9087],\n",
       "        [0.6299],\n",
       "        [1.9345],\n",
       "        [1.6307],\n",
       "        [0.7674],\n",
       "        [1.5388],\n",
       "        [5.6567],\n",
       "        [0.9087],\n",
       "        [5.2103],\n",
       "        [5.6731],\n",
       "        [1.2158],\n",
       "        [1.3718],\n",
       "        [1.1722],\n",
       "        [1.5352],\n",
       "        [5.6567],\n",
       "        [1.2985],\n",
       "        [1.7965],\n",
       "        [0.8932],\n",
       "        [0.9087],\n",
       "        [1.1416],\n",
       "        [5.2103],\n",
       "        [5.9916],\n",
       "        [1.6459],\n",
       "        [5.8659],\n",
       "        [0.5960],\n",
       "        [1.5919],\n",
       "        [1.5193],\n",
       "        [5.2103],\n",
       "        [5.2103],\n",
       "        [5.8275],\n",
       "        [0.9087],\n",
       "        [5.2103],\n",
       "        [1.7277],\n",
       "        [5.6567],\n",
       "        [0.7269],\n",
       "        [5.2103],\n",
       "        [4.5607],\n",
       "        [0.6667],\n",
       "        [2.9255],\n",
       "        [1.3043],\n",
       "        [5.9809],\n",
       "        [2.6728],\n",
       "        [1.3797],\n",
       "        [2.2445],\n",
       "        [5.2103],\n",
       "        [5.2103],\n",
       "        [5.2103],\n",
       "        [2.6728],\n",
       "        [0.6844],\n",
       "        [3.9182],\n",
       "        [1.5264],\n",
       "        [0.6309],\n",
       "        [0.9087],\n",
       "        [0.4642],\n",
       "        [1.3486],\n",
       "        [5.2103],\n",
       "        [2.6022],\n",
       "        [1.6011],\n",
       "        [5.9403],\n",
       "        [0.8308],\n",
       "        [1.5022],\n",
       "        [1.7227],\n",
       "        [0.9087],\n",
       "        [0.8932],\n",
       "        [5.2103],\n",
       "        [1.3103],\n",
       "        [5.2103],\n",
       "        [0.8932],\n",
       "        [1.5521],\n",
       "        [2.6022],\n",
       "        [1.2644],\n",
       "        [1.6562],\n",
       "        [1.8333],\n",
       "        [1.2883],\n",
       "        [5.2103],\n",
       "        [0.9328],\n",
       "        [1.8094],\n",
       "        [2.9255],\n",
       "        [5.2103],\n",
       "        [1.4228],\n",
       "        [1.4573],\n",
       "        [1.8548],\n",
       "        [1.6401],\n",
       "        [1.4524],\n",
       "        [5.2103],\n",
       "        [5.9659],\n",
       "        [5.6567],\n",
       "        [0.7674],\n",
       "        [1.1958],\n",
       "        [0.8932],\n",
       "        [1.3830],\n",
       "        [1.9182],\n",
       "        [3.9182],\n",
       "        [1.7433],\n",
       "        [5.9959],\n",
       "        [1.6500],\n",
       "        [2.1770],\n",
       "        [1.8548],\n",
       "        [1.4810],\n",
       "        [1.5010],\n",
       "        [5.2103],\n",
       "        [5.2103],\n",
       "        [5.8659]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1398,  0.2578,  0.0067,  ...,  0.0022, -0.0567,  0.0539],\n",
       "        [-0.0345,  0.5666,  0.0138,  ..., -0.0308, -0.0490,  0.0282],\n",
       "        [-0.0262, -0.2580, -0.0314,  ..., -0.0224, -0.0267,  0.0326],\n",
       "        ...,\n",
       "        [-0.2423, -0.2699, -0.0769,  ..., -0.1205, -0.1915, -0.1536],\n",
       "        [-0.2423, -0.2699, -0.0769,  ..., -0.1205, -0.1915, -0.1536],\n",
       "        [-0.3200, -0.4053, -0.0855,  ..., -0.1178, -0.2277, -0.2164]])"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantized * quantized.norm(p=2, dim=-1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3149,  0.6769,  0.1253,  ..., -0.0045, -0.1866,  0.1910],\n",
       "        [-1.9470,  4.1741,  0.2301,  ..., -0.0606, -0.2085,  0.0677],\n",
       "        [-0.1827, -0.2787, -0.2146,  ..., -0.2211, -0.1881, -0.7975],\n",
       "        ...,\n",
       "        [-0.0288,  0.0232, -0.2488,  ..., -0.2464, -0.3122,  0.0921],\n",
       "        [-0.5402, -0.8153, -0.0747,  ..., -0.4094, -1.4079, -0.1554],\n",
       "        [-0.8989, -0.0449, -0.3596,  ...,  0.0108, -0.0728, -0.7832]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3370)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(dataset[0][0] - quantized).abs().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([287, 128])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((\n",
    "    state_dict[f\"layers.0.weight\"].T, \n",
    "    state_dict[f\"layers.1.weight\"].T, \n",
    "    state_dict[f\"layers.2.weight\"].T, \n",
    "    state_dict[f\"layers.3.weight\"],\n",
    "    state_dict[f\"layers.0.bias\"].unsqueeze(0),\n",
    "    state_dict[f\"layers.1.bias\"].unsqueeze(0),\n",
    "    state_dict[f\"layers.2.bias\"].unsqueeze(0),\n",
    "    )).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict[f\"layers.1.weight\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict[f\"layers.3.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "biases = get_all_biases(dataset, 3, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0706)\n",
      "tensor(0.7267)\n",
      "tensor(-5.4607)\n",
      "tensor(4.3834)\n"
     ]
    }
   ],
   "source": [
    "print(biases.mean())\n",
    "print(biases.std())\n",
    "print(biases.min())\n",
    "print(biases.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3446)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(pos_biases < 2).int().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  1.,  0.,  2.,  2.,  4.,  2.,  1.,  2.,  1.,  5.,  2.,  1.,\n",
       "         0.,  1.,  2.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.,  3.,  3.,\n",
       "         3.,  0.,  1.,  0.,  3.,  0.,  1.,  4.,  3.,  0.,  2.,  1.,  1.,\n",
       "         3.,  1.,  2.,  1.,  2.,  6.,  2.,  3.,  3.,  0.,  1.,  0.,  1.,\n",
       "         3.,  3.,  3.,  0.,  2.,  3.,  1.,  1.,  3.,  0.,  2.,  0.,  2.,\n",
       "         2.,  4.,  5.,  2.,  4.,  1.,  4.,  1.,  1.,  3.,  2.,  2.,  2.,\n",
       "         1.,  2.,  0.,  2.,  2.,  1.,  1.,  2.,  1.,  6.,  3.,  1.,  4.,\n",
       "         2.,  0.,  2.,  3.,  5.,  0.,  4.,  1.,  4.,  2.,  1.,  2.,  4.,\n",
       "         2.,  2.,  3.,  4.,  4.,  3.,  1.,  1.,  2.,  5.,  1.,  7.,  5.,\n",
       "         3.,  1.,  2.,  1.,  2.,  3.,  1.,  6.,  3.,  2.,  2.,  1.,  0.,\n",
       "         2.,  3.,  4.,  5.,  3.,  1.,  1.,  6.,  2.,  3.,  1.,  2.,  3.,\n",
       "         6.,  4.,  2.,  4.,  2.,  0.,  3.,  4.,  2.,  3.,  2.,  4.,  6.,\n",
       "         2.,  2.,  2.,  2.,  3.,  3.,  3.,  3.,  4.,  1.,  5.,  2.,  5.,\n",
       "         3.,  2.,  2.,  2.,  1.,  3.,  5.,  1.,  1.,  4.,  2.,  1.,  2.,\n",
       "         2.,  6.,  1.,  5.,  3.,  5.,  4.,  4.,  1.,  5.,  8.,  4.,  1.,\n",
       "         2.,  3.,  1.,  5.,  3.,  4.,  3.,  6.,  3.,  1.,  2.,  3.,  0.,\n",
       "         3.,  3.,  2.,  5.,  1.,  1.,  5.,  3.,  3.,  6.,  6.,  0.,  2.,\n",
       "         2.,  4.,  2.,  2.,  5.,  4.,  5.,  2.,  1.,  2.,  4.,  6.,  5.,\n",
       "         5.,  1.,  7.,  4.,  2.,  7.,  1.,  4.,  4.,  2.,  2.,  3.,  5.,\n",
       "         5.,  5.,  2.,  9.,  4.,  3.,  3.,  3.,  2.,  5.,  0.,  5.,  4.,\n",
       "         5.,  5.,  3.,  6.,  4.,  2.,  8.,  5.,  5.,  5.,  8.,  6.,  5.,\n",
       "         4.,  9.,  0.,  4.,  3.,  9.,  3.,  7.,  4.,  5.,  2.,  7.,  4.,\n",
       "         5.,  6.,  6.,  7.,  3.,  5.,  3.,  1.,  3.,  4.,  3.,  4.,  3.,\n",
       "         6.,  1.,  2.,  5.,  1.,  5.,  9.,  2.,  4.,  6.,  3.,  1.,  7.,\n",
       "         5.,  3.,  3.,  6.,  6.,  5., 10.,  7.,  1.,  7.,  2.,  3.,  4.,\n",
       "         2.,  4.,  2.,  3.,  3.,  5.,  0.,  7.,  4.,  5.,  1.,  4.,  2.,\n",
       "         5.,  5.,  8.,  7.,  3.,  4., 10.,  4.,  7.,  4.,  2.,  3.,  3.,\n",
       "         4.,  6.,  4.,  7.,  6.,  2.,  0.,  5.,  7.,  4.,  3.,  4., 11.,\n",
       "         5.,  3.,  8.,  4.,  4.,  4.,  1.,  4.,  2.,  2.,  6.,  7.,  8.,\n",
       "         3.,  4.,  8.,  8.,  4.,  1.,  4.,  5.,  3.,  7.,  7.,  3.,  3.,\n",
       "         9.,  3.,  7.,  3.,  0.,  5.,  2.,  8.,  4.,  8.,  4.,  4.,  3.,\n",
       "         1.,  1.,  3.,  6.,  5.,  2.,  4.,  2.,  4.,  5.,  4.,  3.,  3.,\n",
       "         6.,  4.,  6.,  4., 10.,  6.,  4.,  7.,  5.,  4.,  7.,  4.,  8.,\n",
       "         6.,  3.,  3.,  6.,  5.,  7.,  1.,  2.,  8.,  4.,  2.,  3.,  4.,\n",
       "         3.,  4., 11.,  5.,  4.,  2.,  3.,  7.,  6.,  4.,  6.,  1.,  6.,\n",
       "         4.,  2.,  6.,  5.,  9.,  3.,  1.,  7.,  3.,  5.,  7.,  6.,  3.,\n",
       "         6.,  9.,  7.,  5.,  5.,  3.,  5.,  4.,  8.,  6.,  5.,  6.,  8.,\n",
       "         7.,  4.,  8.,  5.,  3.,  3.,  6.,  3.,  0.,  2.,  1.,  6.,  5.,\n",
       "         1.,  6.,  3.,  5.,  4.,  3.,  4.,  8.,  1.,  4.,  6.,  7.,  6.,\n",
       "         5.,  3.,  1.,  5.,  4.,  4.,  1.,  8.,  2.,  5.,  3.,  1.,  6.,\n",
       "         3.,  3.,  3.,  6.,  2.,  4.,  7.,  3.,  7.,  4.,  5.,  5.,  8.,\n",
       "         9.,  5.,  4.,  1.,  3.,  3.,  4.,  4.,  3.,  5.,  6.,  4.,  9.,\n",
       "         3.,  6.,  8.,  6.,  6.,  1.,  5.,  3.,  2.,  4.,  6.,  5.,  2.,\n",
       "         4.,  1.,  4.,  1.,  3.,  4.,  4.,  1.,  7.,  6.,  4.,  5.,  3.,\n",
       "         2.,  2.,  1.,  5.,  5.,  8.,  3.,  9.,  4.,  3.,  4.,  4.,  5.,\n",
       "         4.,  4.,  1.,  5.,  6.,  8.,  7.,  4.,  2.,  0.,  6.,  4.,  4.,\n",
       "         4.,  7.,  6.,  5.,  6.,  3.,  4.,  5.,  5.,  4.,  6.,  2.,  7.,\n",
       "         3.,  7.,  3.,  7.,  5.,  4.,  7.,  6.,  0.,  5.,  2.,  6.,  3.,\n",
       "         9.,  3.,  2.,  5.,  5.,  2.,  3.,  7.,  5.,  3., 10.,  5.,  5.,\n",
       "         8.,  3.,  3.,  2.,  3.,  4.,  7.,  6.,  4.,  5.,  3.,  5.,  8.,\n",
       "         0.,  3.,  5.,  8.,  3.,  4.,  1.,  8.,  0.,  5.,  2.,  5.,  6.,\n",
       "         4.,  5.,  3.,  5.,  2.,  7.,  3.,  4.,  2.,  2.,  5.,  3.,  3.,\n",
       "         3.,  5.,  4.,  2.,  1.,  5.,  5.,  1.,  4.,  3.,  8.,  2.,  2.,\n",
       "         3.,  7.,  3.,  5.,  2.,  5.,  2.,  8.,  5.,  4.,  7.,  6.,  4.,\n",
       "         1.,  5.,  0.,  5.,  4.,  3.,  1.,  2.,  4.,  5.,  2.,  4.,  4.,\n",
       "         5.,  4.,  5.,  0.,  3.,  3.,  6.,  4.,  4.,  3.,  3.,  6.,  0.,\n",
       "         4.,  2.,  1.,  2.,  4.,  2.,  3.,  3.,  3.,  3.,  2.,  1.,  4.,\n",
       "         2.,  5.,  9.,  4.,  5.,  2.,  4.,  2.,  4.,  3.,  3.,  7.,  2.,\n",
       "         5.,  2.,  3.,  2.,  5.,  5.,  3.,  1.,  4.,  4.,  6.,  6.,  3.,\n",
       "         0.,  4.,  2.,  4.,  3.,  5.,  3.,  1.,  6.,  1.,  1.,  3.,  6.,\n",
       "         6.,  2.,  0.,  3.,  2.,  6.,  1.,  3.,  5.,  1.,  2.,  2.,  2.,\n",
       "         1.,  3.,  4.,  1.,  1.,  5.,  2.,  1.,  4.,  3.,  1.,  1.,  4.,\n",
       "         3.,  6.,  3.,  4.,  3.,  3.,  4.,  2.,  6.,  0.,  4.,  2.,  3.,\n",
       "         4.,  2.,  2.,  3.,  3.,  2.,  7.,  1.,  4.,  3.,  0.,  3.,  9.,\n",
       "         0.,  1.,  2.,  2.,  4.,  3.,  1.,  1.,  4.,  1.,  3.,  1.,  5.,\n",
       "         3.,  2.,  3.,  5.,  2.,  3.,  3.,  6.,  0.,  2.,  2.,  1.,  5.,\n",
       "         1.,  2.,  6.,  2.,  4.,  1.,  3.,  2.,  2.,  3.,  7.,  2.,  7.,\n",
       "         2.,  1.,  6.,  3.,  2.,  2.,  3.,  4.,  3.,  3.,  2.,  3.,  2.,\n",
       "         3.,  6.,  2.,  2.,  2.,  1.,  3.,  4.,  0.,  3.,  0.,  1.,  1.,\n",
       "         1.,  3.,  5.,  1.,  3.,  2.,  2.,  1.,  1.,  0.,  1.,  3.,  1.,\n",
       "         1.,  1.,  2.,  5.,  1.,  1.,  4.,  2.,  4.,  1.,  2.,  3.,  1.,\n",
       "         1.,  4.,  4.,  3.,  2.,  2.,  2.,  3.,  4.,  4.,  1.,  3.,  4.,\n",
       "         1.,  2.,  1.,  5.,  2.,  1.,  1.,  5.,  1.,  3.,  3.,  5.,  4.,\n",
       "         3.,  2.,  5.,  2.,  4.,  2.,  4.,  1.,  4.,  5.,  3.,  2.,  2.,\n",
       "         4.,  0.,  1.,  1.,  1.,  2.,  5.,  1.,  3.,  2.,  0.,  1.,  5.,\n",
       "         2.,  2.,  3.,  0.,  1.,  3.,  3.,  4.,  1.,  3.,  1.,  0.,  0.,\n",
       "         3.,  3.,  2.,  1.,  3.,  1.,  1.,  3.,  2.,  1.,  0.,  2.]),\n",
       " array([0.00241671, 0.00441374, 0.00641078, ..., 1.99545884, 1.99745595,\n",
       "        1.99945295]),\n",
       " <BarContainer object of 1000 artists>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pos_biases = biases[biases>0]\n",
    "\n",
    "plt.hist(pos_biases[pos_biases<2], bins=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_weights = True\n",
    "if compute_weights:\n",
    "    import h5py\n",
    "\n",
    "    all_weights_layer_0 = torch.zeros(27, 4045, 128)\n",
    "    all_weights_layer_1 = torch.zeros(128, 4045, 128)\n",
    "    all_weights_layer_2 = torch.zeros(128, 4045, 128)\n",
    "    all_weights_layer_3 = torch.zeros(128, 4045, 1)\n",
    "\n",
    "\n",
    "    for i in range(27):\n",
    "        all_weights_layer_0[i] = get_all_weights(dataset, 0, i)\n",
    "\n",
    "    for i in range(128):\n",
    "        all_weights_layer_1[i] = get_all_weights(dataset, 1, i)\n",
    "\n",
    "    for i in range(128):\n",
    "        all_weights_layer_2[i] = get_all_weights(dataset, 2, i)\n",
    "\n",
    "    for i in range(128):\n",
    "        all_weights_layer_3[i] = get_all_weights(dataset, 3, i)\n",
    "        \n",
    "    all_weights = torch.cat((all_weights_layer_0.view(-1, 128), all_weights_layer_1.view(-1, 128), all_weights_layer_2.view(-1, 128), all_weights_layer_3.view(-1, 128)))\n",
    "\n",
    "    # Save the tensor to an HDF5 file\n",
    "    with h5py.File('datasets/plane_mlp_weights.h5', 'w') as f:\n",
    "        f.create_dataset('dataset', data=all_weights)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import h5py\n",
    "\n",
    "class HDF5Dataset(Dataset):\n",
    "    def __init__(self, hdf5_file, dataset_name):\n",
    "        self.hdf5_file = hdf5_file\n",
    "        self.dataset_name = dataset_name\n",
    "        with h5py.File(self.hdf5_file, 'r') as f:\n",
    "            self.dataset_length = f[self.dataset_name].shape[0]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.dataset_length\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        with h5py.File(self.hdf5_file, 'r') as f:\n",
    "            data = f[self.dataset_name][idx]\n",
    "            return torch.tensor(data)\n",
    "\n",
    "# Instantiate the dataset and dataloader\n",
    "hdf5_dataset = HDF5Dataset('datasets/plane_mlp_weights.h5', 'dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2**14\n",
    "train_dataloader = DataLoader(hdf5_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:7fnfl6zh) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▂▃▄▆▇▁▃▄▅▇▁▂▄▅▇█▂▄▄▆█▂▃▅▆▇▁▃▅▅▇▂▂▄▆▇█▂▄▆</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>loss</td><td>██▆▆▅▅▄▃▃▃▃▃▂▂▂▂▂▂▂▂▂▁▁▂▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>lr</td><td>▁▂▄▅▆████████████████▇▇▇▇▇▇▇▇▇▇▇▇▇▆▆▆▆▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>52</td></tr><tr><td>epoch</td><td>7</td></tr><tr><td>loss</td><td>0.23942</td></tr><tr><td>lr</td><td>0.0036</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-2024-06-27-10-47-05</strong> at: <a href='https://wandb.ai/adl-for-cv/autoencoder/runs/7fnfl6zh' target=\"_blank\">https://wandb.ai/adl-for-cv/autoencoder/runs/7fnfl6zh</a><br/> View project at: <a href='https://wandb.ai/adl-for-cv/autoencoder' target=\"_blank\">https://wandb.ai/adl-for-cv/autoencoder</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240627_104706-7fnfl6zh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:7fnfl6zh). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/luis/uni/adl4cv/adl4cv/adl4cv/wandb/run-20240627_124647-27300iod</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adl-for-cv/autoencoder/runs/27300iod' target=\"_blank\">run-2024-06-27-10-47-05</a></strong> to <a href='https://wandb.ai/adl-for-cv/autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adl-for-cv/autoencoder' target=\"_blank\">https://wandb.ai/adl-for-cv/autoencoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adl-for-cv/autoencoder/runs/27300iod' target=\"_blank\">https://wandb.ai/adl-for-cv/autoencoder/runs/27300iod</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: models/vq_ae/model_epoch_0.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: models/vq_ae/model_epoch_1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: models/vq_ae/model_epoch_2.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: models/vq_ae/model_epoch_3.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved: models/vq_ae/model_epoch_4.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                         \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 32\u001b[0m\n\u001b[1;32m     28\u001b[0m vq_config\u001b[38;5;241m.\u001b[39mdim_dec \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m128\u001b[39m)\n\u001b[1;32m     29\u001b[0m vq_config\u001b[38;5;241m.\u001b[39mwith_vq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m ae_trained \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvq_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mL1Loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/adl4cv/training/training_autoencoder.py:108\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(config, model_config, train_loader, eval_loader, loss)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(config\u001b[38;5;241m.\u001b[39mmax_iters):\n\u001b[1;32m    107\u001b[0m     loop \u001b[38;5;241m=\u001b[39m tqdm(train_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 108\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/uni/adl4cv/adl4cv/adl4cv/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Network error (ConnectionError), entering retry loop.\n"
     ]
    }
   ],
   "source": [
    "from networks.vq_ae import VQAutoencoderConfig\n",
    "from training.training_autoencoder import train_model, TrainingConfig\n",
    "\n",
    "from torch import nn\n",
    "from torch.nn import MSELoss, CrossEntropyLoss, L1Loss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "batch_size = 2**14\n",
    "train_dataloader = DataLoader(hdf5_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = train_dataloader#DataLoader([test_dataset[0][0][0]], batch_size=1, shuffle=True)\n",
    "\n",
    "train_config = TrainingConfig()\n",
    "train_config.max_iters = 10\n",
    "train_config.always_save_checkpoint = True\n",
    "train_config.weight_decay = 0.0\n",
    "train_config.learning_rate = 5e-3\n",
    "train_config.lr_decay_iters = train_config.max_iters*len(train_dataloader)\n",
    "train_config.warmup_iters = 0.05*train_config.max_iters*len(train_dataloader)\n",
    "train_config.log_interval = 1\n",
    "train_config.out_dir = \"models/vq_ae\"\n",
    "\n",
    "vq_config = VQAutoencoderConfig()\n",
    "vq_config.dim_enc = (128, 64, 32)\n",
    "vq_config.dim_dec = (32, 64, 128)\n",
    "vq_config.with_vq = False\n",
    "\n",
    "\n",
    "ae_trained = train_model(train_config, vq_config, train_dataloader, test_dataloader, L1Loss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from networks.vq_ae import VQAutoencoder\n",
    "\n",
    "\n",
    "vq_ae = VQAutoencoder(vq_config)\n",
    "vq_ae_dict = torch.load(\"models/vq_ae/model_epoch_6.pth\")[\"model_state_dict\"]\n",
    "vq_ae.load_state_dict(vq_ae_dict)\n",
    "\n",
    "\n",
    "for batch in train_dataloader:\n",
    "    X = batch\n",
    "    Y = vq_ae(X)\n",
    "    error = X-Y\n",
    "    break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1078, 0.0341, 0.0054,  ..., 0.0309, 0.0983, 0.3144],\n",
       "        [0.0984, 0.2903, 0.0172,  ..., 0.3958, 0.7926, 1.1895],\n",
       "        [0.0341, 0.0267, 0.0785,  ..., 0.0658, 0.0469, 0.0328],\n",
       "        ...,\n",
       "        [0.1093, 0.0593, 0.0043,  ..., 0.0463, 0.0622, 0.0515],\n",
       "        [0.3041, 0.0401, 0.0287,  ..., 0.7800, 0.6764, 3.0190],\n",
       "        [0.2775, 1.1532, 0.0257,  ..., 0.7382, 0.0043, 0.2169]],\n",
       "       grad_fn=<AbsBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error.abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
