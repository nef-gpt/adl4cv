{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable autoreload of module\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "import torch\n",
    "import os\n",
    "\n",
    "from data.DWSNets_dataset import DWSNetsDataset, LayerOneHotTransform, FlattenTransform, BiasFlagTransform\n",
    "from networks.naive_rq_ae import RQAutoencoder, RQAutoencoderConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dir_path = os.path.dirname(os.path.abspath(os.getcwd()))\n",
    "data_root = os.path.join(dir_path, \"adl4cv\", \"datasets\", \"DWSNets\", \"mnist-inrs\")\n",
    "\n",
    "class AutoencoderTransform(torch.nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.bias = BiasFlagTransform()\n",
    "    self.flatten = FlattenTransform()\n",
    "    self.layer_one_hot = LayerOneHotTransform()\n",
    "\n",
    "  def forward(self, x, y):\n",
    "    bias = self.bias(x)\n",
    "    layer = self.layer_one_hot(x)    \n",
    "    x = self.flatten(x)\n",
    "    return torch.hstack((x, layer, bias)), y\n",
    "\n",
    "\n",
    "\n",
    "train_dataset = DWSNetsDataset(data_root, transform=AutoencoderTransform())\n",
    "test_dataset = DWSNetsDataset(data_root, split=\"test\", transform=AutoencoderTransform())\n",
    "path = \"datasets/DWSNets/mnist-inrs/mnist_splits.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0190,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0074,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0846,  1.0000,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [-0.1998,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [-0.1661,  0.0000,  0.0000,  1.0000,  0.0000],\n",
      "        [-0.0389,  0.0000,  0.0000,  1.0000,  1.0000]])\n",
      "tensor([[ 0.1465,  0.3759, -0.2415, -0.0327, -0.0401],\n",
      "        [ 0.1465,  0.3759, -0.2415, -0.0327, -0.0401],\n",
      "        [ 0.1465,  0.3759, -0.2415, -0.0327, -0.0401],\n",
      "        ...,\n",
      "        [ 0.1465,  0.3759, -0.2415, -0.0327, -0.0401],\n",
      "        [ 0.1465,  0.3759, -0.2415, -0.0327, -0.0401],\n",
      "        [ 0.1465,  0.3759, -0.2415, -0.0327, -0.0401]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "ae_config = RQAutoencoderConfig(dim_l=(5, 64, 4, 3))\n",
    "ae = RQAutoencoder(ae_config)\n",
    "\n",
    "print(train_dataset[203][0])\n",
    "print(ae(train_dataset[203][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:7s07lipu) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval_loss</td><td>▁</td></tr><tr><td>loss</td><td>██▇▇▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>batch</td><td>200</td></tr><tr><td>epoch</td><td>0</td></tr><tr><td>eval_loss</td><td>0.1135</td></tr><tr><td>loss</td><td>0.03488</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">run-2024-05-23-14-46-27</strong> at: <a href='https://wandb.ai/adl-for-cv/autoencoder/runs/7s07lipu' target=\"_blank\">https://wandb.ai/adl-for-cv/autoencoder/runs/7s07lipu</a><br/> View project at: <a href='https://wandb.ai/adl-for-cv/autoencoder' target=\"_blank\">https://wandb.ai/adl-for-cv/autoencoder</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240523_144628-7s07lipu/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:7s07lipu). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/luca/uni/master/second-semester/adl4cv/wandb/run-20240523_144746-mdjs747f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/adl-for-cv/autoencoder/runs/mdjs747f' target=\"_blank\">run-2024-05-23-14-47-46</a></strong> to <a href='https://wandb.ai/adl-for-cv/autoencoder' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/adl-for-cv/autoencoder' target=\"_blank\">https://wandb.ai/adl-for-cv/autoencoder</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/adl-for-cv/autoencoder/runs/mdjs747f' target=\"_blank\">https://wandb.ai/adl-for-cv/autoencoder/runs/mdjs747f</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[127], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m train_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(train_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m test_dataloader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTrainingConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mae_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMSELoss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/uni/master/second-semester/adl4cv/training/training_autoencoder.py:116\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(config, model_config, train_loader, eval_loader, loss)\u001b[0m\n\u001b[1;32m    113\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m: loss\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: epoch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m})\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m config\u001b[38;5;241m.\u001b[39meval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 116\u001b[0m         eval_loss \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaler\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mlog({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m: eval_loss, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m\"\u001b[39m: epoch, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m\"\u001b[39m: i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m})\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39malways_save_checkpoint:\n",
      "File \u001b[0;32m~/uni/master/second-semester/adl4cv/training/training_autoencoder.py:133\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, eval_loader, criterion, device, scaler)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;66;03m# only take random 16 batches\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     idx \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandperm(\u001b[38;5;28mlen\u001b[39m(eval_loader))[:\u001b[38;5;241m16\u001b[39m]\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43meval_loader\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m:\n\u001b[1;32m    134\u001b[0m         inputs \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m autocast(device_type\u001b[38;5;241m=\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype, enabled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m(scaler)):\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from training.training_autoencoder import train_model, TrainingConfig\n",
    "\n",
    "from torch.nn import MSELoss\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "train_model(TrainingConfig(), ae_config, train_dataloader, test_dataloader, MSELoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
