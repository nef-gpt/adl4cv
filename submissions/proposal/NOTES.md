abstract

learn a vocabulary of latent embeddings - using some kind of neighbourhood encoding
train an autoencoder to find an embedding that maps from a unordered representation to a ordered latent space
find positional encoding based on graph structure of the neural network
experiment with ordering of the weight


IDEA:

ordering of the weights (depth-first search)



TODO:

research attention-based learning for unordered data
autoregressive models for continuous values / how to predict the token if token is a continuous number (eg. float)