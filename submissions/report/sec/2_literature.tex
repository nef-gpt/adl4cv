% Literature Review
\section{Related Works}
\label{sec:literature}

\subsection*{Neural Implicit Fields and Diffusion Models}
Recent advancements have demonstrated the effectiveness of neural implicit fields in representing high-fidelity 3D geometries and radiance fields. For instance, DeepSDF \cite{park2019deepsdflearningcontinuoussigned} encodes the shapes of objects as signed distance functions using a multi-layer neural network, and NeRF uses MLPs to encode radiance fields for photorealistic rendering from novel views \cite{mildenhall2020nerfrepresentingscenesneural}. Additionally, methods like Fourier features and periodic activation functions have been proposed to improve the representation of complex signals by addressing the bias towards learning low-frequency details in standard MLP \cite{tancik2020fourierfeaturesletnetworks, sitzmann2020implicitneuralrepresentationsperiodic}.


\subsection*{Transformer-Based 3D Structure Generation}
Transformer architectures have shown promise in generating 3D structures. MeshGPT \cite{siddiqui2023meshgpt}, for example, uses a decoder-only transformer to autoregressively generate triangle meshes, representing them as sequences of geometric embeddings. This approach has demonstrated improvements in mesh generation quality, emphasizing the capability of transformers to handle complex geometric data efficiently.


\subsection*{Generative Adversarial Networks (GANs)}
GANs \cite{goodfellow2014generativeadversarialnetworks} have been widely used for generating high-resolution images and 3D structures. However, they often suffer from training instability. This has led researchers to explore diffusion models as alternatives, which offer more stable training dynamics and improved generative performance.


\subsection*{Diffusion Models in Generative Modeling}
Diffusion probabilistic models have emerged as powerful alternatives to GANs and energy-based models for generative tasks. Specifically, HyperDiffusion \cite{erko√ß2023hyperdiffusion} operates directly on the MLP weights of neural fields, enabling high-fidelity synthesis of 3D and 4D shapes. This method leverages a transformer-based architecture to model the diffusion process, achieving state-of-the-art performance in generating compact and coherent neural implicit fields.
