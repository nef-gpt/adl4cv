% Literature Review
\section{Related Works}
\label{sec:literature}

\subsection*{Implicit neural fields and Diffusion Models}
Recent advancements have demonstrated the effectiveness of implicit neural fields in representing high-fidelity 3D geometries and radiance fields. For instance, DeepSDF \cite{park2019deepsdflearningcontinuoussigned} encodes the shapes of objects as signed distance functions using a multi-layer neural network, and NeRF uses MLPs to encode radiance fields for photorealistic rendering from novel views \cite{mildenhall2020nerfrepresentingscenesneural}. Additionally, methods like Fourier features and periodic activation functions have been proposed to improve the representation of complex signals by addressing the bias towards learning low-frequency details in standard MLP \cite{tancik2020fourierfeaturesletnetworks, sitzmann2020implicitneuralrepresentationsperiodic}. Our methods aims to generate novel implicit neural fields that represent the implicit signal of both image data as well as the surface of 3D structures.


\subsection*{Transformer-Based 3D Structure Generation}
Transformer architectures have shown promise in generating 3D structures. MeshGPT \cite{siddiqui2023meshgpt}, for example, uses a decoder-only transformer to autoregressively generate triangle meshes, representing them as sequences of geometric embeddings. This approach has demonstrated improvements in mesh generation quality, emphasizing the capability of transformers to handle complex geometric data efficiently. Adapting this technique, our pipeline uses a GPT like transformer but changes the domain from triangle meshes to MLP-weights.


\subsection*{Diffusion Models in Generative Modeling}
Diffusion models have been emerging in the recent past and shown promising results for novel generation tasks. Specifically, HyperDiffusion \cite{erko√ß2023hyperdiffusion} operates directly on the MLP weights of neural fields, enabling high-fidelity synthesis of 3D and 4D shapes. This method leverages a transformer-based architecture to model the diffusion process, achieving state-of-the-art performance in generating compact and coherent implicit neural fields. Influenced by this work we show the possibility of generating novel implicit neural field weights using an autoregressive process.
